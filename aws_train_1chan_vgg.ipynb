{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hollywood-hindu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0 tf\n",
      "2.4.3 keras\n"
     ]
    }
   ],
   "source": [
    "### Init network Build\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "import keras\n",
    "import time\n",
    "import tensorflow as tf\n",
    "print(tf.__version__, 'tf')\n",
    "print(keras.__version__, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "laughing-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.read_csv('image_metrics_031021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "likely-camera",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99707, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>img_res</th>\n",
       "      <th>img_type</th>\n",
       "      <th>img_index</th>\n",
       "      <th>da_num</th>\n",
       "      <th>img_path</th>\n",
       "      <th>da_number</th>\n",
       "      <th>cwa_determination</th>\n",
       "      <th>metrics</th>\n",
       "      <th>mean</th>\n",
       "      <th>stdev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>lores</td>\n",
       "      <td>mndwi</td>\n",
       "      <td>292</td>\n",
       "      <td>LRC-2003-22227</td>\n",
       "      <td>/data/image_final2/GEE_images_final2_lores_mnd...</td>\n",
       "      <td>LRC-2003-22227</td>\n",
       "      <td>1</td>\n",
       "      <td>(-0.3306894463763968, 0.09898692070930509)</td>\n",
       "      <td>-0.330689</td>\n",
       "      <td>0.098987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hires</td>\n",
       "      <td>mndwi</td>\n",
       "      <td>8157</td>\n",
       "      <td>SAC-2007-01367</td>\n",
       "      <td>/data/image_final2/GEE_images_final2_hires_mnd...</td>\n",
       "      <td>SAC-2007-01367</td>\n",
       "      <td>0</td>\n",
       "      <td>(-0.40988840562690426, 0.19788100896017022)</td>\n",
       "      <td>-0.409888</td>\n",
       "      <td>0.197881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>lores</td>\n",
       "      <td>srtm</td>\n",
       "      <td>5495</td>\n",
       "      <td>MVP-2020-00252-MHK</td>\n",
       "      <td>/data/image_final2/GEE_images_final2_lores_srt...</td>\n",
       "      <td>MVP-2020-00252-MHK</td>\n",
       "      <td>0</td>\n",
       "      <td>(211.5080108642578, 18.443937482788826)</td>\n",
       "      <td>211.508011</td>\n",
       "      <td>18.443937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>lores</td>\n",
       "      <td>gmndwi</td>\n",
       "      <td>10297</td>\n",
       "      <td>SAM-2016-00139-MJF</td>\n",
       "      <td>/data/image_final2/GEE_images_final2_lores_gmn...</td>\n",
       "      <td>SAM-2016-00139-MJF</td>\n",
       "      <td>1</td>\n",
       "      <td>(0.340306, 0.6714834)</td>\n",
       "      <td>0.340306</td>\n",
       "      <td>0.671483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>hires</td>\n",
       "      <td>seasonality</td>\n",
       "      <td>8500</td>\n",
       "      <td>SAC-2016-00087</td>\n",
       "      <td>/data/image_final2/GEE_images_final2_hires_sea...</td>\n",
       "      <td>SAC-2016-00087</td>\n",
       "      <td>1</td>\n",
       "      <td>(0.02587890625, 0.4714458509886673)</td>\n",
       "      <td>0.025879</td>\n",
       "      <td>0.471446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 img_res     img_type  img_index              da_num  \\\n",
       "0           0   lores        mndwi        292      LRC-2003-22227   \n",
       "1           1   hires        mndwi       8157      SAC-2007-01367   \n",
       "2           2   lores         srtm       5495  MVP-2020-00252-MHK   \n",
       "3           3   lores       gmndwi      10297  SAM-2016-00139-MJF   \n",
       "4           4   hires  seasonality       8500      SAC-2016-00087   \n",
       "\n",
       "                                            img_path           da_number  \\\n",
       "0  /data/image_final2/GEE_images_final2_lores_mnd...      LRC-2003-22227   \n",
       "1  /data/image_final2/GEE_images_final2_hires_mnd...      SAC-2007-01367   \n",
       "2  /data/image_final2/GEE_images_final2_lores_srt...  MVP-2020-00252-MHK   \n",
       "3  /data/image_final2/GEE_images_final2_lores_gmn...  SAM-2016-00139-MJF   \n",
       "4  /data/image_final2/GEE_images_final2_hires_sea...      SAC-2016-00087   \n",
       "\n",
       "   cwa_determination                                      metrics        mean  \\\n",
       "0                  1   (-0.3306894463763968, 0.09898692070930509)   -0.330689   \n",
       "1                  0  (-0.40988840562690426, 0.19788100896017022)   -0.409888   \n",
       "2                  0      (211.5080108642578, 18.443937482788826)  211.508011   \n",
       "3                  1                        (0.340306, 0.6714834)    0.340306   \n",
       "4                  1          (0.02587890625, 0.4714458509886673)    0.025879   \n",
       "\n",
       "       stdev  \n",
       "0   0.098987  \n",
       "1   0.197881  \n",
       "2  18.443937  \n",
       "3   0.671483  \n",
       "4   0.471446  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_merged.shape)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fitted-carter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MVP    14379\n",
       "MVN     9281\n",
       "SAC     7953\n",
       "SWG     7717\n",
       "NAO     6484\n",
       "MVK     6079\n",
       "LRC     5317\n",
       "NWO     4676\n",
       "POA     4452\n",
       "SAW     3385\n",
       "LRH     3148\n",
       "LRL     3062\n",
       "SAM     3029\n",
       "LRB     2889\n",
       "NWK     2732\n",
       "LRE     1752\n",
       "SWL     1700\n",
       "NAN     1674\n",
       "MVM     1567\n",
       "NAB     1400\n",
       "NWP     1023\n",
       "NWS     1020\n",
       "NAP      940\n",
       "SAS      874\n",
       "MVR      790\n",
       "SAJ      630\n",
       "SWT      428\n",
       "POH      340\n",
       "LRP      329\n",
       "NAE      290\n",
       "NWW      160\n",
       "LRN      157\n",
       "MVS       50\n",
       "Name: da_num, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f3 = df_merged.da_num.apply(lambda x: x[:3])\n",
    "f3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "original-cardiff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408\n"
     ]
    }
   ],
   "source": [
    "dir2 = '/data/training_data4/'\n",
    "train_X = [f for f in Path(dir2).iterdir()] #if 'SAW' in f.name]\n",
    "print(len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "criminal-holly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SAC-2015-00882'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0].name[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "framed-matthew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(train_X[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "played-pavilion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_label(da_num_i, df_merged = df_merged):\n",
    "    return int(df_merged[df_merged.da_num == da_num_i].cwa_determination.iloc[0])\n",
    "get_label(train_X[0].name[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "convinced-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = [get_label(x.name[:-4]) for x in train_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "respective-interference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408 1408\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X), len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "southwest-reality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_3d(p):\n",
    "    x = np.load(p)\n",
    "    return np.concatenate([x,x,x]).reshape(256,256,3)\n",
    "load_3d(train_X[9]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "hourly-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_train_X = [load_3d(f).reshape(-1,256,256,3) for f in train_X]\n",
    "arr_train_X = [x + .756 for x in arr_train_X]\n",
    "arr_train_X = [x * 1/1.5 for x in arr_train_X]\n",
    "\n",
    "#arr_train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "neutral-depth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408\n",
      "1408\n",
      "0.4921875\n"
     ]
    }
   ],
   "source": [
    "print(len(arr_train_X))\n",
    "print(len(train_y))\n",
    "print(np.mean(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-advertising",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "marked-jacket",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33262303"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = [np.mean(x) for x in arr_train_X]\n",
    "np.nanmean(means)\n",
    "#for x in arr_train_X:\n",
    "#    if np.isnan(np.mean(x)):\n",
    "#        print(x)\n",
    "#        for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "described-garden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 3)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_train_X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "promotional-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the images with vgg16\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "vgg16_model1 = VGG16(include_top=False, weights='imagenet', input_shape=(256,256, 3))\n",
    "transformed = [vgg16_model1.predict(x) for x in arr_train_X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "controlled-master",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "industrial-amino",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8, 8, 512)\n",
      "0.0\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "type(transformed[0])\n",
    "print(transformed[0].shape)\n",
    "print(np.min(transformed[0]))\n",
    "print(transformed[0][0,2,6,12:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "exterior-establishment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'stdev')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#investigate transformed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "m = [np.mean(x) for x in transformed]\n",
    "s = [np.std(x) for x in transformed]\n",
    "fig, ax = plt.subplots(2, figsize = (7,7))\n",
    "ax[0].hist(m)\n",
    "ax[0].set_title('mean')\n",
    "ax[1].hist(s)\n",
    "ax[1].set_title('stdev')\n",
    "#mos = np.mean([np.std(x) for x in transformed])\n",
    "#sos = np.std([np.std(x) for x in transformed])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "flexible-terrorist",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Seqential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-b0f72d840da4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtop_model_vgg16\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtop_model_vgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeqential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16_model1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtop_model_vgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtop_model_vgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Seqential' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Concatenate, Input, Lambda, Flatten, Softmax, BatchNormalization, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "top_model_vgg16 = Sequential()\n",
    "top_model_vgg16.add(Seqential(vgg16_model1))\n",
    "top_model_vgg16.add(Dense(512,activation='relu', input_shape=(8,8,512,)))\n",
    "top_model_vgg16.add(LeakyReLU(alpha = 0.1))\n",
    "top_model_vgg16.add(BatchNormalization())\n",
    "#top_model_vgg16.add(Dropout(0.5))\n",
    "\n",
    "#top_model_vgg16.add(Dense(512, activation='relu'))\n",
    "#top_model_vgg16.add(LeakyReLU(alpha = 0.1))\n",
    "#top_model_vgg16.add(BatchNormalization())\n",
    "#top_model_vgg16.add(Dropout(0.2))\n",
    "\n",
    "#top_model_vgg16.add(Dense(256, activation='relu'))\n",
    "#top_model_vgg16.add(LeakyReLU(alpha = 0.1))\n",
    "#top_model_vgg16.add(BatchNormalization())\n",
    "#top_model_vgg16.add(Dropout(0.5))\n",
    "\n",
    "top_model_vgg16.add(Dense(256, activation='relu'))\n",
    "top_model_vgg16.add(LeakyReLU(alpha = 0.1))\n",
    "top_model_vgg16.add(BatchNormalization())\n",
    "#top_model_vgg16.add(Dropout(0.2))\n",
    "\n",
    "top_model_vgg16.add(Dense(128, activation='relu'))\n",
    "top_model_vgg16.add(LeakyReLU(alpha = 0.1))\n",
    "top_model_vgg16.add(BatchNormalization())\n",
    "#top_model_vgg16.add(Dropout(0.5))\n",
    "\n",
    "#top_model_vgg16.add(Dense(128, activation='relu'))\n",
    "#top_model_vgg16.add(LeakyReLU(alpha = 0.1))\n",
    "#top_model_vgg16.add(BatchNormalization())\n",
    "#top_model_vgg16.add(Dropout(0.2))\n",
    "\n",
    "#top_model_vgg16.add(Dense(64, activation='relu'))\n",
    "#top_model_vgg16.add(LeakyReLU(alpha = 0.1))\n",
    "#top_model_vgg16.add(BatchNormalization())\n",
    "#top_model_vgg16.add(Dropout(0.5))\n",
    "\n",
    "#top_model_vgg16.add(Dense(64, activation='relu'))\n",
    "#model.add(LeakyReLU(alpha = 0.1))\n",
    "#model.add(BatchNormalization())\n",
    "#top_model_vgg16.add(Dropout(0.2))\n",
    "\n",
    "#top_model_vgg16.add(Dense(32, activation='relu'))\n",
    "#model.add(LeakyReLU(alpha = 0.1))\n",
    "#model.add(BatchNormalization())\n",
    "#top_model_vgg16.add(Dropout(0.5))\n",
    "\n",
    "top_model_vgg16.add(Flatten())\n",
    "#top_model_vgg16.add(Dense(32,activation='relu'))\n",
    "#top_model_vgg16.add(Dropout(0.2))\n",
    "top_model_vgg16.add(Dense(1, activation = 'sigmoid')), \n",
    "\n",
    "#top_model_vgg16.add(Softmax())\n",
    "\n",
    "top_model_vgg16.summary()\n",
    "\n",
    "top_model_vgg16.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "downtown-monte",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1408, 8, 8, 512) (1408,)\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2670 - accuracy: 0.9352 - val_loss: 0.6913 - val_accuracy: 0.5177\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2593 - accuracy: 0.9538 - val_loss: 0.6921 - val_accuracy: 0.5142\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2494 - accuracy: 0.9636 - val_loss: 0.6918 - val_accuracy: 0.5213\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.2976 - accuracy: 0.8925 - val_loss: 0.6914 - val_accuracy: 0.5177\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.2800 - accuracy: 0.8934 - val_loss: 0.6991 - val_accuracy: 0.5213\n",
      "Train time: 1.5748374462127686\n"
     ]
    }
   ],
   "source": [
    "train_X_transform, train_y = np.array(transformed).reshape(-1,8,8,512), np.array(train_y)\n",
    "print(train_X_transform.shape, train_y.shape)\n",
    "# Train the top model with the vgg16 extracted feature\n",
    "t0 = time.time()\n",
    "top_model_vgg16.fit(train_X_transform, train_y, epochs=5, batch_size=412, validation_split = 0.2)\n",
    "print(\"Train time:\", time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "hundred-season",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4921875"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-instrument",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "accessible-vacation",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5530647 ],\n",
       "       [0.615571  ],\n",
       "       [0.6014415 ],\n",
       "       [0.5732824 ],\n",
       "       [0.4842569 ],\n",
       "       [0.554946  ],\n",
       "       [0.6046836 ],\n",
       "       [0.56508374],\n",
       "       [0.6013986 ],\n",
       "       [0.57375604],\n",
       "       [0.5620803 ],\n",
       "       [0.53165287],\n",
       "       [0.5759678 ],\n",
       "       [0.58225673],\n",
       "       [0.5950668 ],\n",
       "       [0.62529445],\n",
       "       [0.5620189 ],\n",
       "       [0.57533544],\n",
       "       [0.572263  ],\n",
       "       [0.5560221 ],\n",
       "       [0.55870026],\n",
       "       [0.5573043 ],\n",
       "       [0.55465055],\n",
       "       [0.57555956],\n",
       "       [0.5653618 ],\n",
       "       [0.57306963],\n",
       "       [0.55964386],\n",
       "       [0.53954643],\n",
       "       [0.6060331 ],\n",
       "       [0.5832075 ],\n",
       "       [0.56680524],\n",
       "       [0.5818143 ],\n",
       "       [0.53141016],\n",
       "       [0.5784481 ],\n",
       "       [0.5637895 ],\n",
       "       [0.5815287 ],\n",
       "       [0.5837059 ],\n",
       "       [0.5913999 ],\n",
       "       [0.5827023 ],\n",
       "       [0.5478481 ],\n",
       "       [0.59595424],\n",
       "       [0.579196  ],\n",
       "       [0.5560963 ],\n",
       "       [0.5728743 ],\n",
       "       [0.57457125],\n",
       "       [0.5835815 ],\n",
       "       [0.53326875],\n",
       "       [0.54810613],\n",
       "       [0.57877684],\n",
       "       [0.56568384],\n",
       "       [0.56455725],\n",
       "       [0.55815375],\n",
       "       [0.6648496 ],\n",
       "       [0.55735546],\n",
       "       [0.606847  ],\n",
       "       [0.59790283],\n",
       "       [0.5781919 ],\n",
       "       [0.56378   ],\n",
       "       [0.5769045 ],\n",
       "       [0.586174  ],\n",
       "       [0.59529495],\n",
       "       [0.58150715],\n",
       "       [0.5332414 ],\n",
       "       [0.55226785],\n",
       "       [0.58199084],\n",
       "       [0.58423936],\n",
       "       [0.52807164],\n",
       "       [0.58277476],\n",
       "       [0.53819454],\n",
       "       [0.56278825],\n",
       "       [0.5503381 ],\n",
       "       [0.54826486],\n",
       "       [0.5787526 ],\n",
       "       [0.5717738 ],\n",
       "       [0.5602562 ],\n",
       "       [0.5700914 ],\n",
       "       [0.5574767 ],\n",
       "       [0.6317111 ],\n",
       "       [0.5858987 ],\n",
       "       [0.54737765],\n",
       "       [0.57694167],\n",
       "       [0.5568702 ],\n",
       "       [0.5788775 ],\n",
       "       [0.57043123],\n",
       "       [0.60381794],\n",
       "       [0.5711704 ],\n",
       "       [0.6058297 ],\n",
       "       [0.58179617],\n",
       "       [0.54704887],\n",
       "       [0.6258546 ],\n",
       "       [0.5407729 ],\n",
       "       [0.5837732 ],\n",
       "       [0.5745831 ],\n",
       "       [0.59581107],\n",
       "       [0.5704006 ],\n",
       "       [0.56582433],\n",
       "       [0.57545644],\n",
       "       [0.59406805],\n",
       "       [0.62595713],\n",
       "       [0.6157291 ],\n",
       "       [0.61649764],\n",
       "       [0.5700812 ],\n",
       "       [0.53435534],\n",
       "       [0.6189353 ],\n",
       "       [0.53944397],\n",
       "       [0.57439363],\n",
       "       [0.6441223 ],\n",
       "       [0.5414695 ],\n",
       "       [0.55486333],\n",
       "       [0.55986315],\n",
       "       [0.56856984],\n",
       "       [0.58029526],\n",
       "       [0.651303  ],\n",
       "       [0.58184177],\n",
       "       [0.58190197],\n",
       "       [0.57716244],\n",
       "       [0.5845856 ],\n",
       "       [0.62210935],\n",
       "       [0.5600144 ],\n",
       "       [0.5840782 ],\n",
       "       [0.62571603],\n",
       "       [0.5660146 ],\n",
       "       [0.5824674 ],\n",
       "       [0.57530266],\n",
       "       [0.5998546 ],\n",
       "       [0.57765484],\n",
       "       [0.5727911 ],\n",
       "       [0.5756607 ],\n",
       "       [0.6327347 ],\n",
       "       [0.5970737 ],\n",
       "       [0.578701  ],\n",
       "       [0.57668346],\n",
       "       [0.65228003],\n",
       "       [0.55816644],\n",
       "       [0.6331391 ],\n",
       "       [0.57145053],\n",
       "       [0.5798183 ],\n",
       "       [0.5560728 ],\n",
       "       [0.58908963],\n",
       "       [0.557591  ],\n",
       "       [0.67537874],\n",
       "       [0.56480557],\n",
       "       [0.5846307 ],\n",
       "       [0.56363773],\n",
       "       [0.5690551 ],\n",
       "       [0.55017835],\n",
       "       [0.631886  ],\n",
       "       [0.5580985 ],\n",
       "       [0.5476348 ],\n",
       "       [0.5600062 ],\n",
       "       [0.56559294],\n",
       "       [0.6626806 ],\n",
       "       [0.55690914],\n",
       "       [0.5897762 ],\n",
       "       [0.56170636],\n",
       "       [0.6131226 ],\n",
       "       [0.5746442 ],\n",
       "       [0.51221865],\n",
       "       [0.60772765],\n",
       "       [0.6100602 ],\n",
       "       [0.5493083 ],\n",
       "       [0.5200192 ],\n",
       "       [0.5205707 ],\n",
       "       [0.5828262 ],\n",
       "       [0.5828626 ],\n",
       "       [0.6105032 ],\n",
       "       [0.61078805],\n",
       "       [0.6054373 ],\n",
       "       [0.565041  ],\n",
       "       [0.68577313],\n",
       "       [0.5713566 ],\n",
       "       [0.5239842 ],\n",
       "       [0.5783792 ],\n",
       "       [0.5583161 ],\n",
       "       [0.6068714 ],\n",
       "       [0.5336856 ],\n",
       "       [0.5670593 ],\n",
       "       [0.5806231 ],\n",
       "       [0.6161782 ],\n",
       "       [0.5752677 ],\n",
       "       [0.56561244],\n",
       "       [0.58658147],\n",
       "       [0.5179639 ],\n",
       "       [0.5856977 ],\n",
       "       [0.5971903 ],\n",
       "       [0.592253  ],\n",
       "       [0.55103666],\n",
       "       [0.64620906],\n",
       "       [0.56490344],\n",
       "       [0.554838  ],\n",
       "       [0.5565577 ],\n",
       "       [0.5685502 ],\n",
       "       [0.57776886],\n",
       "       [0.5733606 ],\n",
       "       [0.56063765],\n",
       "       [0.56038743],\n",
       "       [0.598231  ],\n",
       "       [0.5418753 ],\n",
       "       [0.56792885],\n",
       "       [0.55348015],\n",
       "       [0.5532133 ],\n",
       "       [0.5876627 ],\n",
       "       [0.5494259 ],\n",
       "       [0.5780151 ],\n",
       "       [0.5524764 ],\n",
       "       [0.5692893 ],\n",
       "       [0.61612666],\n",
       "       [0.5605576 ],\n",
       "       [0.543754  ],\n",
       "       [0.57424533],\n",
       "       [0.5722189 ],\n",
       "       [0.56924874],\n",
       "       [0.6136579 ],\n",
       "       [0.60942984],\n",
       "       [0.55539083],\n",
       "       [0.56616193],\n",
       "       [0.54532963],\n",
       "       [0.5557022 ],\n",
       "       [0.5691414 ],\n",
       "       [0.58442974],\n",
       "       [0.567609  ],\n",
       "       [0.60501736],\n",
       "       [0.5505299 ],\n",
       "       [0.5789358 ],\n",
       "       [0.55677634],\n",
       "       [0.5397285 ],\n",
       "       [0.5966326 ],\n",
       "       [0.5702868 ],\n",
       "       [0.59422654],\n",
       "       [0.55556345],\n",
       "       [0.65772235],\n",
       "       [0.5667566 ],\n",
       "       [0.61535627],\n",
       "       [0.5603374 ],\n",
       "       [0.6730223 ],\n",
       "       [0.6517663 ],\n",
       "       [0.56866586],\n",
       "       [0.5564937 ],\n",
       "       [0.55670244],\n",
       "       [0.56657827],\n",
       "       [0.5741668 ],\n",
       "       [0.5962917 ],\n",
       "       [0.5961351 ],\n",
       "       [0.57800937],\n",
       "       [0.6170856 ],\n",
       "       [0.5685847 ],\n",
       "       [0.6829494 ],\n",
       "       [0.5525831 ],\n",
       "       [0.5659024 ],\n",
       "       [0.5635894 ],\n",
       "       [0.57634133],\n",
       "       [0.5563984 ],\n",
       "       [0.53156894],\n",
       "       [0.58290243],\n",
       "       [0.5718139 ],\n",
       "       [0.63053995],\n",
       "       [0.5827369 ],\n",
       "       [0.55211264],\n",
       "       [0.5673414 ],\n",
       "       [0.5620697 ],\n",
       "       [0.6400974 ],\n",
       "       [0.5833753 ],\n",
       "       [0.579071  ],\n",
       "       [0.5664433 ],\n",
       "       [0.56899935],\n",
       "       [0.62372726],\n",
       "       [0.59190595],\n",
       "       [0.5891178 ],\n",
       "       [0.6105542 ],\n",
       "       [0.58511573],\n",
       "       [0.54799765],\n",
       "       [0.53759545],\n",
       "       [0.66410595],\n",
       "       [0.5669467 ],\n",
       "       [0.58233005],\n",
       "       [0.6215597 ],\n",
       "       [0.5851715 ],\n",
       "       [0.58567953],\n",
       "       [0.6183305 ],\n",
       "       [0.52996343],\n",
       "       [0.6501848 ],\n",
       "       [0.5825376 ],\n",
       "       [0.5687369 ],\n",
       "       [0.67434895],\n",
       "       [0.56582105],\n",
       "       [0.56895417],\n",
       "       [0.5516438 ],\n",
       "       [0.5611828 ],\n",
       "       [0.582368  ],\n",
       "       [0.569611  ],\n",
       "       [0.64326   ],\n",
       "       [0.5464746 ],\n",
       "       [0.57037765],\n",
       "       [0.5616936 ],\n",
       "       [0.5584628 ],\n",
       "       [0.58533394],\n",
       "       [0.58887035],\n",
       "       [0.5603146 ],\n",
       "       [0.5660129 ],\n",
       "       [0.55516976],\n",
       "       [0.56772286],\n",
       "       [0.56974274],\n",
       "       [0.6596897 ],\n",
       "       [0.60919756],\n",
       "       [0.58663875],\n",
       "       [0.5709391 ],\n",
       "       [0.5748838 ],\n",
       "       [0.6283764 ],\n",
       "       [0.58261347],\n",
       "       [0.5754263 ],\n",
       "       [0.5465569 ],\n",
       "       [0.5838669 ],\n",
       "       [0.57364154],\n",
       "       [0.5755816 ],\n",
       "       [0.5333522 ],\n",
       "       [0.5447541 ],\n",
       "       [0.6607942 ],\n",
       "       [0.5734321 ],\n",
       "       [0.58492386],\n",
       "       [0.568957  ],\n",
       "       [0.6105761 ],\n",
       "       [0.56737334],\n",
       "       [0.5572893 ],\n",
       "       [0.5734615 ],\n",
       "       [0.55563873],\n",
       "       [0.5920269 ],\n",
       "       [0.5505579 ],\n",
       "       [0.56619143],\n",
       "       [0.56107676],\n",
       "       [0.58130294],\n",
       "       [0.5931358 ],\n",
       "       [0.5798751 ],\n",
       "       [0.5547377 ],\n",
       "       [0.5599513 ],\n",
       "       [0.5634459 ],\n",
       "       [0.6182091 ],\n",
       "       [0.60149795],\n",
       "       [0.58039623],\n",
       "       [0.5928301 ],\n",
       "       [0.5908407 ],\n",
       "       [0.6051846 ],\n",
       "       [0.58011   ],\n",
       "       [0.57309705],\n",
       "       [0.58346593],\n",
       "       [0.5824792 ],\n",
       "       [0.5970983 ],\n",
       "       [0.62357956],\n",
       "       [0.57543683],\n",
       "       [0.57235324],\n",
       "       [0.5769067 ],\n",
       "       [0.5388696 ],\n",
       "       [0.56846476],\n",
       "       [0.59512776],\n",
       "       [0.5442685 ],\n",
       "       [0.55865747],\n",
       "       [0.5826464 ],\n",
       "       [0.64946127],\n",
       "       [0.6142613 ],\n",
       "       [0.56876075],\n",
       "       [0.5666175 ],\n",
       "       [0.57378674],\n",
       "       [0.6241001 ],\n",
       "       [0.54898924],\n",
       "       [0.5853549 ],\n",
       "       [0.5912474 ],\n",
       "       [0.5475426 ],\n",
       "       [0.53288436],\n",
       "       [0.61701393],\n",
       "       [0.5370322 ],\n",
       "       [0.56938237],\n",
       "       [0.5563259 ],\n",
       "       [0.56432235],\n",
       "       [0.5526506 ],\n",
       "       [0.61914265],\n",
       "       [0.6454188 ],\n",
       "       [0.605885  ],\n",
       "       [0.58344674],\n",
       "       [0.5841512 ],\n",
       "       [0.576921  ],\n",
       "       [0.66215044],\n",
       "       [0.5568108 ],\n",
       "       [0.55826074],\n",
       "       [0.5489555 ],\n",
       "       [0.57363963],\n",
       "       [0.567692  ],\n",
       "       [0.54345584],\n",
       "       [0.55533236],\n",
       "       [0.55859905],\n",
       "       [0.55020636],\n",
       "       [0.5640053 ],\n",
       "       [0.6019899 ],\n",
       "       [0.60909337],\n",
       "       [0.59707886],\n",
       "       [0.6040138 ],\n",
       "       [0.57257086],\n",
       "       [0.56954473],\n",
       "       [0.62326944],\n",
       "       [0.55258536],\n",
       "       [0.5521789 ],\n",
       "       [0.58612293],\n",
       "       [0.5626857 ],\n",
       "       [0.63707155],\n",
       "       [0.5716793 ],\n",
       "       [0.6066361 ],\n",
       "       [0.5630886 ],\n",
       "       [0.5821376 ],\n",
       "       [0.61356974],\n",
       "       [0.5297375 ],\n",
       "       [0.5465027 ],\n",
       "       [0.5899393 ],\n",
       "       [0.5500964 ],\n",
       "       [0.5370764 ]], dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model_vgg16.predict(train_X_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-martial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "quantitative-swiss",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_27 (Flatten)         (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 512)               16777728  \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 16,778,241\n",
      "Trainable params: 16,778,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# baseline model\n",
    "# create model\n",
    "model22 = Sequential()\n",
    "model22.add(Flatten(input_shape=(8,8,512,)))\n",
    "model22.add(Dense(512,activation='relu'))\n",
    "model22.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model22.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model22.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "experienced-symphony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412, 8, 8, 512) (412,)\n"
     ]
    }
   ],
   "source": [
    "train_X_transform, train_y = np.array(transformed).reshape(412,8,8,512), np.array(train_y)\n",
    "print(train_X_transform.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "detailed-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 8.4017 - accuracy: 0.4837\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 3.2754 - accuracy: 0.5078\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9847 - accuracy: 0.5128\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.1488 - accuracy: 0.4922\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7131 - accuracy: 0.5213\n",
      "Train time: 1.3266499042510986\n"
     ]
    }
   ],
   "source": [
    "# Train the top model with the vgg16 extracted features\n",
    "t0 = time.time()\n",
    "model22.fit(train_X_transform, train_y, epochs=5, batch_size=412)#, validation_split = 0.2)\n",
    "print(\"Train time:\", time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-secret",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "shaped-quantity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 11 01:47:18 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   46C    P0    71W / 149W |  10877MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "whole-operations",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "vgg16_model1 = VGG16(include_top=False, weights='imagenet', input_shape=(256,256, 3))\n",
    "#vgg16_model2 = VGG16(include_top=False, weights='imagenet', input_shape=(256,256, 3))\n",
    "#vgg16_model3 = VGG16(include_top=False, weights='imagenet', input_shape=(256,256, 3))\n",
    "\n",
    "vgg16_model1.trainable = False\n",
    "#vgg16_model2.trainable = False\n",
    "#vgg16_model3.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "atmospheric-least",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256, 256, 3)\n",
      "(None, 8, 8, 512)\n",
      "(None, 8, 8, 10)\n",
      "(None, 640)\n",
      "(None, 10)\n",
      "(None, 2)\n",
      "(None, 2)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Concatenate, Input, Lambda, Flatten, Softmax\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "num_channels = 3\n",
    "input = Input(shape=(256,256, num_channels))\n",
    "\n",
    "branch_outputs = []\n",
    "\n",
    "# loop for however many branches you want to use.  (each branch needs 3 channel depth)\n",
    "\n",
    "# create looping so that vgg16 model input is created ie 256,256,3\n",
    "print(input.shape)\n",
    "#out = Lambda(lambda x: x[:,:,:,i:i+3])(input)\n",
    "#print(out.shape)\n",
    "\n",
    "# Setting up your layers in each branch: (currently each branch is identical architecture.)\n",
    "out = Sequential(vgg16_model1)(input)   # use pretrained and loaded vgg16\n",
    "\n",
    "print(out.shape)\n",
    "out = Dense(10)(out)\n",
    "print(out.shape)\n",
    "out = Flatten()(out)\n",
    "print(out.shape)\n",
    "branch_outputs.append(out)\n",
    "\n",
    "# Concatenating the branches outputs:\n",
    "#out = Concatenate()(branch_outputs)\n",
    "#print(out.shape)\n",
    "\n",
    "# Add final dense layers and softmax\n",
    "out = Dense(20)(out)\n",
    "out = Dense(10)(out)\n",
    "print(out.shape)\n",
    "out = Dense(6)(out)\n",
    "out = Dense(2)(out)\n",
    "print(out.shape)\n",
    "out = Softmax()(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "christian-hamburg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 8, 8, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 8, 8, 10)          5130      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 20)                12820     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 14        \n",
      "_________________________________________________________________\n",
      "softmax_4 (Softmax)          (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 14,732,928\n",
      "Trainable params: 18,240\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=input, outputs=out)   \n",
    "model.summary()\n",
    "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "previous-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "statewide-identifier",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 3)\n",
      "[[0.1622066  0.83779347]]\n",
      "time taken: 6.368284225463867 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "test_input = np.random.rand(256,256,3)\n",
    "test_input = test_input.reshape(1, 256,256, 3)\n",
    "print(test_input.shape)\n",
    "t0 = time.time()\n",
    "print(model.predict(test_input))\n",
    "print(f\"time taken: {time.time()-t0} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "affiliated-share",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6/6 [==============================] - 4s 590ms/step - loss: 7.6871 - accuracy: 0.2888 - val_loss: 7.6871 - val_accuracy: 0.2892\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 3s 543ms/step - loss: 7.6871 - accuracy: 0.2888 - val_loss: 7.6871 - val_accuracy: 0.2892\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 7.6871 - accuracy: 0.2888 - val_loss: 7.6871 - val_accuracy: 0.2892\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 3s 542ms/step - loss: 7.6871 - accuracy: 0.2888 - val_loss: 7.6871 - val_accuracy: 0.2892\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 3s 542ms/step - loss: 7.6871 - accuracy: 0.2888 - val_loss: 7.6871 - val_accuracy: 0.2892\n",
      "Train time: 20.48793864250183\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "model.fit(arr_train_X, arr_train_y, epochs=5, batch_size=64, validation_split = 0.2)#, workers=4, use_multiprocessing=True)\n",
    "print(\"Train time:\", time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "egyptian-inclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 8, 8, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8, 8, 10)          5130      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 20)                12820     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 126       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 14        \n",
      "_________________________________________________________________\n",
      "softmax_2 (Softmax)          (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 14,732,778\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 18,090\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_layer = model.get_layer(name='sequential_2', index=None)\n",
    "#model.get_layer(name='dense_8', index=None).trainable = False\n",
    "model.get_layer(name='dense_9', index=None).trainable = False\n",
    "model.get_layer(name='dense_10', index=None).trainable = False\n",
    "model.get_layer(name='dense_11', index=None).trainable = False\n",
    "model.get_layer(name='dense_12', index=None).trainable = False\n",
    "\n",
    "vgg_layer.trainable = True\n",
    "model.summary()\n",
    "opt = keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "hydraulic-newman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/9 [=====>........................] - ETA: 1s - loss: 7.6795 - accuracy: 0.6250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1532s vs `on_train_batch_end` time: 0.3289s). Check your callbacks.\n",
      "9/9 [==============================] - 15s 2s/step - loss: 7.6771 - accuracy: 0.5970 - val_loss: 7.6763 - val_accuracy: 0.5882\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 4s 480ms/step - loss: 7.6771 - accuracy: 0.5970 - val_loss: 7.6763 - val_accuracy: 0.5882\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 4s 481ms/step - loss: 7.6771 - accuracy: 0.5970 - val_loss: 7.6763 - val_accuracy: 0.5882\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 4s 481ms/step - loss: 7.6771 - accuracy: 0.5970 - val_loss: 7.6763 - val_accuracy: 0.5882\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 4s 479ms/step - loss: 7.6771 - accuracy: 0.5970 - val_loss: 7.6763 - val_accuracy: 0.5882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9c3eb82278>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(arr_train_X, arr_train_y, epochs=5, batch_size=16, validation_split = 0.2)#, workers=4, use_multiprocessing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-encounter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-object",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cardiac-population",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5952380952380952"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(arr_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aware-banana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.1937740e-31]\n",
      " [1.0000000e+00 1.2457646e-30]\n",
      " [1.0000000e+00 3.6220060e-25]\n",
      " [1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "x = model.predict_on_batch(arr_train_X[:10])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-storm",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
