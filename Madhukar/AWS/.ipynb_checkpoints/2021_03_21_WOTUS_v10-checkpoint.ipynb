{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gh39s2KK_dGM"
   },
   "source": [
    "- v1: works till the categorical pipeline where it errors out for unknown variables\n",
    "- v2: fully functional\n",
    "- v3: baseline run (on the old dataset)\n",
    "- v4: baseline run (on the full 2021.03.17_full_dataset)\n",
    "- v5: baseline run (on 2021.03.19_full_dataset with all SSURGO variables)\n",
    "- v6: aoc_roc (on 2021.03.19_full_dataset with all SSURGO variables). Mute the Stacking as it is not possible with RandomizedSearchCV. Have to have a dev split.\n",
    "- v7: model v7 random state 123 on train/test, model v7.1 random_state 431 on train/dev/test\n",
    "- v8g: Golden model\n",
    "\n",
    "- ROC_AUC with lat, lon (baseline)\n",
    "====================\n",
    "lr:           0.64103\n",
    "xgb:          0.82366\n",
    "voting_clf:   0.83027\n",
    "lgbm:         0.86395\n",
    "stacking:     0.85923\n",
    "\n",
    "\n",
    "- v9: without lat, lon\n",
    "\n",
    "- ROC_AUC without lat, lon\n",
    "=======================\n",
    "lr:           0.64211\n",
    "xgb:          0.8031\n",
    "voting_clf:   0.83105\n",
    "lgbm:         0.85952\n",
    "stacking:     0.85427\n",
    "\n",
    "- v9.1: without lat, lon, potential_wetland\n",
    "\n",
    "- ROC_AUC without lat, lon, potential_wetland\n",
    "===============\n",
    "lr:           0.63992\n",
    "xgb:          0.79093\n",
    "voting_clf:   0.82987\n",
    "lgbm:         0.85143\n",
    "stacking:     0.84328\n",
    "\n",
    "- v9.2: without lat, lon, potential_wetland, district\n",
    "\n",
    "- ROC_AUC without lat, lon, potential_wetland, district\n",
    "===============\n",
    "lr:           0.64208\n",
    "xgb:          0.77907\n",
    "voting_clf:   0.79829\n",
    "lgbm:         0.82675\n",
    "stacking:     0.82185\n",
    "\n",
    "- v9.3: without lat, lon, potential_wetland, district and flodfreqdc and drclassdcd as ordinal\n",
    "\n",
    "- ROC_AUC on Test\n",
    "===============\n",
    "lr:           0.6382\n",
    "xgb:          0.73089\n",
    "voting_clf:   0.79126\n",
    "lgbm:         0.82512\n",
    "stacking:     0.8195\n",
    "\n",
    "- v9.4: without lat, lon, potential_wetland, district, county \n",
    "- ROC_AUC on Test\n",
    "===============\n",
    "lr:           0.6395\n",
    "xgb:          0.74096\n",
    "voting_clf:   0.7911\n",
    "lgbm:         0.82448\n",
    "stacking:     0.82343\n",
    "\n",
    "- v9.5: without lat, lon, potential_wetland, district, county, mukey\n",
    "- ROC_AUC on Test\n",
    "===============\n",
    "lr:           0.65309\n",
    "xgb:          0.75117\n",
    "voting_clf:   0.77845\n",
    "lgbm:         0.80626\n",
    "stacking:     0.80424\n",
    "\n",
    "- v9.5: without lat, lon, potential_wetland, district, county, mukey, and filtering out bad latitude\n",
    "THIS IS SUSPECT. CANT REPEAT IT.\n",
    "- ROC_AUC on Test\n",
    "===============\n",
    "lr:           0.63894\n",
    "xgb:          0.74922\n",
    "voting_clf:   0.79839\n",
    "lgbm:         0.86986\n",
    "stacking:     0.86281\n",
    "\n",
    "- v9,5_r2: supposed to be repeat of v9.5 but unsuccessful (probably bcoz of wrong cat features)\n",
    "- ROC_AUC on Test\n",
    "===============\n",
    "lr:           0.64148\n",
    "xgb:          0.7066\n",
    "lgbm:         0.79702\n",
    "stacking:     0.78626\n",
    "voting_clf:   0.7632\n",
    "\n",
    "- ROC_AUC on Test\n",
    "===============\n",
    "lr:           0.62669\n",
    "xgb:          0.71814\n",
    "lgbm:         0.8006\n",
    "stacking:     0.80005\n",
    "voting_clf:   0.7683\n",
    "\n",
    "- v9.6: baseline and filtering out bad latitude\n",
    "- ROC_AUC on Test\n",
    "===============\n",
    "lr:           0.6306\n",
    "xgb:          0.79659\n",
    "voting_clf:   0.82816\n",
    "lgbm:         0.85251\n",
    "stacking:     0.84547\n",
    "\n",
    "- v9.6_r2: baseline and filtering out bad latitude\n",
    "- ROC_AUC on Test\n",
    "===============\n",
    "lr:           0.6302\n",
    "xgb:          0.81153\n",
    "voting_clf:   0.83019\n",
    "lgbm:         0.85353\n",
    "stacking:     0.85285\n",
    "\n",
    "\n",
    "- ROC_AUC with lat, lon (baseline)\n",
    "====================\n",
    "lr:           0.64103\n",
    "xgb:          0.82366\n",
    "voting_clf:   0.83027\n",
    "lgbm:         0.86395\n",
    "stacking:     0.85923\n",
    "\n",
    "- v9.4: without lat, lon, potential_wetland, district, county \n",
    "- ROC_AUC on Test\n",
    "===============\n",
    "lr:           0.6395\n",
    "xgb:          0.74096\n",
    "voting_clf:   0.7911\n",
    "lgbm:         0.82448\n",
    "stacking:     0.82343\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "file_param_dict = {}\n",
    "golden_models = [\"v8g\"]\n",
    "\n",
    "# file params\n",
    "stop_before_models = False\n",
    "random_state = 123 # for train, dev, test splits\n",
    "dev = True\n",
    "\n",
    "FILE_VERSION = \"v10\"\n",
    "run_models = True # BEWARE! This overwrites the models stored on disk\n",
    "run_logistic = True\n",
    "\n",
    "if FILE_VERSION in golden_models:\n",
    "    if run_models:\n",
    "        turn_off_run_models\n",
    "\n",
    "file_param_dict[\"random_state\"] = random_state\n",
    "file_param_dict[\"dev\"] = dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wj4LjNpHOzc9",
    "outputId": "6b01c399-d6fc-46c6-f622-ac200674afb8"
   },
   "outputs": [],
   "source": [
    "# !pip install lightgbm\n",
    "# !pip install xgboost\n",
    "# !pip install mlxtend\n",
    "# !pip install seaborn\n",
    "# !pip install shapely\n",
    "# !pip install geopandas\n",
    "\n",
    "# import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "y6CJ-2pyO-Pu"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "# from shapely.geometry import Point\n",
    "# import geopandas as gpd\n",
    "# from geopandas import GeoDataFrame\n",
    "\n",
    "\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# SK-learn libraries for machine learning\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import *\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import xgboost\n",
    "import lightgbm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "id": "1q95q-9wPEky"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14619, 494)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_pickle(\"../../../data/2021.03.23_full_dataset\")\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flod_ordered = [\"None\", \"Very rare\", \"Rare\", \"Occasional\", \"Frequent\", \"Very frequent\"]\n",
    "# flod_dict = dict(zip(flod_ordered, range(len(flod_ordered))))\n",
    "\n",
    "# def flodfreqdc_ordinal(string):\n",
    "#     try:\n",
    "#         return flod_dict[string]\n",
    "#     except:\n",
    "#         return np.nan\n",
    "    \n",
    "    \n",
    "# df_full[\"flodfreqdc\"] = df_full.apply(lambda x: flodfreqdc_ordinal(x.flodfreqdc), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drclassdcd_ordered = [\"Excessively drained\", \"Somewhat excessively drained\", \"Well drained\", \n",
    "# \"Moderately well drained\", \"Somewhat poorly drained\", \"Poorly drained\", \"Very poorly drained\", \"Subaqueous\"]\n",
    "\n",
    "# drclassdcd_dict = dict(zip(drclassdcd_ordered, range(len(drclassdcd_ordered))))\n",
    "\n",
    "# def drclassdcd_ordinal(string):\n",
    "#     try:\n",
    "#         return drclassdcd_dict[string]\n",
    "#     except:\n",
    "#         return np.nan\n",
    "    \n",
    "# df_full[\"drclassdcd\"] = df_full.apply(lambda x: drclassdcd_ordinal(x.drclassdcd), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14613, 494)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove longitude > -50 (bad datapoints)\n",
    "\n",
    "df_full = df_full[df_full.longitude < -50]\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cwa5', 'cwa1', 'cwa8', 'cwa6', 'rha_determination', 'longitude',\n",
       "       'cwa7', 'potential_wetland', 'district', 'cwa3',\n",
       "       ...\n",
       "       'county', 'state', 'closest_wb_distance_m', 'closest_fl_distance_m',\n",
       "       'closest_fl_area_sqkm', 'closest_wb_area_sqkm', 'closest_fl_elevation',\n",
       "       'closest_wb_elevation', 'huc4', 'huc6'],\n",
       "      dtype='object', length=494)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "vmXibdpmoSgz"
   },
   "outputs": [],
   "source": [
    "# df_full = df_full[df_full.district != \"Alaska\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0iIGqq0DlEz",
    "outputId": "4f42a088-639b-4bf6-84a5-c8a8deefa4a7"
   },
   "outputs": [],
   "source": [
    "# set(df_full.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V4OSS7EfFWLD",
    "outputId": "5cba5f6a-118e-4979-8194-000e45123b90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%good records = 98%\n"
     ]
    }
   ],
   "source": [
    "# any records where the cwa_determination is contrary to expectations?\n",
    "good_records = (df_full.apply(lambda x: \n",
    "               (np.sum(x.cwa1 + x.cwa2 + x.cwa3 + x.cwa4 + x.cwa5 + \n",
    "                       x.cwa6 + x.cwa7 + x.cwa8 + x.cwa9) > 0) * 1 \n",
    "               == x.cwa_determination, \n",
    "               axis=1))\n",
    "\n",
    "print(\"%good records = {}%\".format(round(np.mean(good_records) * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "MUI--cUNFmXp",
    "outputId": "08a07e58-d2a0-4ead-c85a-7e9edbf94883"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cwa5</th>\n",
       "      <th>cwa1</th>\n",
       "      <th>cwa8</th>\n",
       "      <th>cwa6</th>\n",
       "      <th>rha_determination</th>\n",
       "      <th>longitude</th>\n",
       "      <th>cwa7</th>\n",
       "      <th>potential_wetland</th>\n",
       "      <th>district</th>\n",
       "      <th>cwa3</th>\n",
       "      <th>...</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>closest_wb_distance_m</th>\n",
       "      <th>closest_fl_distance_m</th>\n",
       "      <th>closest_fl_area_sqkm</th>\n",
       "      <th>closest_wb_area_sqkm</th>\n",
       "      <th>closest_fl_elevation</th>\n",
       "      <th>closest_wb_elevation</th>\n",
       "      <th>huc4</th>\n",
       "      <th>huc6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-77.58614</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Monroe</td>\n",
       "      <td>36</td>\n",
       "      <td>1.57328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156.193548</td>\n",
       "      <td>0414</td>\n",
       "      <td>041401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-78.89428</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Niagara</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.87247</td>\n",
       "      <td>1.1484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0413</td>\n",
       "      <td>041300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-78.98265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Niagara</td>\n",
       "      <td>36</td>\n",
       "      <td>2.11826</td>\n",
       "      <td>1.20083</td>\n",
       "      <td>3.3237</td>\n",
       "      <td>4.196</td>\n",
       "      <td>194.0</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>0412</td>\n",
       "      <td>041201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 494 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cwa5  cwa1  cwa8  cwa6  rha_determination  longitude  cwa7  \\\n",
       "36     0     0     0     0                  0  -77.58614     0   \n",
       "50     0     0     0     0                  0  -78.89428     0   \n",
       "56     0     0     0     0                  0  -78.98265     0   \n",
       "\n",
       "    potential_wetland district  cwa3  ...   county  state  \\\n",
       "36                  1  Buffalo     0  ...   Monroe     36   \n",
       "50                  1  Buffalo     0  ...  Niagara     36   \n",
       "56                  1  Buffalo     0  ...  Niagara     36   \n",
       "\n",
       "    closest_wb_distance_m  closest_fl_distance_m closest_fl_area_sqkm  \\\n",
       "36                1.57328                    NaN                  NaN   \n",
       "50                    NaN                0.87247               1.1484   \n",
       "56                2.11826                1.20083               3.3237   \n",
       "\n",
       "    closest_wb_area_sqkm closest_fl_elevation  closest_wb_elevation  huc4  \\\n",
       "36                 0.060                  NaN            156.193548  0414   \n",
       "50                   NaN                121.0                   NaN  0413   \n",
       "56                 4.196                194.0            194.000000  0412   \n",
       "\n",
       "      huc6  \n",
       "36  041401  \n",
       "50  041300  \n",
       "56  041201  \n",
       "\n",
       "[3 rows x 494 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek at not good records\n",
    "df_full[~good_records].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wS52NjAa4kE_"
   },
   "source": [
    "# Train-Dev-Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "id": "Tc_mmRYBKxU6"
   },
   "outputs": [],
   "source": [
    "# filter out the bad records\n",
    "\n",
    "df_full = df_full[good_records]\n",
    "\n",
    "if dev:\n",
    "    df, df_test = train_test_split(df_full, test_size=0.2, random_state = random_state) # 20% test\n",
    "    df, df_dev = train_test_split(df, test_size=0.25, random_state = random_state) # 60% train, 20% dev\n",
    "else:\n",
    "    df, df_test = train_test_split(df_full, test_size=0.2, random_state = random_state) # 80% train, 20% test\n",
    "    df_dev = df_test.copy()\n",
    "    \n",
    "# df, df_test = train_test_split(df_full, test_size=0.95, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8592, 494)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bODkeQCDPr24"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Zs23ZZxPtnN"
   },
   "source": [
    "### Remove cols with all NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "id": "vBwbLX6YPwT_"
   },
   "outputs": [],
   "source": [
    "nan_cols = []\n",
    "for col in df.columns:\n",
    "  nan_frac = np.mean(df[str(col)].isna())\n",
    "  if nan_frac == 1:\n",
    "    nan_cols.append(col)\n",
    "nan_cols\n",
    "df.drop(nan_cols, inplace=True, axis=1)\n",
    "\n",
    "# two cols are removed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8592, 492)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxWXqayaFhXp",
    "outputId": "52c2ceb0-fc0c-49ce-8fb4-4050e7c7f778"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"county\" in df_full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlZ2nLgVPOn1"
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xlE_M1C2PIgp",
    "outputId": "af65405c-4220-4fe4-c5b9-c922d395bfde"
   },
   "outputs": [],
   "source": [
    "df_num_features = pd.DataFrame(df.describe().columns)\n",
    "# for count, col in enumerate(df.describe().columns):\n",
    "#   print(count, col)\n",
    "\n",
    "# 5, 7, 14, 17, 19:445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462, 1)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQVQGqHhGkE_"
   },
   "source": [
    "## Numerical Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "viN9PWn5PY7H",
    "outputId": "25a607e3-e822-47b5-908e-ff201a1ac251"
   },
   "outputs": [],
   "source": [
    "# numerical features of interest: \n",
    "imp_num_feature_list = [5, 7, 11] + list(range(17, 30)) + list(range(31, len(df_num_features))) # baseline\n",
    "# imp_num_feature_list = list(range(19, 445))  # v9.5: no lat, lon, potential_wetland, district, mukey\n",
    "\n",
    "\n",
    "imp_num_feature = df_num_features.loc[imp_num_feature_list]\n",
    "imp_num_feature = list(imp_num_feature.values.flatten())\n",
    "\n",
    "file_param_dict[\"imp_num_feature\"] = imp_num_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfKbTgYTGohQ"
   },
   "source": [
    "## Categorical Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'county',\n",
       " 'da_number',\n",
       " 'date_issued_or_denied',\n",
       " 'district',\n",
       " 'drclassdcd',\n",
       " 'drclasswet',\n",
       " 'engcmssdcd',\n",
       " 'engcmssmp',\n",
       " 'engdwbdcd',\n",
       " 'engdwbll',\n",
       " 'engdwbml',\n",
       " 'engdwobdcd',\n",
       " 'englrsdcd',\n",
       " 'engsldcd',\n",
       " 'engsldcp',\n",
       " 'engstafdcd',\n",
       " 'engstafll',\n",
       " 'engstafml',\n",
       " 'flodfreqdc',\n",
       " 'flodfreqma',\n",
       " 'forpehrtdc',\n",
       " 'huc4',\n",
       " 'huc6',\n",
       " 'hydgrpdcd',\n",
       " 'jurisdiction_type',\n",
       " 'mustatus',\n",
       " 'nwi_wetland_list_200m',\n",
       " 'nwi_wetland_list_2500m',\n",
       " 'state',\n",
       " 'urbrecptdc'}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek at categorical features\n",
    "set(df.columns) - set(df.describe().columns)\n",
    "# len(set(df.describe().columns))\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "n5JCwDs_Q8pW"
   },
   "outputs": [],
   "source": [
    "# call out the important categorical features\n",
    "\n",
    "\n",
    "# imp_cat_feature = ['district', 'flodfreqdc', 'drclassdcd', 'county', 'jurisdiction_type'] # baseline\n",
    "# # imp_cat_feature = ['flodfreqdc', 'drclassdcd','jurisdiction_type'] # v9.5 \n",
    "imp_cat_feature = ['county',\n",
    " 'district',\n",
    " 'drclassdcd',\n",
    " 'drclasswet',\n",
    " 'engcmssdcd',\n",
    " 'engcmssmp',\n",
    " 'engdwbdcd',\n",
    " 'engdwbll',\n",
    " 'engdwbml',\n",
    " 'engdwobdcd',\n",
    " 'englrsdcd',\n",
    " 'engsldcd',\n",
    " 'engsldcp',\n",
    " 'engstafdcd',\n",
    " 'engstafll',\n",
    " 'engstafml',\n",
    " 'flodfreqdc',\n",
    " 'flodfreqma',\n",
    " 'forpehrtdc',\n",
    " 'huc6',\n",
    " 'hydgrpdcd',\n",
    " 'jurisdiction_type',\n",
    " 'state',\n",
    " 'urbrecptdc']\n",
    "file_param_dict[\"imp_cat_feature\"] = imp_cat_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VweeykE-4Ter"
   },
   "source": [
    "# Order Train-Dev-Test splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqbXGvZIRHGi",
    "outputId": "6238c23e-8db0-4cc0-fe3c-71f547ef6e6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2865, 471)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-arrange so numerical columns go first, then the categorical\n",
    "df1 = df[imp_num_feature]\n",
    "df2 = df[imp_cat_feature]\n",
    "\n",
    "# train\n",
    "df_X_combined_ordered = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "# dev\n",
    "df_dev_X = pd.concat([df_dev[imp_num_feature], df_dev[imp_cat_feature]], axis=1)\n",
    "\n",
    "\n",
    "# test\n",
    "df_test_X = pd.concat([df_test[imp_num_feature], df_test[imp_cat_feature]], axis=1)\n",
    "\n",
    "\n",
    "df_X_combined_ordered.columns #44\n",
    "df_X_combined_ordered.shape # (10000, 44)\n",
    "df_test_X.shape # (4500, 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude',\n",
       " 'potential_wetland',\n",
       " 'latitude',\n",
       " 'niccdcd',\n",
       " 'aws0100wta',\n",
       " 'wtdepannmi',\n",
       " 'niccdcdpct',\n",
       " 'hydclprs',\n",
       " 'aws025wta',\n",
       " 'wtdepaprju',\n",
       " 'slopegradw',\n",
       " 'iccdcdpct',\n",
       " 'urbrecptwt',\n",
       " 'brockdepmi',\n",
       " 'iccdcd',\n",
       " 'pondfreqpr',\n",
       " 'aws0150wta',\n",
       " 'aws050wta',\n",
       " 'slopegradd',\n",
       " 'awmmfpwwta',\n",
       " 'transition_9_200m',\n",
       " 'recurrence_mean_200m',\n",
       " 'transition_2_200m',\n",
       " 'seasonality_min_200m',\n",
       " 'transition_8_200m',\n",
       " 'transition_5_200m',\n",
       " 'seasonality_stdev_200m',\n",
       " 'seasonality_max_200m',\n",
       " 'recurrence_min_200m',\n",
       " 'recurrence_max_200m',\n",
       " 'transition_7_200m',\n",
       " 'slope_min_200m',\n",
       " 'elevation_min_200m',\n",
       " 'transition_0_200m',\n",
       " 'elevation_mean_200m',\n",
       " 'elevation_max_200m',\n",
       " 'slope_max_200m',\n",
       " 'transition_3_200m',\n",
       " 'transition_4_200m',\n",
       " 'elevation_stdev_200m',\n",
       " 'recurrence_stdev_200m',\n",
       " 'transition_1_200m',\n",
       " 'transition_6_200m',\n",
       " 'slope_stdev_200m',\n",
       " 'seasonality_mean_200m',\n",
       " 'slope_mean_200m',\n",
       " 'wb_area_sum_200m',\n",
       " 'fl_length_sum_200m',\n",
       " 'wb_area_mean_200m',\n",
       " 'fl_intephem_count_200m',\n",
       " 'fl_streamorde_sum_200m',\n",
       " 'wb_ftype_artificialpath_200m',\n",
       " 'fl_ftype_pipeline_200m',\n",
       " 'wb_ftype_canalditch_200m',\n",
       " 'wb_gnis_name_ind_count_200m',\n",
       " 'fl_flow_type_mean_200m',\n",
       " 'wb_ftype_coastline_200m',\n",
       " 'fl_areasqkm_count_200m',\n",
       " 'fl_areasqkm_sum_200m',\n",
       " 'fl_areasqkm_mean_200m',\n",
       " 'fl_intephem_mean_200m',\n",
       " 'fl_streamorde_count_200m',\n",
       " 'wb_ftype_streamriver_200m',\n",
       " 'fl_totdasqkm_sum_200m',\n",
       " 'fl_gnis_name_ind_count_200m',\n",
       " 'fl_flow_type_count_200m',\n",
       " 'fl_startflag_mean_200m',\n",
       " 'fl_ftype_canalditch_200m',\n",
       " 'fl_gnis_name_ind_sum_200m',\n",
       " 'wb_gnis_name_ind_sum_200m',\n",
       " 'fl_startflag_count_200m',\n",
       " 'fl_totdasqkm_count_200m',\n",
       " 'wb_ftype_pipeline_200m',\n",
       " 'fl_divergence_count_200m',\n",
       " 'fl_length_mean_200m',\n",
       " 'fl_flow_type_sum_200m',\n",
       " 'wb_area_count_200m',\n",
       " 'fl_ftype_coastline_200m',\n",
       " 'wb_ftype_connector_200m',\n",
       " 'fl_length_count_200m',\n",
       " 'fl_streamorde_mean_200m',\n",
       " 'fl_intephem_sum_200m',\n",
       " 'fl_ftype_connector_200m',\n",
       " 'fl_divergence_sum_200m',\n",
       " 'fl_ftype_streamriver_200m',\n",
       " 'fl_gnis_name_ind_mean_200m',\n",
       " 'fl_totdasqkm_mean_200m',\n",
       " 'fl_ftype_artificialpath_200m',\n",
       " 'fl_divergence_mean_200m',\n",
       " 'fl_startflag_sum_200m',\n",
       " 'wb_gnis_name_ind_mean_200m',\n",
       " 'nwi_SYSTEM_NAME_marine_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_mesohaline_200m',\n",
       " 'nwi_SUBSYSTEM_NAME_littoral_200m',\n",
       " 'nwi_WATER_REGIME_NAME_seasonally_flooded-tidal_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_hyperhaline/hypersaline_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_diked/impounded_200m',\n",
       " 'nwi_WATER_REGIME_NAME_semipermanently_flooded_200m',\n",
       " 'nwi_SUBSYSTEM_NAME_intertidal_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_unconsolidated_shore_200m',\n",
       " 'nwi_CLASS_NAME_forested_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_rooted_vascular_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_acid_200m',\n",
       " 'nwi_estuarine_and_marine_wetland_200m',\n",
       " 'nwi_SUBCLASS_NAME_aquatic_moss_200m',\n",
       " 'nwi_SUBCLASS_NAME_evergreen_200m',\n",
       " 'nwi_SUBCLASS_NAME_floating_vascular_200m',\n",
       " 'nwi_lake_200m',\n",
       " 'nwi_SUBCLASS_NAME_non_persistent_200m',\n",
       " 'nwi_SUBCLASS_NAME_sand_200m',\n",
       " 'nwi_WATER_REGIME_NAME_permanently_flooded-tidal_200m',\n",
       " 'nwi_WATER_REGIME_SUBGROUP_zzz_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_zzz_200m',\n",
       " 'nwi_SUBCLASS_NAME_cobble-gravel_200m',\n",
       " 'nwi_SUBCLASS_NAME_dead_200m',\n",
       " 'nwi_CLASS_NAME_unconsolidated_shore_200m',\n",
       " 'nwi_CLASS_NAME_zzz_200m',\n",
       " 'nwi_WATER_REGIME_NAME_irregularly_flooded_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_mixohaline/mixosaline_(brackish)_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_mollusk_200m',\n",
       " 'nwi_WATER_REGIME_SUBGROUP_nontidal_200m',\n",
       " 'nwi_shrub_wetland_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_cobble-gravel_200m',\n",
       " 'nwi_WATER_REGIME_NAME_subtidal_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_dead_200m',\n",
       " 'nwi_SUBCLASS_NAME_phragmites_australis_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_spoil_200m',\n",
       " 'nwi_other_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_beaver_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_rocky_shore_200m',\n",
       " 'nwi_SUBCLASS_NAME_persistent_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_forested_200m',\n",
       " 'nwi_SUBCLASS_NAME_organic_200m',\n",
       " 'nwi_SUBCLASS_NAME_lichen_200m',\n",
       " 'nwi_WATER_REGIME_NAME_intermittently_exposed_200m',\n",
       " 'nwi_SUBCLASS_NAME_needle-leaved_deciduous_200m',\n",
       " 'nwi_SYSTEM_NAME_estuarine_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_needle-leaved_deciduous_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_polyhaline_200m',\n",
       " 'nwi_estuarine_and_marine_deepwater_200m',\n",
       " 'nwi_SUBSYSTEM_NAME_limnetic_200m',\n",
       " 'nwi_CLASS_NAME_rocky_shore_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_vegetated_200m',\n",
       " 'nwi_WATER_REGIME_SUBGROUP_freshwater_tidal_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_mud_200m',\n",
       " 'nwi_WATER_REGIME_NAME_zzz_200m',\n",
       " 'nwi_SUBCLASS_NAME_bedrock_200m',\n",
       " 'nwi_freshwater_forested_200m',\n",
       " 'nwi_SUBSYSTEM_NAME_lower_perennial_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_mineral_200m',\n",
       " 'nwi_SUBCLASS_NAME_vegetated_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_emergent_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_unconsolidated_bottom_200m',\n",
       " 'nwi_SYSTEM_NAME_lacustrine_200m',\n",
       " 'nwi_CLASS_NAME_emergent_200m',\n",
       " 'nwi_WATER_REGIME_NAME_temporary_flooded_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_organic_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_sand_200m',\n",
       " 'nwi_freshwater_pond_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_moss-lichen_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_oligohaline_200m',\n",
       " 'nwi_SUBCLASS_NAME_deciduous_200m',\n",
       " 'nwi_WATER_REGIME_NAME_regularly_flooded_200m',\n",
       " 'nwi_SUBCLASS_NAME_broad-leaved_evergreen_200m',\n",
       " 'nwi_WATER_REGIME_NAME_seasonally_saturated_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_deciduous_200m',\n",
       " 'nwi_WATER_REGIME_NAME_artificially_flooded_200m',\n",
       " 'nwi_SUBCLASS_NAME_needle-leaved_evergreen_200m',\n",
       " 'nwi_riverine_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_euthaline/eusaline_200m',\n",
       " 'nwi_CLASS_NAME_reef_200m',\n",
       " 'nwi_SUBCLASS_NAME_rubble_200m',\n",
       " 'nwi_freshwater_emergent_wetland_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_evergreen_200m',\n",
       " 'nwi_CLASS_NAME_rock_bottom_200m',\n",
       " 'nwi_SUBSYSTEM_NAME_unknown_perennial_200m',\n",
       " 'nwi_WATER_REGIME_NAME_permanently_flooded_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_non_persistent_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_excavated_200m',\n",
       " 'nwi_SUBCLASS_NAME_zzz_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_rubble_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_persistent_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_aquatic_moss_200m',\n",
       " 'nwi_SUBCLASS_NAME_broad-leaved_deciduous_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_zzz_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_artificial_substrate_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_moss_200m',\n",
       " 'nwi_CLASS_NAME_moss-lichen_200m',\n",
       " 'nwi_CLASS_NAME_scrub-shrub_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_alkaline_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_needle-leaved_evergreen_200m',\n",
       " 'nwi_SUBSYSTEM_NAME_upper_perennial_200m',\n",
       " 'nwi_SUBCLASS_NAME_algal_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_broad-leaved_deciduous_200m',\n",
       " 'nwi_SYSTEM_NAME_riverine_200m',\n",
       " 'nwi_SUBCLASS_NAME_coral_200m',\n",
       " 'nwi_SUBCLASS_NAME_mud_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_aquatic_bed_200m',\n",
       " 'nwi_SYSTEM_NAME_palustrine_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_scrub-shrub_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_partially_drained/ditched_200m',\n",
       " 'nwi_SUBSYSTEM_NAME_subtidal_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_coral_200m',\n",
       " 'nwi_SUBSYSTEM_NAME_intermittent_200m',\n",
       " 'nwi_SUBCLASS_NAME_mollusk_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_floating_vascular_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_organic_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_phragmites_australis_200m',\n",
       " 'nwi_feature_count_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_lichen_200m',\n",
       " 'nwi_WATER_REGIME_NAME_temporary_flooded-tidal_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_bedrock_200m',\n",
       " 'nwi_WATER_REGIME_SUBGROUP_saltwater_tidal_200m',\n",
       " 'nwi_CLASS_NAME_aquatic_bed_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_algal_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_reef_200m',\n",
       " 'nwi_SUBSYSTEM_NAME_tidal_200m',\n",
       " 'nwi_WATER_REGIME_NAME_seasonally_flooded/saturated_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_managed_200m',\n",
       " 'nwi_WATER_REGIME_NAME_intermittently_flooded_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_farmed_200m',\n",
       " 'nwi_CLASS_NAME_streambed_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_zzz_200m',\n",
       " 'nwi_WATER_REGIME_NAME_continuously__saturated_200m',\n",
       " 'nwi_SUBCLASS_NAME_rooted_vascular_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_broad-leaved_evergreen_200m',\n",
       " 'nwi_WATER_REGIME_NAME_seasonally_flooded_200m',\n",
       " 'nwi_CLASS_NAME_unconsolidated_bottom_200m',\n",
       " 'nwi_SUBCLASS_NAME_moss_200m',\n",
       " 'nwi_WATER_REGIME_NAME_irregularly_exposed_200m',\n",
       " 'nwi_WATER_REGIME_NAME_semipermanently_flooded-tidal_200m',\n",
       " 'transition_0_2500m',\n",
       " 'slope_min_2500m',\n",
       " 'recurrence_min_2500m',\n",
       " 'transition_6_2500m',\n",
       " 'elevation_max_2500m',\n",
       " 'transition_5_2500m',\n",
       " 'elevation_min_2500m',\n",
       " 'transition_7_2500m',\n",
       " 'seasonality_min_2500m',\n",
       " 'slope_stdev_2500m',\n",
       " 'transition_4_2500m',\n",
       " 'recurrence_stdev_2500m',\n",
       " 'elevation_stdev_2500m',\n",
       " 'elevation_mean_2500m',\n",
       " 'transition_3_2500m',\n",
       " 'seasonality_max_2500m',\n",
       " 'seasonality_stdev_2500m',\n",
       " 'seasonality_mean_2500m',\n",
       " 'slope_max_2500m',\n",
       " 'slope_mean_2500m',\n",
       " 'transition_8_2500m',\n",
       " 'transition_9_2500m',\n",
       " 'transition_1_2500m',\n",
       " 'recurrence_mean_2500m',\n",
       " 'transition_2_2500m',\n",
       " 'recurrence_max_2500m',\n",
       " 'wb_gnis_name_ind_count_2500m',\n",
       " 'wb_ftype_canalditch_2500m',\n",
       " 'fl_ftype_canalditch_2500m',\n",
       " 'fl_ftype_streamriver_2500m',\n",
       " 'fl_flow_type_sum_2500m',\n",
       " 'fl_divergence_mean_2500m',\n",
       " 'fl_totdasqkm_count_2500m',\n",
       " 'wb_gnis_name_ind_sum_2500m',\n",
       " 'wb_area_mean_2500m',\n",
       " 'fl_divergence_sum_2500m',\n",
       " 'fl_ftype_coastline_2500m',\n",
       " 'fl_ftype_artificialpath_2500m',\n",
       " 'wb_ftype_streamriver_2500m',\n",
       " 'wb_gnis_name_ind_mean_2500m',\n",
       " 'fl_flow_type_count_2500m',\n",
       " 'fl_startflag_sum_2500m',\n",
       " 'fl_intephem_mean_2500m',\n",
       " 'fl_startflag_count_2500m',\n",
       " 'wb_ftype_pipeline_2500m',\n",
       " 'fl_totdasqkm_sum_2500m',\n",
       " 'fl_intephem_count_2500m',\n",
       " 'fl_gnis_name_ind_count_2500m',\n",
       " 'fl_gnis_name_ind_sum_2500m',\n",
       " 'fl_divergence_count_2500m',\n",
       " 'fl_length_mean_2500m',\n",
       " 'fl_areasqkm_mean_2500m',\n",
       " 'fl_length_sum_2500m',\n",
       " 'fl_ftype_connector_2500m',\n",
       " 'fl_streamorde_count_2500m',\n",
       " 'fl_intephem_sum_2500m',\n",
       " 'fl_totdasqkm_mean_2500m',\n",
       " 'wb_ftype_connector_2500m',\n",
       " 'fl_streamorde_sum_2500m',\n",
       " 'wb_ftype_coastline_2500m',\n",
       " 'fl_areasqkm_count_2500m',\n",
       " 'fl_gnis_name_ind_mean_2500m',\n",
       " 'wb_ftype_artificialpath_2500m',\n",
       " 'fl_flow_type_mean_2500m',\n",
       " 'fl_ftype_pipeline_2500m',\n",
       " 'fl_streamorde_mean_2500m',\n",
       " 'wb_area_count_2500m',\n",
       " 'wb_area_sum_2500m',\n",
       " 'fl_length_count_2500m',\n",
       " 'fl_areasqkm_sum_2500m',\n",
       " 'fl_startflag_mean_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_seasonally_flooded/saturated_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_zzz_2500m',\n",
       " 'nwi_SPLIT_CLASS_NAME_zzz_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_polyhaline_2500m',\n",
       " 'nwi_SUBSYSTEM_NAME_limnetic_2500m',\n",
       " 'nwi_freshwater_forested_2500m',\n",
       " 'nwi_SUBCLASS_NAME_coral_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_zzz_2500m',\n",
       " 'nwi_CLASS_NAME_forested_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_algal_2500m',\n",
       " 'nwi_WATER_REGIME_SUBGROUP_saltwater_tidal_2500m',\n",
       " 'nwi_SUBCLASS_NAME_algal_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_seasonally_flooded_2500m',\n",
       " 'nwi_SUBCLASS_NAME_deciduous_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_cobble-gravel_2500m',\n",
       " 'nwi_SYSTEM_NAME_riverine_2500m',\n",
       " 'nwi_other_2500m',\n",
       " 'nwi_SUBCLASS_NAME_needle-leaved_deciduous_2500m',\n",
       " 'nwi_SPLIT_CLASS_NAME_rocky_shore_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_partially_drained/ditched_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_alkaline_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_broad-leaved_evergreen_2500m',\n",
       " 'nwi_SUBSYSTEM_NAME_lower_perennial_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_euthaline/eusaline_2500m',\n",
       " 'nwi_SYSTEM_NAME_estuarine_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_intermittently_exposed_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_rubble_2500m',\n",
       " 'nwi_estuarine_and_marine_deepwater_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_spoil_2500m',\n",
       " 'nwi_SUBCLASS_NAME_lichen_2500m',\n",
       " 'nwi_SUBCLASS_NAME_organic_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_seasonally_saturated_2500m',\n",
       " 'nwi_SUBSYSTEM_NAME_tidal_2500m',\n",
       " 'nwi_SPLIT_CLASS_NAME_moss-lichen_2500m',\n",
       " 'nwi_freshwater_pond_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_mineral_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_sand_2500m',\n",
       " 'nwi_SUBCLASS_NAME_vegetated_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_rooted_vascular_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_persistent_2500m',\n",
       " 'nwi_WATER_REGIME_SUBGROUP_freshwater_tidal_2500m',\n",
       " 'nwi_SPLIT_CLASS_NAME_emergent_2500m',\n",
       " 'nwi_CLASS_NAME_reef_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_mixohaline/mixosaline_(brackish)_2500m',\n",
       " 'nwi_SUBCLASS_NAME_sand_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_dead_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_beaver_2500m',\n",
       " 'nwi_SUBSYSTEM_NAME_intermittent_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_farmed_2500m',\n",
       " 'nwi_SUBCLASS_NAME_bedrock_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_moss_2500m',\n",
       " 'nwi_CLASS_NAME_zzz_2500m',\n",
       " 'nwi_SUBCLASS_NAME_persistent_2500m',\n",
       " 'nwi_SUBCLASS_NAME_rubble_2500m',\n",
       " 'nwi_SUBCLASS_NAME_phragmites_australis_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_permanently_flooded-tidal_2500m',\n",
       " 'nwi_SUBCLASS_NAME_aquatic_moss_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_zzz_2500m',\n",
       " 'nwi_CLASS_NAME_aquatic_bed_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_managed_2500m',\n",
       " 'nwi_CLASS_NAME_scrub-shrub_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_vegetated_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_mollusk_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_continuously__saturated_2500m',\n",
       " 'nwi_SPLIT_CLASS_NAME_unconsolidated_bottom_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_phragmites_australis_2500m',\n",
       " 'nwi_CLASS_NAME_unconsolidated_bottom_2500m',\n",
       " 'nwi_SUBCLASS_NAME_broad-leaved_evergreen_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_hyperhaline/hypersaline_2500m',\n",
       " 'nwi_SPLIT_CLASS_NAME_aquatic_bed_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_lichen_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_permanently_flooded_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_artificial_substrate_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_temporary_flooded-tidal_2500m',\n",
       " 'nwi_shrub_wetland_2500m',\n",
       " 'nwi_SUBCLASS_NAME_dead_2500m',\n",
       " 'nwi_SPLIT_CLASS_NAME_unconsolidated_shore_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_non_persistent_2500m',\n",
       " 'nwi_SUBCLASS_NAME_floating_vascular_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_organic_2500m',\n",
       " 'nwi_SUBSYSTEM_NAME_subtidal_2500m',\n",
       " 'nwi_CLASS_NAME_unconsolidated_shore_2500m',\n",
       " 'nwi_CLASS_NAME_rocky_shore_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_coral_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_aquatic_moss_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_oligohaline_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_mesohaline_2500m',\n",
       " 'nwi_SPLIT_CLASS_NAME_reef_2500m',\n",
       " 'nwi_lake_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_seasonally_flooded-tidal_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_subtidal_2500m',\n",
       " 'nwi_SUBCLASS_NAME_moss_2500m',\n",
       " 'nwi_SUBCLASS_NAME_zzz_2500m',\n",
       " 'nwi_SUBCLASS_NAME_broad-leaved_deciduous_2500m',\n",
       " 'nwi_SYSTEM_NAME_palustrine_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_deciduous_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_semipermanently_flooded-tidal_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_organic_2500m',\n",
       " 'nwi_SUBCLASS_NAME_needle-leaved_evergreen_2500m',\n",
       " 'nwi_SUBSYSTEM_NAME_intertidal_2500m',\n",
       " 'nwi_CLASS_NAME_rock_bottom_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_irregularly_flooded_2500m',\n",
       " 'nwi_WATER_REGIME_SUBGROUP_zzz_2500m',\n",
       " 'nwi_SUBCLASS_NAME_mollusk_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_acid_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_diked/impounded_2500m',\n",
       " 'nwi_SUBCLASS_NAME_non_persistent_2500m',\n",
       " 'nwi_SUBSYSTEM_NAME_littoral_2500m',\n",
       " 'nwi_CLASS_NAME_emergent_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_semipermanently_flooded_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_floating_vascular_2500m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_excavated_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_artificially_flooded_2500m',\n",
       " 'nwi_SUBSYSTEM_NAME_upper_perennial_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_bedrock_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_broad-leaved_deciduous_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_mud_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_temporary_flooded_2500m',\n",
       " 'nwi_freshwater_emergent_wetland_2500m',\n",
       " 'nwi_SPLIT_CLASS_NAME_forested_2500m',\n",
       " 'nwi_SPLIT_CLASS_NAME_scrub-shrub_2500m',\n",
       " 'nwi_SYSTEM_NAME_lacustrine_2500m',\n",
       " 'nwi_SUBCLASS_NAME_rooted_vascular_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_intermittently_flooded_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_evergreen_2500m',\n",
       " 'nwi_SYSTEM_NAME_marine_2500m',\n",
       " 'nwi_CLASS_NAME_moss-lichen_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_needle-leaved_deciduous_2500m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_needle-leaved_evergreen_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_regularly_flooded_2500m',\n",
       " 'nwi_WATER_REGIME_SUBGROUP_nontidal_2500m',\n",
       " 'nwi_riverine_2500m',\n",
       " 'nwi_estuarine_and_marine_wetland_2500m',\n",
       " 'nwi_SUBCLASS_NAME_mud_2500m',\n",
       " 'nwi_SUBSYSTEM_NAME_unknown_perennial_2500m',\n",
       " 'nwi_CLASS_NAME_streambed_2500m',\n",
       " 'nwi_WATER_REGIME_NAME_irregularly_exposed_2500m',\n",
       " 'nwi_SUBCLASS_NAME_cobble-gravel_2500m',\n",
       " 'nwi_SUBCLASS_NAME_evergreen_2500m',\n",
       " 'closest_wb_distance_m',\n",
       " 'closest_fl_distance_m',\n",
       " 'closest_fl_area_sqkm',\n",
       " 'closest_wb_area_sqkm',\n",
       " 'closest_fl_elevation',\n",
       " 'closest_wb_elevation']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_num_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdBKul2wROi4",
    "outputId": "fb607dae-a36a-4e9b-e4be-eb54ae133426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "niccdcd 0.11\n",
      "aws0100wta 0.04\n",
      "wtdepannmi 0.04\n",
      "niccdcdpct 0.04\n",
      "hydclprs 0.04\n",
      "aws025wta 0.04\n",
      "wtdepaprju 0.04\n",
      "slopegradw 0.04\n",
      "iccdcdpct 0.04\n",
      "urbrecptwt 0.04\n",
      "brockdepmi 0.04\n",
      "iccdcd 0.88\n",
      "pondfreqpr 0.04\n",
      "aws0150wta 0.04\n",
      "aws050wta 0.04\n",
      "slopegradd 0.04\n",
      "awmmfpwwta 0.04\n",
      "transition_9_200m 1.0\n",
      "recurrence_mean_200m 0.77\n",
      "transition_2_200m 0.96\n",
      "seasonality_min_200m 0.82\n",
      "transition_8_200m 0.95\n",
      "transition_5_200m 0.85\n",
      "seasonality_stdev_200m 0.82\n",
      "seasonality_max_200m 0.82\n",
      "recurrence_min_200m 0.79\n",
      "recurrence_max_200m 0.79\n",
      "transition_7_200m 0.95\n",
      "slope_min_200m 0.02\n",
      "elevation_min_200m 0.02\n",
      "transition_0_200m 0.99\n",
      "elevation_mean_200m 0.02\n",
      "elevation_max_200m 0.02\n",
      "slope_max_200m 0.02\n",
      "transition_3_200m 0.99\n",
      "transition_4_200m 0.9\n",
      "elevation_stdev_200m 0.02\n",
      "recurrence_stdev_200m 0.79\n",
      "transition_1_200m 0.89\n",
      "transition_6_200m 0.94\n",
      "slope_stdev_200m 0.02\n",
      "seasonality_mean_200m 0.8\n",
      "slope_mean_200m 0.02\n",
      "fl_length_sum_200m 0.09\n",
      "fl_length_mean_200m 0.09\n",
      "transition_0_2500m 0.82\n",
      "slope_min_2500m 0.02\n",
      "recurrence_min_2500m 0.08\n",
      "transition_6_2500m 0.35\n",
      "elevation_max_2500m 0.02\n",
      "transition_5_2500m 0.12\n",
      "elevation_min_2500m 0.02\n",
      "transition_7_2500m 0.55\n",
      "seasonality_min_2500m 0.11\n",
      "slope_stdev_2500m 0.02\n",
      "transition_4_2500m 0.31\n",
      "recurrence_stdev_2500m 0.08\n",
      "elevation_stdev_2500m 0.02\n",
      "elevation_mean_2500m 0.02\n",
      "transition_3_2500m 0.79\n",
      "seasonality_max_2500m 0.11\n",
      "seasonality_stdev_2500m 0.11\n",
      "seasonality_mean_2500m 0.11\n",
      "slope_max_2500m 0.02\n",
      "slope_mean_2500m 0.02\n",
      "transition_8_2500m 0.54\n",
      "transition_9_2500m 0.89\n",
      "transition_1_2500m 0.49\n",
      "recurrence_mean_2500m 0.07\n",
      "transition_2_2500m 0.41\n",
      "recurrence_max_2500m 0.08\n",
      "fl_length_mean_2500m 0.53\n",
      "fl_length_sum_2500m 0.53\n",
      "closest_wb_distance_m 0.47\n",
      "closest_fl_distance_m 0.3\n",
      "closest_fl_area_sqkm 0.4\n",
      "closest_wb_area_sqkm 0.67\n",
      "closest_fl_elevation 0.3\n",
      "closest_wb_elevation 0.47\n"
     ]
    }
   ],
   "source": [
    "# fraction of nan's in each variable\n",
    "for var in df_X_combined_ordered.describe().columns:\n",
    "    try:\n",
    "        if np.mean(df_X_combined_ordered[str(var)].isna()) != 0:\n",
    "            print(var, round(np.mean(df_X_combined_ordered[str(var)].isna()), 2))\n",
    "    except Exception as e:\n",
    "        print(var, \"<-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "id": "D4kq__Giqima"
   },
   "outputs": [],
   "source": [
    "# impute 0's into wb_area_mean, fl_length_sum, fl_length_mean because they were\n",
    "# assigned np.nan if they were absent\n",
    "# A non-existent water feature should be assigned 0 given definition of each\n",
    "\n",
    "def fill_na(df):\n",
    "  try:\n",
    "    df.fl_length_sum_200m = df.fl_length_sum_200m.fillna(0)\n",
    "    df.fl_length_mean_200m = df.fl_length_sum_200m.fillna(0)\n",
    "    df.fl_length_sum_2500m = df.fl_length_sum_200m.fillna(0)\n",
    "    df.fl_length_mean_2500m = df.fl_length_sum_200m.fillna(0)\n",
    "  except:\n",
    "    pass\n",
    "  return df\n",
    "\n",
    "df_X_combined_ordered = fill_na(df_X_combined_ordered)\n",
    "df_dev_X_combined_ordered = fill_na(df_dev_X)\n",
    "df_test_X_combined_ordered = fill_na(df_test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qy2KEjaNq487",
    "outputId": "077aa965-5d64-4ad9-abc7-001580eb74d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "niccdcd 0.11\n",
      "aws0100wta 0.04\n",
      "wtdepannmi 0.04\n",
      "niccdcdpct 0.04\n",
      "hydclprs 0.04\n",
      "aws025wta 0.04\n",
      "wtdepaprju 0.04\n",
      "slopegradw 0.04\n",
      "iccdcdpct 0.04\n",
      "urbrecptwt 0.04\n",
      "brockdepmi 0.04\n",
      "iccdcd 0.88\n",
      "pondfreqpr 0.04\n",
      "aws0150wta 0.04\n",
      "aws050wta 0.04\n",
      "slopegradd 0.04\n",
      "awmmfpwwta 0.04\n",
      "transition_9_200m 1.0\n",
      "recurrence_mean_200m 0.77\n",
      "transition_2_200m 0.96\n",
      "seasonality_min_200m 0.82\n",
      "transition_8_200m 0.95\n",
      "transition_5_200m 0.85\n",
      "seasonality_stdev_200m 0.82\n",
      "seasonality_max_200m 0.82\n",
      "recurrence_min_200m 0.79\n",
      "recurrence_max_200m 0.79\n",
      "transition_7_200m 0.95\n",
      "slope_min_200m 0.02\n",
      "elevation_min_200m 0.02\n",
      "transition_0_200m 0.99\n",
      "elevation_mean_200m 0.02\n",
      "elevation_max_200m 0.02\n",
      "slope_max_200m 0.02\n",
      "transition_3_200m 0.99\n",
      "transition_4_200m 0.9\n",
      "elevation_stdev_200m 0.02\n",
      "recurrence_stdev_200m 0.79\n",
      "transition_1_200m 0.89\n",
      "transition_6_200m 0.94\n",
      "slope_stdev_200m 0.02\n",
      "seasonality_mean_200m 0.8\n",
      "slope_mean_200m 0.02\n",
      "transition_0_2500m 0.82\n",
      "slope_min_2500m 0.02\n",
      "recurrence_min_2500m 0.08\n",
      "transition_6_2500m 0.35\n",
      "elevation_max_2500m 0.02\n",
      "transition_5_2500m 0.12\n",
      "elevation_min_2500m 0.02\n",
      "transition_7_2500m 0.55\n",
      "seasonality_min_2500m 0.11\n",
      "slope_stdev_2500m 0.02\n",
      "transition_4_2500m 0.31\n",
      "recurrence_stdev_2500m 0.08\n",
      "elevation_stdev_2500m 0.02\n",
      "elevation_mean_2500m 0.02\n",
      "transition_3_2500m 0.79\n",
      "seasonality_max_2500m 0.11\n",
      "seasonality_stdev_2500m 0.11\n",
      "seasonality_mean_2500m 0.11\n",
      "slope_max_2500m 0.02\n",
      "slope_mean_2500m 0.02\n",
      "transition_8_2500m 0.54\n",
      "transition_9_2500m 0.89\n",
      "transition_1_2500m 0.49\n",
      "recurrence_mean_2500m 0.07\n",
      "transition_2_2500m 0.41\n",
      "recurrence_max_2500m 0.08\n",
      "closest_wb_distance_m 0.47\n",
      "closest_fl_distance_m 0.3\n",
      "closest_fl_area_sqkm 0.4\n",
      "closest_wb_area_sqkm 0.67\n",
      "closest_fl_elevation 0.3\n",
      "closest_wb_elevation 0.47\n",
      "\n",
      "niccdcd 0.1\n",
      "aws0100wta 0.04\n",
      "wtdepannmi 0.04\n",
      "niccdcdpct 0.04\n",
      "hydclprs 0.04\n",
      "aws025wta 0.04\n",
      "wtdepaprju 0.04\n",
      "slopegradw 0.04\n",
      "iccdcdpct 0.04\n",
      "urbrecptwt 0.04\n",
      "brockdepmi 0.04\n",
      "iccdcd 0.88\n",
      "pondfreqpr 0.04\n",
      "aws0150wta 0.04\n",
      "aws050wta 0.04\n",
      "slopegradd 0.04\n",
      "awmmfpwwta 0.04\n",
      "transition_9_200m 1.0\n",
      "recurrence_mean_200m 0.79\n",
      "transition_2_200m 0.96\n",
      "seasonality_min_200m 0.84\n",
      "transition_8_200m 0.95\n",
      "transition_5_200m 0.87\n",
      "seasonality_stdev_200m 0.84\n",
      "seasonality_max_200m 0.84\n",
      "recurrence_min_200m 0.81\n",
      "recurrence_max_200m 0.81\n",
      "transition_7_200m 0.97\n",
      "slope_min_200m 0.02\n",
      "elevation_min_200m 0.02\n",
      "transition_0_200m 0.99\n",
      "elevation_mean_200m 0.02\n",
      "elevation_max_200m 0.02\n",
      "slope_max_200m 0.02\n",
      "transition_3_200m 0.99\n",
      "transition_4_200m 0.91\n",
      "elevation_stdev_200m 0.02\n",
      "recurrence_stdev_200m 0.81\n",
      "transition_1_200m 0.9\n",
      "transition_6_200m 0.94\n",
      "slope_stdev_200m 0.02\n",
      "seasonality_mean_200m 0.82\n",
      "slope_mean_200m 0.02\n",
      "transition_0_2500m 0.84\n",
      "slope_min_2500m 0.02\n",
      "recurrence_min_2500m 0.07\n",
      "transition_6_2500m 0.36\n",
      "elevation_max_2500m 0.02\n",
      "transition_5_2500m 0.12\n",
      "elevation_min_2500m 0.02\n",
      "transition_7_2500m 0.56\n",
      "seasonality_min_2500m 0.11\n",
      "slope_stdev_2500m 0.02\n",
      "transition_4_2500m 0.32\n",
      "recurrence_stdev_2500m 0.07\n",
      "elevation_stdev_2500m 0.02\n",
      "elevation_mean_2500m 0.02\n",
      "transition_3_2500m 0.81\n",
      "seasonality_max_2500m 0.11\n",
      "seasonality_stdev_2500m 0.11\n",
      "seasonality_mean_2500m 0.11\n",
      "slope_max_2500m 0.02\n",
      "slope_mean_2500m 0.02\n",
      "transition_8_2500m 0.55\n",
      "transition_9_2500m 0.9\n",
      "transition_1_2500m 0.5\n",
      "recurrence_mean_2500m 0.06\n",
      "transition_2_2500m 0.42\n",
      "recurrence_max_2500m 0.07\n",
      "closest_wb_distance_m 0.48\n",
      "closest_fl_distance_m 0.31\n",
      "closest_fl_area_sqkm 0.42\n",
      "closest_wb_area_sqkm 0.68\n",
      "closest_fl_elevation 0.31\n",
      "closest_wb_elevation 0.48\n",
      "\n",
      "niccdcd 0.11\n",
      "aws0100wta 0.04\n",
      "wtdepannmi 0.04\n",
      "niccdcdpct 0.04\n",
      "hydclprs 0.04\n",
      "aws025wta 0.04\n",
      "wtdepaprju 0.04\n",
      "slopegradw 0.04\n",
      "iccdcdpct 0.04\n",
      "urbrecptwt 0.04\n",
      "brockdepmi 0.04\n",
      "iccdcd 0.89\n",
      "pondfreqpr 0.04\n",
      "aws0150wta 0.04\n",
      "aws050wta 0.04\n",
      "slopegradd 0.04\n",
      "awmmfpwwta 0.04\n",
      "transition_9_200m 1.0\n",
      "recurrence_mean_200m 0.76\n",
      "transition_2_200m 0.96\n",
      "seasonality_min_200m 0.82\n",
      "transition_8_200m 0.95\n",
      "transition_5_200m 0.85\n",
      "seasonality_stdev_200m 0.82\n",
      "seasonality_max_200m 0.82\n",
      "recurrence_min_200m 0.78\n",
      "recurrence_max_200m 0.78\n",
      "transition_7_200m 0.95\n",
      "slope_min_200m 0.02\n",
      "elevation_min_200m 0.02\n",
      "transition_0_200m 0.99\n",
      "elevation_mean_200m 0.02\n",
      "elevation_max_200m 0.02\n",
      "slope_max_200m 0.02\n",
      "transition_3_200m 0.98\n",
      "transition_4_200m 0.9\n",
      "elevation_stdev_200m 0.02\n",
      "recurrence_stdev_200m 0.78\n",
      "transition_1_200m 0.89\n",
      "transition_6_200m 0.94\n",
      "slope_stdev_200m 0.02\n",
      "seasonality_mean_200m 0.8\n",
      "slope_mean_200m 0.02\n",
      "transition_0_2500m 0.82\n",
      "slope_min_2500m 0.02\n",
      "recurrence_min_2500m 0.08\n",
      "transition_6_2500m 0.37\n",
      "elevation_max_2500m 0.02\n",
      "transition_5_2500m 0.12\n",
      "elevation_min_2500m 0.02\n",
      "transition_7_2500m 0.55\n",
      "seasonality_min_2500m 0.11\n",
      "slope_stdev_2500m 0.02\n",
      "transition_4_2500m 0.32\n",
      "recurrence_stdev_2500m 0.08\n",
      "elevation_stdev_2500m 0.02\n",
      "elevation_mean_2500m 0.02\n",
      "transition_3_2500m 0.81\n",
      "seasonality_max_2500m 0.11\n",
      "seasonality_stdev_2500m 0.11\n",
      "seasonality_mean_2500m 0.11\n",
      "slope_max_2500m 0.02\n",
      "slope_mean_2500m 0.02\n",
      "transition_8_2500m 0.55\n",
      "transition_9_2500m 0.9\n",
      "transition_1_2500m 0.5\n",
      "recurrence_mean_2500m 0.07\n",
      "transition_2_2500m 0.4\n",
      "recurrence_max_2500m 0.08\n",
      "closest_wb_distance_m 0.48\n",
      "closest_fl_distance_m 0.3\n",
      "closest_fl_area_sqkm 0.39\n",
      "closest_wb_area_sqkm 0.67\n",
      "closest_fl_elevation 0.3\n",
      "closest_wb_elevation 0.48\n"
     ]
    }
   ],
   "source": [
    "# fraction of nan's in each variable\n",
    "def print_na(df_X_combined_ordered):\n",
    "  for var in df_X_combined_ordered.describe().columns:\n",
    "    if np.mean(df_X_combined_ordered[str(var)].isna()) != 0:\n",
    "      print(var, round(np.mean(df_X_combined_ordered[str(var)].isna()), 2))\n",
    "\n",
    "print_na(df_X_combined_ordered)      \n",
    "print()\n",
    "print_na(df_dev_X_combined_ordered)\n",
    "print()\n",
    "print_na(df_test_X_combined_ordered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiZZiHI7rroC"
   },
   "source": [
    "# Offline OHE to keep track of variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "id": "5wgvKVZ7rNb8"
   },
   "outputs": [],
   "source": [
    "# ohe-hot-encode the columns\n",
    "# get_dummies only encodes cat columns\n",
    "df_X_combined_dummies_ordered = pd.get_dummies(df_X_combined_ordered)\n",
    "# df_X_combined_dummies_ordered.columns # 90\n",
    "\n",
    "df_dev_X_combined_dummies_ordered = pd.get_dummies(df_dev_X_combined_ordered)\n",
    "df_test_X_combined_dummies_ordered = pd.get_dummies(df_test_X_combined_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2DzQYz-guOe",
    "outputId": "d15cc667-b613-4161-fdee-cb63bd03ce29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8592, 471)\n",
      "(2865, 471)\n",
      "(2865, 471)\n",
      "(8592, 1968)\n",
      "(2865, 1616)\n",
      "(2865, 1595)\n"
     ]
    }
   ],
   "source": [
    "print(df_X_combined_ordered.shape)\n",
    "print(df_dev_X_combined_ordered.shape)\n",
    "print(df_test_X_combined_ordered.shape)\n",
    "print(df_X_combined_dummies_ordered.shape)\n",
    "print(df_dev_X_combined_dummies_ordered.shape)\n",
    "print(df_test_X_combined_dummies_ordered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1Eq49x-r55M"
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "id": "YoBhg5wPrxlx"
   },
   "outputs": [],
   "source": [
    "# impute categorical data\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "  \"\"\"\n",
    "  By inheriting TransformerMixin, you get fit_transform method for free \n",
    "  if you implement fit and transform methods\n",
    "  \"\"\" \n",
    "\n",
    "  def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "\n",
    "        Columns of dtype object are imputed with the most frequent value \n",
    "        in column.\n",
    "        Columns of other types are imputed with median of column.\n",
    "        \"\"\"\n",
    "  def fit(self, X, y=None):\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].median() for c in X], \n",
    "            index=X.columns)\n",
    "        return self\n",
    "\n",
    "  def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "id": "2E_VtoXpr8W9"
   },
   "outputs": [],
   "source": [
    "# Pipeline for numerical columns\n",
    "# 1. fill NA's with median values\n",
    "# 2. scale them\n",
    "\n",
    "# num_pipeline_impute_ss = Pipeline([        # should be list of tuples\n",
    "#                           (\"num_imputer\", SimpleImputer(strategy=\"median\")),\n",
    "#                           (\"std_scaler\", StandardScaler())\n",
    "#                           ])                      \n",
    "\n",
    "# num_pipeline_impute_ss = Pipeline([        # should be list of tuples\n",
    "#                           (\"num_imputer\", SimpleImputer(strategy=\"median\")),\n",
    "#                           (\"robust_scaler\", RobustScaler())\n",
    "#                           ])                      \n",
    "\n",
    "num_pipeline_impute_ss = Pipeline([        # should be list of tuples\n",
    "                          (\"num_imputer\", SimpleImputer(strategy=\"median\"))\n",
    "                          ])                      \n",
    "\n",
    "\n",
    "# Pipleline for categorical columns\n",
    "# 1. fill NA's with most frequent values\n",
    "# 2. one hot code\n",
    "\n",
    "# cat_pipeline_impute_ohe = Pipeline([(\"cat_imputer\", DataFrameImputer()),\n",
    "#                          (\"one_hot_encoder\", OneHotEncoder(drop=\"first\", \\\n",
    "#                                                            sparse=False))\n",
    "#                          ])\n",
    "\n",
    "\n",
    "# you want to do the following where you handle_unknown categories in the \n",
    "# test data by ignoring them. However, in the imeplementation, I am using\n",
    "# df_X_combined_dummies_ordered to indicate the numerical and cat columns \n",
    "# hence need to fix the df_X_combined_dummies_ordered such that the first \n",
    "# ohe is not dropped (as is being done in immediately above)\n",
    "\n",
    "cat_pipeline_impute_ohe = Pipeline([(\"cat_imputer\", DataFrameImputer()),\n",
    "                         (\"one_hot_encoder\", OneHotEncoder(sparse=False,\n",
    "                                                           handle_unknown = \"ignore\"))\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "id": "T6zsqDgLsIhp"
   },
   "outputs": [],
   "source": [
    "numericals_list = list(df_X_combined_ordered.describe().columns)\n",
    "categories_list = list(set(df_X_combined_ordered.columns) - set(numericals_list))\n",
    "\n",
    "# here trying to do numerical and categorical transformation in isolation\n",
    "# this because ColumnTransformer removes column name information :-(\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# only the cat columns will be one-hot encoded\n",
    "partial_transformer_impute_ohe = ColumnTransformer([\n",
    "                                   (\"categorical_ohe\", cat_pipeline_impute_ohe,\\\n",
    "                                    categories_list)\n",
    "])\n",
    "\n",
    "# only the numerical columns withh get standard scaling\n",
    "partial_transformer_impute_ss = ColumnTransformer([\n",
    "                                   (\"numerical_ss_impute\", num_pipeline_impute_ss,\\\n",
    "                                    numericals_list)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation of Dev and Test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7DxNTfIFtT9y",
    "outputId": "5d8a5f9d-f079-43d8-b8db-65afc2d25027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8592, 447)\n",
      "(2865, 447)\n",
      "(2865, 447)\n"
     ]
    }
   ],
   "source": [
    "# Pass the numerical columns through Numerical Pipeline \n",
    "\n",
    "# train\n",
    "full_data_ohe_ss_imputed = (partial_transformer_impute_ss\n",
    "                            .fit(df_X_combined_ordered[numericals_list])\n",
    "                            .transform(df_X_combined_ordered[numericals_list])) \n",
    "print(full_data_ohe_ss_imputed.shape)\n",
    "\n",
    "# dev\n",
    "dev_ohe_ss_imputed = (partial_transformer_impute_ss\n",
    "                            .fit(df_X_combined_ordered[numericals_list])\n",
    "                            .transform(df_dev_X_combined_ordered[numericals_list])) \n",
    "print(dev_ohe_ss_imputed.shape)\n",
    "\n",
    "\n",
    "# test\n",
    "test_ohe_ss_imputed = (partial_transformer_impute_ss\n",
    "                            .fit(df_X_combined_ordered[numericals_list])\n",
    "                            .transform(df_test_X_combined_ordered[numericals_list])) \n",
    "print(test_ohe_ss_imputed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQD-xNjqtUA9",
    "outputId": "9bf01104-653e-4175-e099-3c7a0296e530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8592, 1521)\n",
      "(2865, 1521)\n",
      "(2865, 1521)\n"
     ]
    }
   ],
   "source": [
    "# Pass the cat columns through Categorical Pipeline\n",
    "\n",
    "# train\n",
    "cat_data_OHE = (partial_transformer_impute_ohe\n",
    "                .fit(df_X_combined_ordered)\n",
    "                .transform(df_X_combined_ordered))\n",
    "print(cat_data_OHE.shape)\n",
    "\n",
    "# test\n",
    "dev_cat_data_OHE = (partial_transformer_impute_ohe\n",
    "                .fit(df_X_combined_ordered)\n",
    "                .transform(df_dev_X_combined_ordered))\n",
    "print(dev_cat_data_OHE.shape)\n",
    "\n",
    "# test\n",
    "test_cat_data_OHE = (partial_transformer_impute_ohe\n",
    "                .fit(df_X_combined_ordered)\n",
    "                .transform(df_test_X_combined_ordered))\n",
    "print(test_cat_data_OHE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgK2Nv2HycZo",
    "outputId": "9af08aa1-945f-49a2-a36b-42064875d6d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8592, 1968) (8592,) (2865, 1968) (2865,) (2865, 1968) (2865,)\n"
     ]
    }
   ],
   "source": [
    "# join the arrays into one array that can be passed into models\n",
    "\n",
    "# train\n",
    "X = np.hstack((full_data_ohe_ss_imputed, cat_data_OHE))\n",
    "Y = np.array(df.cwa_determination)\n",
    "\n",
    "# dev\n",
    "dev_X = np.hstack((dev_ohe_ss_imputed, dev_cat_data_OHE))\n",
    "dev_Y = np.array(df_dev.cwa_determination)\n",
    "\n",
    "# test\n",
    "test_X = np.hstack((test_ohe_ss_imputed, test_cat_data_OHE))\n",
    "test_Y = np.array(df_test.cwa_determination)\n",
    "\n",
    "print(X.shape, Y.shape, dev_X.shape, dev_Y.shape, test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "id": "vNnvAK30tUDx"
   },
   "outputs": [],
   "source": [
    "# Convert numerical and cat transforms back to dataframe (for housekeeping)\n",
    "\n",
    "# convert numerical arrays into dataframe\n",
    "\n",
    "def make_dataframe(full_data_ohe_ss_imputed, cat_data_OHE):\n",
    "  df_num_data_ohe_ss = (pd.DataFrame(\n",
    "      full_data_ohe_ss_imputed,\n",
    "      columns=list(df_X_combined_dummies_ordered[numericals_list].columns)\n",
    "  ))\n",
    "\n",
    "  # # convert cat arrays into dataframe\n",
    "  ohe_categories_list = (list(set(df_X_combined_dummies_ordered.columns) - set(numericals_list)))\n",
    "  df_cat_data_OHE = (pd.DataFrame(\n",
    "      cat_data_OHE,\n",
    "      columns=list(df_X_combined_dummies_ordered[ohe_categories_list].columns))\n",
    "  )\n",
    "\n",
    "  # concatenate into one dataframe\n",
    "\n",
    "  return pd.concat([df_num_data_ohe_ss, df_cat_data_OHE], axis=1)\n",
    "\n",
    "\n",
    "df_train_X_dummies = make_dataframe(full_data_ohe_ss_imputed, cat_data_OHE)\n",
    "df_dev_X_dummies = make_dataframe(dev_ohe_ss_imputed, dev_cat_data_OHE)\n",
    "df_test_X_dummies = make_dataframe(test_ohe_ss_imputed, test_cat_data_OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "id": "iY1gOlOk5-ZM"
   },
   "outputs": [],
   "source": [
    "if stop_before_models:\n",
    "    stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZOqLgq5EsPm"
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmWtOA8lEThm",
    "outputId": "3a4a38ac-dfe3-4cc8-ddd0-80ae86b3eec8"
   },
   "outputs": [],
   "source": [
    "# print(sorted(metrics.SCORERS.keys()))\n",
    "# sorted(metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_search.__dir__()\n",
    "# random_search.return_train_score\n",
    "\n",
    "# random_search.scoring # roc_auc\n",
    "# random_search.best_score_ # \n",
    "# random_search.scorer_ # make_scorer(roc_auc_score, needs_threshold=True)\n",
    "\n",
    "# random_search.cv_results_\n",
    "# random_search.predict_proba(X)\n",
    "# random_search.predict_log_proba(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_taken(start, end):\n",
    "    delta = end - start\n",
    "    print(\"Time taken (min):\", round(delta.seconds/60, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(fitted_model, test_X, test_Y):\n",
    "#     print(\"accuracy:\", np.mean(test_Y == log_best_model.predict(test_X)))\n",
    "#     print(\"balanced_accuracy_score:\", balanced_accuracy_score(test_Y, log_best_model.predict(test_X)))\n",
    "\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html\n",
    "    # AP summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold\n",
    "    print(\"average_precision_score:\", round(metrics.average_precision_score(test_Y, fitted_model.predict_proba(test_X)[:, 1], average=\"weighted\"), 5))\n",
    "    \n",
    "    \n",
    "    y_prob = fitted_model.predict_proba(test_X)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_Y, y_prob[:, 1], pos_label=1)\n",
    "    print(\"roc_auc\",\":\", round(metrics.auc(fpr, tpr), 5))\n",
    "    \n",
    "    print(\"Classification Report:\") # threshold agnostic because you pass in the test labels instead of scores (probabilities)\n",
    "    print(classification_report(test_Y, fitted_model.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_roc_auc(fitted_model, test_X, test_Y):\n",
    "    y_prob = fitted_model.predict_proba(test_X)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_Y, y_prob[:, 1], pos_label=1)\n",
    "    return round(metrics.auc(fpr, tpr), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpKXfQfXzKLf"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzQrUXTW6J6b",
    "outputId": "506c9dc8-7ddd-46a3-f171-91e9993e52c9"
   },
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "id": "IqOn82eq0Hsy"
   },
   "outputs": [],
   "source": [
    "\n",
    "# build a classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "param_dict = {\"C\":np.logspace(-3,3,7), \n",
    "              \"penalty\":[\"l1\", \"l2\", \"elasticnet\"],\n",
    "              \"l1_ratio\":np.linspace(0,1,10),\n",
    "              \"solver\":[\"lbfgs\", \"saga\"]\n",
    "              }# l1 lasso l2 ridge\n",
    "\n",
    "# run randomized search\n",
    "if run_logistic:\n",
    "    random_search_model = RandomizedSearchCV(clf, \n",
    "                                       param_distributions=param_dict,\n",
    "                                       n_iter=20, \n",
    "                                       scoring='roc_auc', \n",
    "                                       cv=10, \n",
    "                                       n_jobs=-1)\n",
    "\n",
    "\n",
    "    # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    random_search_model.fit(X, Y)\n",
    "    model_dict[\"lr\"] = random_search_model\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYoge1Lo5Xy5",
    "outputId": "608485a4-911d-4c7f-b89b-b2ae06d5b4c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_precision_score: 0.53897\n",
      "roc_auc : 0.65288\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.93      0.79      1848\n",
      "           1       0.66      0.24      0.35      1017\n",
      "\n",
      "    accuracy                           0.69      2865\n",
      "   macro avg       0.67      0.59      0.57      2865\n",
      "weighted avg       0.68      0.69      0.64      2865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "    lr = model_dict[\"lr\"]\n",
    "    model_results(lr, dev_X, dev_Y)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure if useful\n",
    "# precision, recall, thresholds = metrics.precision_recall_curve(test_Y, lr.predict_proba(test_X)[:, 1], pos_label=1)\n",
    "\n",
    "# metrics.plot_precision_recall_curve(lr, test_X, test_Y, response_method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "id": "zLlnRF_s062y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken (min): 1.8\n"
     ]
    }
   ],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ug-A0ZPMDgZ7"
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8k3ZsgjHNjC"
   },
   "outputs": [],
   "source": [
    "# build a classifier\n",
    "clf = XGBRFClassifier()\n",
    "\n",
    "# A parameter grid for XGBoost\n",
    "# https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost\n",
    "param_dict = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n",
    "# run randomized search\n",
    "if run_models:\n",
    "    random_search_model = RandomizedSearchCV(clf, \n",
    "                                   param_distributions=param_dict,\n",
    "                                   n_iter=1, \n",
    "                                   scoring='roc_auc', \n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1)\n",
    "\n",
    "\n",
    "    # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    random_search_model.fit(X, Y)\n",
    "    model_dict[\"xgb\"] = random_search_model\n",
    "    model_dict[\"file_params\"] = file_param_dict    \n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "xgb = model_dict[\"xgb\"]\n",
    "y_predict = lr.predict(test_X) \n",
    "\n",
    "# threshold is taken as 0.5, as proven here\n",
    "# y_predict_ = 1 * (lr.predict_proba(test_X)[:, 1]>0.5) # \n",
    "# np.mean(y_predict == y_predict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(xgb, dev_X, dev_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "DqyeGmeqZXnZ",
    "outputId": "36dc804f-a60b-4a0c-87dd-d4a9bc62411f"
   },
   "outputs": [],
   "source": [
    "#Feature importance for top 50 predictors\n",
    "predictors = [x for x in df_X_combined_dummies_ordered.columns]\n",
    "feat_imp = pd.Series(xgb.best_estimator_.feature_importances_, predictors).sort_values(ascending=False)\n",
    "feat_imp = feat_imp[0:50]\n",
    "plt.rcParams['figure.figsize'] = 20, 5\n",
    "feat_imp.plot(kind='bar', title='Feature Importance')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ez1BBgTW_Bk"
   },
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-nU49jh6tULS",
    "outputId": "166d48d9-0f92-4c84-a479-c662c5172834"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/binilg/lightgbm-with-randomsearchcv-and-feature-imp\n",
    "# Implementation: https://www.kaggle.com/mlisovyi/lightgbm-hyperparameter-optimisation-lb-0-761\n",
    "# Documentation: https://lightgbm.readthedocs.io/en/latest/Features.html\n",
    "# LightGBM Classifier: https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#\n",
    "\n",
    "import lightgbm\n",
    "param_dict = {\n",
    "    'learning_rate': [0.05],\n",
    "    'num_leaves': [90,200],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'max_depth' : [5,6,7,8],\n",
    "    'random_state' : [501], \n",
    "    'colsample_bytree' : [0.5,0.7],\n",
    "    'subsample' : [0.5,0.7],\n",
    "    'min_split_gain' : [0.01],\n",
    "    'min_data_in_leaf':[10],\n",
    "    'metric':['auc']\n",
    "    }\n",
    "#modelling\n",
    "clf = lightgbm.LGBMClassifier()\n",
    "\n",
    "if run_models:\n",
    "    random_search_model = (RandomizedSearchCV(clf, \n",
    "                               param_dict, \n",
    "                               verbose=1, \n",
    "                               cv=10, \n",
    "                               n_jobs = -1, \n",
    "                               n_iter=10,\n",
    "                               scoring='roc_auc'))\n",
    "        # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    random_search_model.fit(X, Y)\n",
    "    model_dict[\"lgbm\"] = random_search_model\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "lgbm = model_dict[\"lgbm\"]\n",
    "y_predict = lgbm.predict(test_X) \n",
    "\n",
    "# threshold is taken as 0.5, as proven here\n",
    "# y_predict_ = 1 * (lr.predict_proba(test_X)[:, 1]>0.5) # \n",
    "# np.mean(y_predict == y_predict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ISubtXNPXo_-",
    "outputId": "54b42de5-9909-4c66-b451-e106a5181e02"
   },
   "outputs": [],
   "source": [
    "model_results(lgbm, dev_X, dev_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "id": "SaFbWsFQX5Vs",
    "outputId": "f00a317c-8b5f-4dd4-e538-8056b8a803be"
   },
   "outputs": [],
   "source": [
    "#Feature importance for top 50 predictors\n",
    "predictors = [x for x in df_X_combined_dummies_ordered.columns]\n",
    "feat_imp = pd.Series(lgbm.best_estimator_.feature_importances_, predictors).sort_values(ascending=False)\n",
    "feat_imp = feat_imp[0:50]\n",
    "plt.rcParams['figure.figsize'] = 20, 5\n",
    "feat_imp.plot(kind='bar', title='Feature Importance')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3RElmg55sOb"
   },
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers, meta_classifier, use_probas=False, cv=2, \n",
    "# use_features_in_secondary=False, stratify=True, shuffle=True, verbose=0, store_train_meta_features=False, use_clones=True)\n",
    "\n",
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "xgb = model_dict[\"xgb\"]\n",
    "lgbm = model_dict[\"lgbm\"]\n",
    "\n",
    "if run_models:\n",
    "    stack_gen_model = (StackingCVClassifier(classifiers=[xgb.best_estimator_,\n",
    "                                                         lgbm.best_estimator_], \n",
    "                                            meta_classifier=xgb.best_estimator_,\n",
    "                                            use_features_in_secondary=True,\n",
    "                                            use_probas=True,\n",
    "                                           random_state=random_state))\n",
    "\n",
    "    stack_gen_model.fit(X, Y)\n",
    "    model_dict[\"stacking\"] = stack_gen_model\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "    \n",
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "stacking = model_dict[\"stacking\"]\n",
    "y_predict = stacking.predict(test_X) \n",
    "y_score = stacking.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "n_classes = 2\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(test_Y, y_score[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_auc\n",
    "\n",
    "# # Compute micro-average ROC curve and ROC area\n",
    "# fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_Y.ravel(), y_score.ravel())\n",
    "# roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# plt.figure()\n",
    "# lw = 2\n",
    "# plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "#          lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver operating characteristic example')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(stack_gen_model, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Efv12Vc6ijNT"
   },
   "outputs": [],
   "source": [
    "if run_models:\n",
    "    vc_clf = (VotingClassifier(estimators=[(\"xbg\", model_dict[\"xgb\"]), \n",
    "                                           (\"lightgbm\", model_dict[\"lgbm\"]),\n",
    "                                          (\"stacking\", model_dict[\"stacking\"])],\n",
    "                                           voting=\"soft\",\n",
    "                                           flatten_transform=False))\n",
    "\n",
    "    vc_fit = vc_clf.fit(dev_X, dev_Y)\n",
    "    model_dict[\"voting_clf\"] = vc_fit\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "\n",
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "voting_clf = model_dict[\"voting_clf\"]\n",
    "y_predict = voting_clf.predict(test_X) \n",
    "y_score = voting_clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(voting_clf, test_X, test_Y)\n",
    "# find_roc_auc(vc_fit, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(fitted_model, test_X, test_Y):\n",
    "#     print(\"accuracy:\", np.mean(test_Y == log_best_model.predict(test_X)))\n",
    "#     print(\"balanced_accuracy_score:\", balanced_accuracy_score(test_Y, log_best_model.predict(test_X)))\n",
    "\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html\n",
    "    # AP summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold\n",
    "    print(\"average_precision_score:\", round(metrics.average_precision_score(test_Y, fitted_model.predict_proba(test_X)[:, 1], average=\"weighted\"), 5))\n",
    "    \n",
    "    y_prob = fitted_model.predict_proba(test_X)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_Y, y_prob[:, 1], pos_label=1)\n",
    "    print(\"roc_auc\",\":\", round(metrics.auc(fpr, tpr), 5))\n",
    "    \n",
    "    print(\"Classification Report:\") # threshold agnostic because you pass in the test labels instead of scores (probabilities)\n",
    "    print(classification_report(test_Y, fitted_model.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC_AUC on Test\")\n",
    "print(\"===============\")\n",
    "for model in model_dict.keys():\n",
    "    if model not in [\"file_params\"]:\n",
    "        print(\"{}:{}{}\".format(model, \" \"*(13 - len(model)), find_roc_auc(model_dict.get(model), test_X, test_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC_AUC on Dev\")\n",
    "print(\"==============\")\n",
    "for model in model_dict.keys():\n",
    "    if model not in [\"file_params\"]:\n",
    "        print(\"{}:{}{}\".format(model, \" \"*(13 - len(model)), find_roc_auc(model_dict.get(model), dev_X, dev_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC_AUC on Training\")\n",
    "print(\"===================\")\n",
    "for model in model_dict.keys():\n",
    "    if model not in [\"file_params\"]:\n",
    "        print(\"{}:{}{}\".format(model, \" \"*(13 - len(model)), find_roc_auc(model_dict.get(model), X, Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = np.array(df_test)\n",
    "model = \"lgbm\"\n",
    "y_predict = model_dict[model].predict(test_X)\n",
    "array2 = y_predict.reshape(y_predict.shape[0],1)\n",
    "array3 = np.hstack((array1, array2))\n",
    "df_pred = pd.DataFrame(array3, columns = list(df_test.columns) + [\"predictions\"])\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false negatives\n",
    "\n",
    "df_fn = df_pred[(df_pred.predictions == 0) & (df_pred.cwa_determination == 1)]\n",
    "df_fn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cols = ['cwa1', 'cwa2', 'cwa3', 'cwa4', 'cwa5', 'cwa6' , 'cwa7', 'cwa8', 'cwa9', 'cwa_determination','longitude', 'latitude', 'Index','da_number',\n",
    "       'jurisdiction_type', 'potential_wetland', \"predictions\"]\n",
    "df_fn[imp_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"lgbm\"\n",
    "model_results(model_dict[model], test_X, test_Y)\n",
    "confusion_matrix(test_Y, model_dict[model].predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false negatives\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df_fn['longitude'], df_fn['latitude'])]\n",
    "gdf = GeoDataFrame(df_fn, geometry=geometry)   \n",
    "\n",
    "#this is a simple map that goes with geopandas\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "north_america = world[world.continent == \"North America\"]\n",
    "gdf.plot(ax=north_america.plot(figsize=(20, 12)), marker='o', color='red', markersize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not false negatives\n",
    "df_not_fn = df_pred[~((df_pred.predictions == 0) & (df_pred.cwa_determination == 1))]\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df_not_fn['longitude'], df_not_fn['latitude'])]\n",
    "gdf = GeoDataFrame(df_not_fn, geometry=geometry)   \n",
    "\n",
    "gdf.plot(ax=north_america.plot(figsize=(20, 12)), marker='o', color='red', markersize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false positives\n",
    "df_fp = df_pred[(df_pred.predictions == 1) & (df_pred.cwa_determination == 0)]\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df_fp['longitude'], df_fp['latitude'])]\n",
    "gdf = GeoDataFrame(df_fp, geometry=geometry)   \n",
    "\n",
    "gdf.plot(ax=north_america.plot(figsize=(20, 12)), marker='o', color='red', markersize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All good predictions\n",
    "df_good_preds = df_pred[((df_pred.predictions == 0) & (df_pred.cwa_determination == 0)) | ((df_pred.predictions == 1) & (df_pred.cwa_determination == 1))]\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df_good_preds['longitude'], df_good_preds['latitude'])]\n",
    "gdf = GeoDataFrame(df_good_preds, geometry=geometry)   \n",
    "\n",
    "gdf.plot(ax=north_america.plot(figsize=(20, 12)), marker='o', color='red', markersize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df_pred['longitude'], df_pred['latitude'])]\n",
    "gdf = GeoDataFrame(df_pred, geometry=geometry)   \n",
    "\n",
    "gdf.plot(ax=north_america.plot(figsize=(20, 12)), marker='o', color='red', markersize=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySEfwFTbEOsU"
   },
   "source": [
    "# Break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gximuif9tUZe"
   },
   "outputs": [],
   "source": [
    "df_fn[df_fn.state == '12'][\"hydclprs\"]#['da_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_fn.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5tIApogtUce"
   },
   "outputs": [],
   "source": [
    "\n",
    "random_search_fitted_models[\"xgb\"].__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_ugRFjytUet"
   },
   "outputs": [],
   "source": [
    "random_search_fitted_models[\"lgbm\"].cv_results_#[\"param_num_leaves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJxn_V1lcnUd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2021.03.19_WOTUS_restart_v6.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
