{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gh39s2KK_dGM"
   },
   "outputs": [],
   "source": [
    "# - v1: works till the categorical pipeline where it errors out for unknown variables\n",
    "# - v2: fully functional\n",
    "# - v3: baseline run (on the old dataset)\n",
    "# - v4: baseline run (on the full 2021.03.17_full_dataset)\n",
    "# - v5: baseline run (on 2021.03.19_full_dataset with all SSURGO variables)\n",
    "# - v6: aoc_roc (on 2021.03.19_full_dataset with all SSURGO variables). Mute the Stacking as it is not possible with RandomizedSearchCV. Have to have a dev split.\n",
    "# - v7: model v7 random state 123 on train/test, model v7.1 random_state 431 on train/dev/test\n",
    "# - v8g: Golden model\n",
    "\n",
    "# - ROC_AUC with lat, lon (baseline)\n",
    "# ====================\n",
    "# lr:           0.64103\n",
    "# xgb:          0.82366\n",
    "# voting_clf:   0.83027\n",
    "# lgbm:         0.86395\n",
    "# stacking:     0.85923\n",
    "\n",
    "\n",
    "# - v9: without lat, lon\n",
    "\n",
    "# - ROC_AUC without lat, lon\n",
    "# =======================\n",
    "# lr:           0.64211\n",
    "# xgb:          0.8031\n",
    "# voting_clf:   0.83105\n",
    "# lgbm:         0.85952\n",
    "# stacking:     0.85427\n",
    "\n",
    "# - v9.1: without lat, lon, potential_wetland\n",
    "\n",
    "# - ROC_AUC without lat, lon, potential_wetland\n",
    "# ===============\n",
    "# lr:           0.63992\n",
    "# xgb:          0.79093\n",
    "# voting_clf:   0.82987\n",
    "# lgbm:         0.85143\n",
    "# stacking:     0.84328\n",
    "\n",
    "# - v9.2: without lat, lon, potential_wetland, district\n",
    "\n",
    "# - ROC_AUC without lat, lon, potential_wetland, district\n",
    "# ===============\n",
    "# lr:           0.64208\n",
    "# xgb:          0.77907\n",
    "# voting_clf:   0.79829\n",
    "# lgbm:         0.82675\n",
    "# stacking:     0.82185\n",
    "\n",
    "# - v9.3: without lat, lon, potential_wetland, district and flodfreqdc and drclassdcd as ordinal\n",
    "\n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.6382\n",
    "# xgb:          0.73089\n",
    "# voting_clf:   0.79126\n",
    "# lgbm:         0.82512\n",
    "# stacking:     0.8195\n",
    "\n",
    "# - v9.4: without lat, lon, potential_wetland, district, county \n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.6395\n",
    "# xgb:          0.74096\n",
    "# voting_clf:   0.7911\n",
    "# lgbm:         0.82448\n",
    "# stacking:     0.82343\n",
    "\n",
    "# - v9.5: without lat, lon, potential_wetland, district, county, mukey\n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.65309\n",
    "# xgb:          0.75117\n",
    "# voting_clf:   0.77845\n",
    "# lgbm:         0.80626\n",
    "# stacking:     0.80424\n",
    "\n",
    "# - v9.5: without lat, lon, potential_wetland, district, county, mukey, and filtering out bad latitude\n",
    "# THIS IS SUSPECT. CANT REPEAT IT.\n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.63894\n",
    "# xgb:          0.74922\n",
    "# voting_clf:   0.79839\n",
    "# lgbm:         0.86986\n",
    "# stacking:     0.86281\n",
    "\n",
    "# - v9,5_r2: supposed to be repeat of v9.5 but unsuccessful (probably bcoz of wrong cat features)\n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.64148\n",
    "# xgb:          0.7066\n",
    "# lgbm:         0.79702\n",
    "# stacking:     0.78626\n",
    "# voting_clf:   0.7632\n",
    "\n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.62669\n",
    "# xgb:          0.71814\n",
    "# lgbm:         0.8006\n",
    "# stacking:     0.80005\n",
    "# voting_clf:   0.7683\n",
    "\n",
    "# - v9.6: baseline and filtering out bad latitude\n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.6306\n",
    "# xgb:          0.79659\n",
    "# voting_clf:   0.82816\n",
    "# lgbm:         0.85251\n",
    "# stacking:     0.84547\n",
    "\n",
    "# - v9.6_r2: baseline and filtering out bad latitude\n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.6302\n",
    "# xgb:          0.81153\n",
    "# voting_clf:   0.83019\n",
    "# lgbm:         0.85353\n",
    "# stacking:     0.85285\n",
    "\n",
    "\n",
    "# - ROC_AUC with lat, lon (baseline)\n",
    "# ====================\n",
    "# lr:           0.64103\n",
    "# xgb:          0.82366\n",
    "# voting_clf:   0.83027\n",
    "# lgbm:         0.86395\n",
    "# stacking:     0.85923\n",
    "\n",
    "# - v9.4: without lat, lon, potential_wetland, district, county \n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.6395\n",
    "# xgb:          0.74096\n",
    "# voting_clf:   0.7911\n",
    "# lgbm:         0.82448\n",
    "# stacking:     0.82343\n",
    "\n",
    "# - v10: baseline (with huc6, nearest wb/fl parameters added)\n",
    "\n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.64444\n",
    "# xgb:          0.80494\n",
    "# voting_clf:   0.82554\n",
    "# lgbm:         0.85336\n",
    "# stacking:     0.8514\n",
    "\n",
    "# - v10.1: baseline (with huc4, nearest wb/fl parameters added)\n",
    "# -ROC_AUC on Test\n",
    "# ===============\n",
    "\n",
    "# lr:           0.64381\n",
    "# voting_clf:   0.82879\n",
    "# xgb:          0.8032\n",
    "# lgbm:         0.85318\n",
    "# stacking:     0.8495\n",
    "\n",
    "# - ROC_AUC on Test: supposed to be repeat of v10.1, but not sure why results are not reproducible\n",
    "# ===============\n",
    "\n",
    "# lr:           0.64381\n",
    "# voting_clf:   0.77483\n",
    "# xgb:          0.75691\n",
    "# lgbm:         0.79563\n",
    "# stacking:     0.78974\n",
    "\n",
    "# - v10.1_rerun: rerunning again and tested by reading back the model file. reproducible results. \n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.64384\n",
    "# voting_clf:   0.8299\n",
    "# xgb:          0.78993\n",
    "# lgbm:         0.85403\n",
    "# stacking:     0.8468\n",
    "\n",
    "\n",
    "# - v10.2: v10.1 with log transformed closest distances (slight improvement seen)\n",
    "# - ROC_AUC on Test: can not reproduce these results the next day. So rerunning again below:\n",
    "# ===============\n",
    "# lr:           0.64219\n",
    "# voting_clf:   0.82924\n",
    "# xgb:          0.7662\n",
    "# lgbm:         0.85495\n",
    "# stacking:     0.85232\n",
    "\n",
    "# - v10.2_rerun:\n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.64251\n",
    "# voting_clf:   0.82815\n",
    "# xgb:          0.74756\n",
    "# lgbm:         0.854\n",
    "# stacking:     0.84738\n",
    "\n",
    "# - v12: implemented the ppv/npv version\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7711, npv = 0.7734 @ threshold = 0.4949\n",
    "# lr:            ppv = 0.6522, npv = 0.6365 @ threshold = 0.5152\n",
    "# xgb:           ppv = 0.7448, npv = 0.7208 @ threshold = 0.5152\n",
    "# stacking:      ppv = 0.7691, npv = 0.7698 @ threshold = 0.5354\n",
    "# voting_clf:    ppv = 0.7598, npv = 0.7562 @ threshold = 0.4949\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lr:           0.62682\n",
    "# voting_clf:   0.82891\n",
    "# xgb:          0.7816\n",
    "# lgbm:         0.84274\n",
    "# stacking:     0.83437\n",
    "\n",
    "    \n",
    "    \n",
    "# v13: data stratification by district\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7893, npv = 0.7873 @ threshold = 0.5253\n",
    "# lr:            ppv = 0.7053, npv = 0.6413 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7731, npv = 0.7593 @ threshold = 0.4545\n",
    "# stacking:      ppv = 0.7992, npv = 0.7788 @ threshold = 0.5253\n",
    "# voting_clf:    ppv = 0.7757, npv = 0.771 @ threshold = 0.5152\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "\n",
    "# lr:           0.63472\n",
    "# voting_clf:   0.84121\n",
    "# xgb:          0.81637\n",
    "# lgbm:         0.86547\n",
    "# stacking:     0.86017\n",
    "\n",
    "# v13.1: with use_features_in_secondary=False in Stacking (this is slightly better)\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7885, npv = 0.7862 @ threshold = 0.5253\n",
    "# lr:            ppv = 0.7053, npv = 0.6413 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7619, npv = 0.7509 @ threshold = 0.4646\n",
    "# stacking:      ppv = 0.7752, npv = 0.7748 @ threshold = 0.5657 (notice the threshold has increased slightly, ppv (and npv?) decreased)\n",
    "# voting_clf:    ppv = 0.7806, npv = 0.7711 @ threshold = 0.5051\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "\n",
    "# lr:           0.63471\n",
    "# voting_clf:   0.84039\n",
    "# xgb:          0.80691\n",
    "# lgbm:         0.86276\n",
    "# stacking:     0.86068\n",
    "\n",
    "# v13.2:\n",
    "# Using 475 principal components\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.754, npv = 0.7611 @ threshold = 0.4949\n",
    "# lr:            ppv = 0.7241, npv = 0.6409 @ threshold = 0.5455\n",
    "# xgb:           ppv = 0.712, npv = 0.7091 @ threshold = 0.4343\n",
    "# stacking:      ppv = 0.7581, npv = 0.7472 @ threshold = 0.5152\n",
    "# voting_clf:    ppv = 0.7472, npv = 0.7506 @ threshold = 0.4848\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.82615\n",
    "# lr:           0.63732\n",
    "# xgb:          0.73877\n",
    "# stacking:     0.81755\n",
    "# voting_clf:   0.81281\n",
    "\n",
    "# v15: knn imputing of variables at nan_th = 0.2\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7746, npv = 0.7718 @ threshold = 0.5556\n",
    "# lr:            ppv = 0.7053, npv = 0.6413 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7313, npv = 0.7284 @ threshold = 0.4848\n",
    "# stacking:      ppv = 0.7785, npv = 0.7732 @ threshold = 0.5253\n",
    "# voting_clf:    ppv = 0.7531, npv = 0.7545 @ threshold = 0.5152\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lr:           0.62915\n",
    "# voting_clf:   0.81977\n",
    "# xgb:          0.77361\n",
    "# lgbm:         0.8542\n",
    "# stacking:     0.85236\n",
    "\n",
    "\n",
    "# v17: with svc and knn\n",
    "\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7787, npv = 0.77 @ threshold = 0.5455\n",
    "# lr:            ppv = 0.7053, npv = 0.6413 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7273, npv = 0.7205 @ threshold = 0.5051\n",
    "# stacking:      ppv = 0.784, npv = 0.766 @ threshold = 0.5657\n",
    "# voting_clf:    ppv = 0.7534, npv = 0.7585 @ threshold = 0.5051\n",
    "# lgbm_second_level: ppv = 0.8, npv = 0.6308 @ threshold = 0.5657\n",
    "# svc:           ppv = 0.6718, npv = 0.6441 @ threshold = 0.5859\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.85012\n",
    "# lr:           0.62915\n",
    "# xgb:          0.76222\n",
    "# stacking:     0.84442\n",
    "# voting_clf:   0.82\n",
    "# lgbm_second_level:0.50845\n",
    "# svc:          0.67335\n",
    "\n",
    "# v18: Removed Alaska because no SSURGO data. Also, the saved model works!\n",
    "\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7828, npv = 0.7813 @ threshold = 0.5253\n",
    "# lr:            ppv = 0.7053, npv = 0.6359 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7216, npv = 0.7305 @ threshold = 0.3636\n",
    "# stacking:      ppv = 0.758, npv = 0.7954 @ threshold = 0.4242\n",
    "# voting_clf:    ppv = 0.7854, npv = 0.765 @ threshold = 0.5152\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.8642\n",
    "# lr:           0.63127\n",
    "# xgb:          0.77811\n",
    "# stacking:     0.85698\n",
    "# voting_clf:   0.83492\n",
    "\n",
    "# v21: 1000m and 2500m data\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7762, npv = 0.7737 @ threshold = 0.5556\n",
    "# lgbm_groups:   ppv = 0.649, npv = 0.6461 @ threshold = 0.1111\n",
    "# lr:            ppv = 1.0, npv = 0.6252 @ threshold = 0.6364\n",
    "# xgb:           ppv = 0.7304, npv = 0.7347 @ threshold = 0.6061\n",
    "# stacking:      ppv = 0.7869, npv = 0.7513 @ threshold = 0.5354\n",
    "# voting_clf:    ppv = 0.7614, npv = 0.7614 @ threshold = 0.5455\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.85726\n",
    "# lgbm_groups:  0.68616\n",
    "# lr:           0.62552\n",
    "# xgb:          0.79837\n",
    "# stacking:     0.84893\n",
    "# voting_clf:   0.83079\n",
    "\n",
    "# v22: 200m and 1000m... clearly this is the best. Next thing to try is capture the seasonality of the nearby wbs and fls\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7881, npv = 0.7837 @ threshold = 0.5354\n",
    "# lgbm_groups:   ppv = 0.6699, npv = 0.6475 @ threshold = 0.1111\n",
    "# lr:            ppv = 0.7473, npv = 0.6368 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7412, npv = 0.7333 @ threshold = 0.4343\n",
    "# stacking:      ppv = 0.7808, npv = 0.7836 @ threshold = 0.4545\n",
    "# voting_clf:    ppv = 0.7759, npv = 0.7733 @ threshold = 0.5051\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.8641\n",
    "# lgbm_groups:  0.66912\n",
    "# lr:           0.64632\n",
    "# xgb:          0.78758\n",
    "# stacking:     0.85629\n",
    "# voting_clf:   0.84187\n",
    "\n",
    "# v22.1: remove Charleston that contributed the most to fn's in v22\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.8063, npv = 0.805 @ threshold = 0.5657\n",
    "# lgbm_groups:   ppv = 0.6667, npv = 0.6606 @ threshold = 0.0909\n",
    "# lr:            ppv = 0.7471, npv = 0.6427 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7738, npv = 0.7726 @ threshold = 0.4949\n",
    "# stacking:      ppv = 0.7994, npv = 0.7991 @ threshold = 0.5758\n",
    "# voting_clf:    ppv = 0.7906, npv = 0.7922 @ threshold = 0.5556\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.88234\n",
    "# lgbm_groups:  0.69274\n",
    "# lr:           0.65399\n",
    "# xgb:          0.83822\n",
    "# stacking:     0.8749\n",
    "# voting_clf:   0.86033    \n",
    "\n",
    "# \"east_coast = [\"Galveston\", \"New Orleans\", \n",
    "# \"Mobile\", \"Jacksonville\", \"Savannah\", \"Charleston\", 'Wilmington', \"Norfolk\", \"Baltimore\", \"Philadelphia\"]\n",
    "# clear but small improvement but the problem is Charleston was filtered out\n",
    "\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.8074, npv = 0.8068 @ threshold = 0.5657\n",
    "# lgbm_groups:   ppv = 0.6823, npv = 0.6554 @ threshold = 0.101\n",
    "# lr:            ppv = 0.7471, npv = 0.6427 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7807, npv = 0.7757 @ threshold = 0.5253\n",
    "# stacking:      ppv = 0.7992, npv = 0.8091 @ threshold = 0.5556\n",
    "# voting_clf:    ppv = 0.7957, npv = 0.7966 @ threshold = 0.5455\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.88673\n",
    "# lgbm_groups:  0.68095\n",
    "# lr:           0.65398\n",
    "# xgb:          0.84006\n",
    "# stacking:     0.88012\n",
    "# voting_clf:   0.86537\n",
    "\n",
    "\n",
    "# east_coast = [\"New Orleans\", \"Charleston\"]  but the problem is Charleston was filtered out\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.8079, npv = 0.8078 @ threshold = 0.5758\n",
    "# lgbm_groups:   ppv = 0.6776, npv = 0.6583 @ threshold = 0.0909\n",
    "# lr:            ppv = 0.7471, npv = 0.6427 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7495, npv = 0.7353 @ threshold = 0.5253\n",
    "# stacking:      ppv = 0.8023, npv = 0.8002 @ threshold = 0.5758\n",
    "# voting_clf:    ppv = 0.7912, npv = 0.7915 @ threshold = 0.5253\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.8876\n",
    "# lgbm_groups:  0.68694\n",
    "# lr:           0.65398\n",
    "# xgb:          0.82051\n",
    "# stacking:     0.88411\n",
    "# voting_clf:   0.86108\n",
    "\n",
    "# east_coast = [\"New Orleans\", \"Charleston\"]  with Charleston included\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7797, npv = 0.7796 @ threshold = 0.5253\n",
    "# lgbm_groups:   ppv = 0.652, npv = 0.6459 @ threshold = 0.1111\n",
    "# lr:            ppv = 0.7473, npv = 0.6368 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7587, npv = 0.7543 @ threshold = 0.4646\n",
    "# stacking:      ppv = 0.7835, npv = 0.7811 @ threshold = 0.5253\n",
    "# voting_clf:    ppv = 0.7691, npv = 0.7706 @ threshold = 0.5152\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.85836\n",
    "# lgbm_groups:  0.67909\n",
    "# lr:           0.64631\n",
    "# xgb:          0.82203\n",
    "# stacking:     0.84927\n",
    "# voting_clf:   0.83851\n",
    "\n",
    "\n",
    "# v23: best so far. v22 with east_coast variable\n",
    "# \"east_coast = [\"Galveston\", \"New Orleans\", \n",
    "# \"Mobile\", \"Jacksonville\", \"Savannah\", \"Charleston\", 'Wilmington', \"Norfolk\", \"Baltimore\", \"Philadelphia\"]\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7841, npv = 0.778 @ threshold = 0.5354\n",
    "# lgbm_groups:   ppv = 0.6432, npv = 0.6432 @ threshold = 0.1212\n",
    "# lr:            ppv = 0.7473, npv = 0.6368 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7236, npv = 0.7226 @ threshold = 0.5152\n",
    "# stacking:      ppv = 0.7843, npv = 0.7784 @ threshold = 0.5253\n",
    "# voting_clf:    ppv = 0.7728, npv = 0.7706 @ threshold = 0.5253\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.85921\n",
    "# lgbm_groups:  0.66969\n",
    "# lr:           0.64629\n",
    "# xgb:          0.78917\n",
    "# stacking:     0.84483\n",
    "# voting_clf:   0.83592\n",
    "\n",
    "\n",
    "\n",
    "# v24: without lat, lon, potential_wetland, district, county, mukey\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7711, npv = 0.7684 @ threshold = 0.5152\n",
    "# lgbm_groups:   ppv = 0.6779, npv = 0.6412 @ threshold = 0.1313\n",
    "# lr:            ppv = 0.7473, npv = 0.6368 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7458, npv = 0.7338 @ threshold = 0.5152\n",
    "# stacking:      ppv = 0.7683, npv = 0.7651 @ threshold = 0.5354\n",
    "# voting_clf:    ppv = 0.7667, npv = 0.76 @ threshold = 0.5455\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.84013\n",
    "# lgbm_groups:  0.64607\n",
    "# lr:           0.64698\n",
    "# xgb:          0.79118\n",
    "# stacking:     0.83714\n",
    "# voting_clf:   0.82432\n",
    "\n",
    "# v24_not_saved: without lat, lon, potential_wetland, district, county, mukey with lr in the stacking\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7711, npv = 0.7684 @ threshold = 0.5152\n",
    "# lgbm_groups:   ppv = 0.6779, npv = 0.6412 @ threshold = 0.1313\n",
    "# lr:            ppv = 0.7473, npv = 0.6368 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7458, npv = 0.7338 @ threshold = 0.5152\n",
    "# stacking:      ppv = 0.7674, npv = 0.7598 @ threshold = 0.5455\n",
    "# voting_clf:    ppv = 0.7667, npv = 0.76 @ threshold = 0.5455\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.84013\n",
    "# lgbm_groups:  0.64607\n",
    "# lr:           0.64698\n",
    "# xgb:          0.79118\n",
    "# stacking:     0.83563\n",
    "# voting_clf:   0.82432\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wj4LjNpHOzc9",
    "outputId": "6b01c399-d6fc-46c6-f622-ac200674afb8"
   },
   "outputs": [],
   "source": [
    "# !pip install lightgbm\n",
    "# !pip install xgboost\n",
    "# !pip install mlxtend\n",
    "# !pip install seaborn\n",
    "# !pip install shapely\n",
    "# !pip install geopandas\n",
    "# !pip install metric_learn\n",
    "# import pickle\n",
    "\n",
    "# !pip3 install keras\n",
    "# !pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "y6CJ-2pyO-Pu"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from optimize_ppv_npv_scorer_ import optimize_ppv_npv_scorer\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# SK-learn libraries for machine learning\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import *\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import xgboost\n",
    "import lightgbm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants and Data imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE_NAME = \"Merge_all_datasets/2021.03.31_200m_1000m\"\n",
    "FILE_VERSION = \"v24_repeat\"\n",
    "\n",
    "run_models = True # BEWARE! This overwrites the models stored on disk\n",
    "run_logistic = True\n",
    "no_lat_lon = True\n",
    "\n",
    "run_svc = False\n",
    "run_autoencoder = False\n",
    "run_knn = False\n",
    "run_svc_second_level = False\n",
    "\n",
    "# file params\n",
    "golden_models = [\"v21\", \"v22\", \"v23\", \"v24\"]\n",
    "stop_before_models = False\n",
    "\n",
    "\n",
    "if run_models:\n",
    "    model_dict = {}\n",
    "    file_param_dict = {}\n",
    "    random_state = 123 # for train, dev, test splits\n",
    "    dev = True\n",
    "    file_param_dict[\"random_state\"] = random_state\n",
    "    file_param_dict[\"dev\"] = dev\n",
    "    file_param_dict[\"input_file_name\"] = INPUT_FILE_NAME\n",
    "\n",
    "else:\n",
    "    model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "    try:\n",
    "        file_param_dict = model_dict[\"file_params\"]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "        \n",
    "    random_state = file_param_dict[\"random_state\"]\n",
    "    dev = file_param_dict[\"dev\"]\n",
    "    INPUT_FILE_NAME = file_param_dict[\"input_file_name\"]\n",
    "\n",
    "if FILE_VERSION in golden_models:\n",
    "    if run_models:\n",
    "        print(\"Warning: you are overwriting golden model\")\n",
    "        stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1q95q-9wPEky"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14619, 495)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_pickle(\"../../../data/\" + INPUT_FILE_NAME)\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CWA determinations as groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_full = pd.read_pickle(\"../../../data/\" + INPUT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_full.columns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: 1,2,3,5\n",
    "# 2: 4,6,7\n",
    "# 3: 8 ,9\n",
    "\n",
    "def check_box_grouping(x):\n",
    "    if x.cwa1 + x.cwa2 + x.cwa3 + x.cwa5 > 0:\n",
    "        return 1\n",
    "    elif x.cwa4 + x.cwa6 + x.cwa7 > 0:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "    \n",
    "    \n",
    "def check_box_grouping(x):\n",
    "    if x.cwa1 + x.cwa3 + x.cwa5 > 0:\n",
    "        return 1\n",
    "    elif  x.cwa2 + x.cwa4 + x.cwa6 + x.cwa7 > 0:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[\"cwa_determination_groups\"] = df_full.apply(lambda x: check_box_grouping(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14613, 496)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove longitude > -50 (bad datapoints)\n",
    "\n",
    "df_full = df_full[df_full.longitude < -50]\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['latitude', 'cwa7', 'cwa8', 'jurisdiction_type', 'cwa9',\n",
       "       'cwa_determination', 'rha1', 'date_issued_or_denied',\n",
       "       'potential_wetland', 'cwa2',\n",
       "       ...\n",
       "       'nwi_SUBCLASS_NAME_evergreen_1000m',\n",
       "       'nwi_FIRST_MODIFIER_NAME_managed_1000m',\n",
       "       'nwi_SUBCLASS_NAME_algal_1000m', 'nwi_CLASS_NAME_forested_1000m',\n",
       "       'nwi_CLASS_NAME_scrub-shrub_1000m', 'nwi_SUBSYSTEM_NAME_subtidal_1000m',\n",
       "       'nwi_WATER_REGIME_NAME_artificially_flooded_1000m',\n",
       "       'nwi_WATER_REGIME_NAME_seasonally_flooded_1000m',\n",
       "       'nwi_SUBCLASS_NAME_vegetated_1000m', 'cwa_determination_groups'],\n",
       "      dtype='object', length=496)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce East Coast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "east_coast = [\"Galveston\", \"New Orleans\", \"Mobile\", \"Jacksonville\", \"Savannah\", \"Charleston\", 'Wilmington', \"Norfolk\", \"Baltimore\", \"Philadelphia\"]\n",
    "# east_coast = [\"New Orleans\", \"Charleston\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[\"east_coast\"] = df_full.apply(lambda x: \"yes\" if x.district in east_coast else \"no\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vmXibdpmoSgz"
   },
   "outputs": [],
   "source": [
    "df_full = df_full[df_full.district != \"Alaska\"] # no SSURGO data for Alaska Charleston\n",
    "# df_full = df_full[df_full.district != \"Charleston\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V4OSS7EfFWLD",
    "outputId": "5cba5f6a-118e-4979-8194-000e45123b90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%good records = 98%\n"
     ]
    }
   ],
   "source": [
    "# any records where the cwa_determination is contrary to expectations?\n",
    "good_records = (df_full.apply(lambda x: \n",
    "               (np.sum(x.cwa1 + x.cwa2 + x.cwa3 + x.cwa4 + x.cwa5 + \n",
    "                       x.cwa6 + x.cwa7 + x.cwa8 + x.cwa9) > 0) * 1 \n",
    "               == x.cwa_determination, \n",
    "               axis=1))\n",
    "\n",
    "print(\"%good records = {}%\".format(round(np.mean(good_records) * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "MUI--cUNFmXp",
    "outputId": "08a07e58-d2a0-4ead-c85a-7e9edbf94883"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>cwa7</th>\n",
       "      <th>cwa8</th>\n",
       "      <th>jurisdiction_type</th>\n",
       "      <th>cwa9</th>\n",
       "      <th>cwa_determination</th>\n",
       "      <th>rha1</th>\n",
       "      <th>date_issued_or_denied</th>\n",
       "      <th>potential_wetland</th>\n",
       "      <th>cwa2</th>\n",
       "      <th>...</th>\n",
       "      <th>nwi_FIRST_MODIFIER_NAME_managed_1000m</th>\n",
       "      <th>nwi_SUBCLASS_NAME_algal_1000m</th>\n",
       "      <th>nwi_CLASS_NAME_forested_1000m</th>\n",
       "      <th>nwi_CLASS_NAME_scrub-shrub_1000m</th>\n",
       "      <th>nwi_SUBSYSTEM_NAME_subtidal_1000m</th>\n",
       "      <th>nwi_WATER_REGIME_NAME_artificially_flooded_1000m</th>\n",
       "      <th>nwi_WATER_REGIME_NAME_seasonally_flooded_1000m</th>\n",
       "      <th>nwi_SUBCLASS_NAME_vegetated_1000m</th>\n",
       "      <th>cwa_determination_groups</th>\n",
       "      <th>east_coast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>43.10595</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RAPANOS</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>02/14/2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>43.19710</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RAPANOS</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>03/14/2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>43.13072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RAPANOS</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>07/12/2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 497 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude  cwa7  cwa8 jurisdiction_type  cwa9  cwa_determination  rha1  \\\n",
       "36  43.10595     0     0           RAPANOS     0                  1     0   \n",
       "50  43.19710     0     0           RAPANOS     0                  1     0   \n",
       "56  43.13072     0     0           RAPANOS     0                  1     0   \n",
       "\n",
       "   date_issued_or_denied  potential_wetland  cwa2  ...  \\\n",
       "36            02/14/2017                  1     0  ...   \n",
       "50            03/14/2018                  1     0  ...   \n",
       "56            07/12/2017                  1     0  ...   \n",
       "\n",
       "    nwi_FIRST_MODIFIER_NAME_managed_1000m  nwi_SUBCLASS_NAME_algal_1000m  \\\n",
       "36                                      0                              0   \n",
       "50                                      0                              0   \n",
       "56                                      0                              0   \n",
       "\n",
       "    nwi_CLASS_NAME_forested_1000m nwi_CLASS_NAME_scrub-shrub_1000m  \\\n",
       "36                              0                                1   \n",
       "50                              2                                0   \n",
       "56                              4                                1   \n",
       "\n",
       "    nwi_SUBSYSTEM_NAME_subtidal_1000m  \\\n",
       "36                                  0   \n",
       "50                                  0   \n",
       "56                                  0   \n",
       "\n",
       "    nwi_WATER_REGIME_NAME_artificially_flooded_1000m  \\\n",
       "36                                                 0   \n",
       "50                                                 0   \n",
       "56                                                 0   \n",
       "\n",
       "   nwi_WATER_REGIME_NAME_seasonally_flooded_1000m  \\\n",
       "36                                              2   \n",
       "50                                              4   \n",
       "56                                              4   \n",
       "\n",
       "    nwi_SUBCLASS_NAME_vegetated_1000m  cwa_determination_groups  east_coast  \n",
       "36                                  0                         3          no  \n",
       "50                                  0                         3          no  \n",
       "56                                  0                         3          no  \n",
       "\n",
       "[3 rows x 497 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek at not good records\n",
    "df_full[~good_records].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['latitude', 'cwa7', 'cwa8', 'jurisdiction_type', 'cwa9',\n",
       "       'cwa_determination', 'rha1', 'date_issued_or_denied',\n",
       "       'potential_wetland', 'cwa2',\n",
       "       ...\n",
       "       'nwi_FIRST_MODIFIER_NAME_managed_1000m',\n",
       "       'nwi_SUBCLASS_NAME_algal_1000m', 'nwi_CLASS_NAME_forested_1000m',\n",
       "       'nwi_CLASS_NAME_scrub-shrub_1000m', 'nwi_SUBSYSTEM_NAME_subtidal_1000m',\n",
       "       'nwi_WATER_REGIME_NAME_artificially_flooded_1000m',\n",
       "       'nwi_WATER_REGIME_NAME_seasonally_flooded_1000m',\n",
       "       'nwi_SUBCLASS_NAME_vegetated_1000m', 'cwa_determination_groups',\n",
       "       'east_coast'],\n",
       "      dtype='object', length=497)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_full.apply(lambda x: np.log(x.closest_wb_distance_m), axis=1))\n",
    "df_full[\"closest_wb_distance_m\"] = df_full.apply(lambda x: np.log(x.closest_wb_distance_m), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_full.apply(lambda x: np.log(x.closest_fl_distance_m), axis=1))\n",
    "df_full[\"closest_fl_distance_m\"] = df_full.apply(lambda x: np.log(x.closest_fl_distance_m), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_full.apply(lambda x: np.log(x.closest_wb_area_sqkm) if x.closest_wb_area_sqkm > 0 else np.nan, axis=1))\n",
    "df_full[\"closest_wb_area_sqkm\"] = df_full.apply(lambda x: np.log(x.closest_wb_area_sqkm) if x.closest_wb_area_sqkm > 0 else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_full.apply(lambda x: np.log(x.closest_fl_area_sqkm) if x.closest_fl_area_sqkm > 0 else np.nan, axis=1))\n",
    "df_full[\"closest_fl_area_sqkm\"] = df_full.apply(lambda x: np.log(x.closest_fl_area_sqkm) if x.closest_fl_area_sqkm > 0 else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAATXklEQVR4nO3df4xd5X3n8fen5keqtlubMnWpba2t1tvKVK2DpsAq+0cWNmBoVZNVExlVxcsiuZGMlEpVW9NIS5vUElG3ZZfdBMldvDFVNq6VNsIibolLqKL8AXhoXAdDWGYhyLYcPI0JaYTKyuS7f9zH5a4z47ljj2ccnvdLurrnfM9zznnOAc3H59c9qSokSf35gcXugCRpcRgAktQpA0CSOmUASFKnDABJ6tQli92Bs7nyyitr9erVi90NSfq+8swzz/xDVY3N1u6iDoDVq1czMTGx2N2QpO8rSV4ZpZ2ngCSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMX9ZPAkrTYVm/7/KKs9+v3/dIFX4dHAJLUKQNAkjo1cgAkWZLkK0kebeNrkjyVZDLJnye5rNUvb+OTbfrqoWXc0+ovJLl53rdGkjSyuRwBfBh4fmj848D9VfXTwGvAXa1+F/Baq9/f2pFkHbAJuBrYAHwyyZLz674k6VyNFABJVgK/BPyPNh7gBuCzrcku4LY2vLGN06bf2NpvBHZX1ZtV9TIwCVw7D9sgSToHox4B/Bfgd4DvtvEfA75VVafa+FFgRRteARwBaNNfb+3/uT7NPP8syZYkE0kmpqamRt8SSdKczBoASX4ZOFFVzyxAf6iqHVU1XlXjY2OzvtBGknSORnkO4D3AryS5FXgX8C+A/wosTXJJ+1f+SuBYa38MWAUcTXIJ8KPAN4fqpw3PI0laYLMeAVTVPVW1sqpWM7iI+8Wq+jXgCeBXW7PNwCNteG8bp03/YlVVq29qdwmtAdYCT8/blkiS5uR8ngT+XWB3kj8EvgI81OoPAX+WZBI4ySA0qKrDSfYAzwGngK1V9dZ5rF+SdB7mFABV9bfA37bhl5jmLp6q+ifgAzPMvx3YPtdOSpLmn08CS1KnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6NcpL4d+V5Okkf5/kcJI/aPVPJXk5ycH2Wd/qSfJAkskkh5JcM7SszUlebJ/NM6xSkrQARnkj2JvADVX1nSSXAl9O8ldt2m9X1WfPaH8Lg/f9rgWuAx4ErktyBXAvMA4U8EySvVX12nxsiCRpbkZ5KXxV1Xfa6KXtU2eZZSPwcJvvSWBpkquAm4H9VXWy/dHfD2w4v+5Lks7VSNcAkixJchA4weCP+FNt0vZ2muf+JJe32grgyNDsR1ttpvqZ69qSZCLJxNTU1Ny2RpI0spECoKreqqr1wErg2iQ/B9wD/Czwi8AVwO/OR4eqakdVjVfV+NjY2HwsUpI0jTndBVRV3wKeADZU1fF2mudN4H8C17Zmx4BVQ7OtbLWZ6pKkRTDKXUBjSZa24R8E3gd8rZ3XJ0mA24Bn2yx7gTva3UDXA69X1XHgMeCmJMuSLANuajVJ0iIY5S6gq4BdSZYwCIw9VfVoki8mGQMCHAQ+1NrvA24FJoE3gDsBqupkko8BB1q7j1bVyXnbEknSnMwaAFV1CHj3NPUbZmhfwNYZpu0Eds6xj5KkC8AngSWpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnRrllZDvSvJ0kr9PcjjJH7T6miRPJZlM8udJLmv1y9v4ZJu+emhZ97T6C0luvmBbJUma1ShHAG8CN1TVLwDrgQ3tXb8fB+6vqp8GXgPuau3vAl5r9ftbO5KsAzYBVwMbgE+210xKkhbBrAFQA99po5e2TwE3AJ9t9V0MXgwPsLGN06bf2F4cvxHYXVVvVtXLDN4ZfO18bIQkae5GugaQZEmSg8AJYD/wf4BvVdWp1uQosKINrwCOALTprwM/NlyfZp7hdW1JMpFkYmpqas4bJEkazUgBUFVvVdV6YCWDf7X/7IXqUFXtqKrxqhofGxu7UKuRpO5dMpfGVfWtJE8A/xpYmuSS9q/8lcCx1uwYsAo4muQS4EeBbw7VTxueR5JmtHrb5xe7C+9Io9wFNJZkaRv+QeB9wPPAE8CvtmabgUfa8N42Tpv+xaqqVt/U7hJaA6wFnp6n7ZAkzdEoRwBXAbvaHTs/AOypqkeTPAfsTvKHwFeAh1r7h4A/SzIJnGRw5w9VdTjJHuA54BSwtaremt/NkSSNatYAqKpDwLunqb/ENHfxVNU/AR+YYVnbge1z76Ykab75JLAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVOjvBJyVZInkjyX5HCSD7f67yc5luRg+9w6NM89SSaTvJDk5qH6hlabTLLtwmySJGkUo7wS8hTwW1X1d0l+BHgmyf427f6q+s/DjZOsY/AayKuBnwT+Jsm/apM/weCdwkeBA0n2VtVz87EhkqS5GeWVkMeB4234H5M8D6w4yywbgd1V9Sbwcns38OlXR062V0mSZHdrawBI0iKY0zWAJKsZvB/4qVa6O8mhJDuTLGu1FcCRodmOttpM9TPXsSXJRJKJqampuXRPkjQHIwdAkh8G/gL4zar6NvAg8FPAegZHCH88Hx2qqh1VNV5V42NjY/OxSEnSNEa5BkCSSxn88f90Vf0lQFW9OjT9T4FH2+gxYNXQ7CtbjbPUJUkLbJS7gAI8BDxfVX8yVL9qqNn7gWfb8F5gU5LLk6wB1gJPAweAtUnWJLmMwYXivfOzGZKkuRrlCOA9wK8DX01ysNV+D7g9yXqggK8DvwFQVYeT7GFwcfcUsLWq3gJIcjfwGLAE2FlVh+dtSyRJczLKXUBfBjLNpH1nmWc7sH2a+r6zzSdJWjg+CSxJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6tQor4RcleSJJM8lOZzkw61+RZL9SV5s38taPUkeSDKZ5FCSa4aWtbm1fzHJ5gu3WZKk2YxyBHAK+K2qWgdcD2xNsg7YBjxeVWuBx9s4wC0M3gO8FtgCPAiDwADuBa4DrgXuPR0akqSFN2sAVNXxqvq7NvyPwPPACmAjsKs12wXc1oY3Ag/XwJPA0vYC+ZuB/VV1sqpeA/YDG+ZzYyRJo5vTNYAkq4F3A08By6vqeJv0DWB5G14BHBma7WirzVQ/cx1bkkwkmZiamppL9yRJczByACT5YeAvgN+sqm8PT6uqAmo+OlRVO6pqvKrGx8bG5mORkqRpjBQASS5l8Mf/01X1l638aju1Q/s+0erHgFVDs69stZnqkqRFMMpdQAEeAp6vqj8ZmrQXOH0nz2bgkaH6He1uoOuB19uposeAm5Isaxd/b2o1SdIiuGSENu8Bfh34apKDrfZ7wH3AniR3Aa8AH2zT9gG3ApPAG8CdAFV1MsnHgAOt3Uer6uR8bIQkae5mDYCq+jKQGSbfOE37ArbOsKydwM65dFCSdGH4JLAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVOjvBJyZ5ITSZ4dqv1+kmNJDrbPrUPT7kkymeSFJDcP1Te02mSSbfO/KZKkuRjlCOBTwIZp6vdX1fr22QeQZB2wCbi6zfPJJEuSLAE+AdwCrANub20lSYtklFdCfinJ6hGXtxHYXVVvAi8nmQSubdMmq+olgCS7W9vn5t5lSdJ8OJ9rAHcnOdROES1rtRXAkaE2R1ttpvr3SLIlyUSSiampqfPoniTpbM41AB4EfgpYDxwH/ni+OlRVO6pqvKrGx8bG5muxkqQzzHoKaDpV9erp4SR/CjzaRo8Bq4aarmw1zlKXJC2CczoCSHLV0Oj7gdN3CO0FNiW5PMkaYC3wNHAAWJtkTZLLGFwo3nvu3ZYkna9ZjwCSfAZ4L3BlkqPAvcB7k6wHCvg68BsAVXU4yR4GF3dPAVur6q22nLuBx4AlwM6qOjzfGyNJGt0odwHdPk35obO03w5sn6a+D9g3p95Jki4YnwSWpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHVq1gBIsjPJiSTPDtWuSLI/yYvte1mrJ8kDSSaTHEpyzdA8m1v7F5NsvjCbI0ka1ShHAJ8CNpxR2wY8XlVrgcfbOMAtDN4DvBbYAjwIg8Bg8CrJ64BrgXtPh4YkaXHMGgBV9SXg5BnljcCuNrwLuG2o/nANPAksbS+QvxnYX1Unq+o1YD/fGyqSpAV0rtcAllfV8Tb8DWB5G14BHBlqd7TVZqpLkhbJeV8ErqoCah76AkCSLUkmkkxMTU3N12IlSWc41wB4tZ3aoX2faPVjwKqhditbbab696iqHVU1XlXjY2Nj59g9SdJszjUA9gKn7+TZDDwyVL+j3Q10PfB6O1X0GHBTkmXt4u9NrSZJWiSXzNYgyWeA9wJXJjnK4G6e+4A9Se4CXgE+2JrvA24FJoE3gDsBqupkko8BB1q7j1bVmReWJUkLaNYAqKrbZ5h04zRtC9g6w3J2Ajvn1DtJ0gXjk8CS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUqfMKgCRfT/LVJAeTTLTaFUn2J3mxfS9r9SR5IMlkkkNJrpmPDZAknZv5OAL4t1W1vqrG2/g24PGqWgs83sYBbgHWts8W4MF5WLck6RxdiFNAG4FdbXgXcNtQ/eEaeBJYmuSqC7B+SdIIzjcACvhCkmeSbGm15VV1vA1/A1jehlcAR4bmPdpq/58kW5JMJJmYmpo6z+5JkmZyyXnO/2+q6liSHwf2J/na8MSqqiQ1lwVW1Q5gB8D4+Pic5pUkje68jgCq6lj7PgF8DrgWePX0qZ32faI1PwasGpp9ZatJkhbBOQdAkh9K8iOnh4GbgGeBvcDm1mwz8Egb3gvc0e4Guh54fehUkSRpgZ3PKaDlwOeSnF7O/6qqv05yANiT5C7gFeCDrf0+4FZgEngDuPM81i1JOk/nHABV9RLwC9PUvwncOE29gK3nuj5J0vzySWBJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcWPACSbEjyQpLJJNsWev2SpIHzeSXknCVZAnwCeB9wFDiQZG9VPbeQ/ZB0blZv+/xid0HzaKGPAK4FJqvqpar6v8BuYOMC90GSxAIfAQArgCND40eB64YbJNkCbGmj30nywgL17WJ1JfAPi92Ji4T74m3ui4F37H7Ix+c8y/C++JejzLDQATCrqtoB7FjsflwskkxU1fhi9+Ni4L54m/tiwP3wtnPZFwt9CugYsGpofGWrSZIW2EIHwAFgbZI1SS4DNgF7F7gPkiQW+BRQVZ1KcjfwGLAE2FlVhxeyD9+HPB32NvfF29wXA+6Ht815X6SqLkRHJEkXOZ8ElqROGQCS1CkD4CKV5GNJDiU5mOQLSX6y1ZPkgfZTGoeSXLPYfb3QkvxRkq+17f1ckqVD0+5p++KFJDcvYjcvuCQfSHI4yXeTjJ8xrZv9cFrPPyuTZGeSE0meHapdkWR/khfb97LZlmMAXLz+qKp+vqrWA48C/6nVbwHWts8W4MHF6d6C2g/8XFX9PPC/gXsAkqxjcCfZ1cAG4JPt50beqZ4F/j3wpeFih/th+GdlbgHWAbe3/dCLTzH4bz1sG/B4Va0FHm/jZ2UAXKSq6ttDoz8EnL5avxF4uAaeBJYmuWrBO7iAquoLVXWqjT7J4PkRGOyL3VX1ZlW9DEwy+LmRd6Sqer6qpnsyvqv90HT9szJV9SXg5BnljcCuNrwLuG225RgAF7Ek25McAX6Nt48Apvs5jRUL3bdF9B+Bv2rDve+L03rcDz1u82yWV9XxNvwNYPlsM1x0PwXRkyR/A/zENJM+UlWPVNVHgI8kuQe4G7h3QTu4gGbbF63NR4BTwKcXsm8LaZT9IM2mqirJrPf4GwCLqKr+3YhNPw3sYxAA78if05htXyT5D8AvAzfW2w+vvOP2xRz+nxj2jtsPI+hxm2fzapKrqup4Oy18YrYZPAV0kUqydmh0I/C1NrwXuKPdDXQ98PrQYd87UpINwO8Av1JVbwxN2gtsSnJ5kjUMLow/vRh9XGQ97gd/VuZ77QU2t+HNwKxHjB4BXLzuS/IzwHeBV4APtfo+4FYGF/reAO5cnO4tqP8OXA7sTwLwZFV9qKoOJ9kDPMfg1NDWqnprEft5QSV5P/DfgDHg80kOVtXNve0H8GdlknwGeC9wZZKjDM4O3AfsSXIXg78ZH5x1Of4UhCT1yVNAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR16v8BdJO7VIHY3GAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_full.apply(lambda x: np.log(x.closest_wb_elevation) if x.closest_wb_elevation > 0 else np.nan, axis=1))\n",
    "df_full[\"closest_wb_elevation\"] = df_full.apply(lambda x: np.log(x.closest_wb_elevation) if x.closest_wb_elevation > 0 else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_full.apply(lambda x: np.log(x.closest_fl_elevation) if x.closest_fl_elevation > 0 else np.nan, axis=1))\n",
    "df_full[\"closest_fl_elevation\"] = df_full.apply(lambda x: np.log(x.closest_fl_elevation) if x.closest_fl_elevation > 0 else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wS52NjAa4kE_"
   },
   "source": [
    "# Train-Dev-Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fraction of nan's in each numerical variable\n",
    "# remove variables that are above nan threshold of nan_th\n",
    "nan_th = 0.2\n",
    "delete_vars = []\n",
    "count = 0\n",
    "errors = 0\n",
    "nan_dist = []\n",
    "for var in df_full.describe().columns:\n",
    "    try:\n",
    "        nan_fraction = np.mean(df_full[str(var)].isna())\n",
    "        if nan_fraction != 0:\n",
    "            count += 1\n",
    "            nan_dist.append(nan_fraction)\n",
    "            if nan_fraction >= nan_th:\n",
    "                delete_vars.append(var)\n",
    "                \n",
    "    except Exception as e:\n",
    "        errors += 1\n",
    "        print(var, \"<-------------------\")\n",
    "print(count, errors)\n",
    "plt.hist(nan_dist)\n",
    "\n",
    "# keep_vars = list(set(df_full.columns) - set(delete_vars)) # wow this is messing up the order\n",
    "\n",
    "keep_vars = []\n",
    "for var in df_full.columns:\n",
    "    if var not in delete_vars:\n",
    "        keep_vars.append(var)\n",
    "df_full = df_full[keep_vars]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14162, 450)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Tc_mmRYBKxU6"
   },
   "outputs": [],
   "source": [
    "# df_full = df_full[good_records]\n",
    "\n",
    "# if dev:\n",
    "#     df, df_test = train_test_split(df_full, test_size=0.2, random_state = random_state) # 20% test\n",
    "#     df, df_dev = train_test_split(df, test_size=0.25, random_state = random_state) # 60% train, 20% dev\n",
    "# else:\n",
    "#     df, df_test = train_test_split(df_full, test_size=0.2, random_state = random_state) # 80% train, 20% test\n",
    "#     df_dev = df_test.copy()\n",
    "    \n",
    "# # df, df_test = train_test_split(df_full, test_size=0.95, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Buffalo', 'Chicago', 'Detroit', 'Huntington', 'Louisville',\n",
       "       'Nashville', 'Pittsburgh', 'Vicksburg', 'Memphis', 'New Orleans',\n",
       "       'St. Paul', 'Rock Island', 'St. Louis', 'Baltimore', 'New England',\n",
       "       'New York', 'Norfolk', 'Philadelphia', 'Kansas City', 'Omaha',\n",
       "       'Portland', 'Seattle', 'Walla Walla', 'Honolulu', 'Charleston',\n",
       "       'Jacksonville', 'Mobile', 'Savannah', 'Wilmington', 'Albuquerque',\n",
       "       'Sacramento', 'Los Angeles', 'San Francisco', 'Fort Worth',\n",
       "       'Galveston', 'Little Rock', 'Tulsa'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.district.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for district in df_full.district.unique():\n",
    "df = pd.DataFrame()\n",
    "df_dev = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "df_ = pd.DataFrame()\n",
    "df_dev_ = pd.DataFrame()\n",
    "df_test_ = pd.DataFrame()\n",
    "\n",
    "for group in df_full.groupby(\"district\"):\n",
    "    try:\n",
    "        df_, df_test_ = train_test_split(group[1], test_size=0.2, random_state = random_state) # 20% test\n",
    "        df_, df_dev_ = train_test_split(df_, test_size=0.25, random_state = random_state) # 60% train, 20% dev\n",
    "    except Exception as e:\n",
    "        print(group[0], e)\n",
    "    df = pd.concat([df, df_])\n",
    "    df_dev = pd.concat([df_dev, df_dev_])\n",
    "    df_test = pd.concat([df_test, df_test_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8472, 450)\n",
      "(2840, 450)\n",
      "(2850, 450)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df_dev.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bODkeQCDPr24"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Zs23ZZxPtnN"
   },
   "source": [
    "### Remove cols with all NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "vBwbLX6YPwT_"
   },
   "outputs": [],
   "source": [
    "nan_cols = []\n",
    "for col in df.columns:\n",
    "  nan_frac = np.mean(df[str(col)].isna())\n",
    "  if nan_frac == 1:\n",
    "    nan_cols.append(col)\n",
    "nan_cols\n",
    "df.drop(nan_cols, inplace=True, axis=1)\n",
    "\n",
    "# two cols are removed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8472, 450)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxWXqayaFhXp",
    "outputId": "52c2ceb0-fc0c-49ce-8fb4-4050e7c7f778"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"county\" in df_full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlZ2nLgVPOn1"
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xlE_M1C2PIgp",
    "outputId": "af65405c-4220-4fe4-c5b9-c922d395bfde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 latitude\n",
      "1 cwa7\n",
      "2 cwa8\n",
      "3 cwa9\n",
      "4 cwa_determination\n",
      "5 rha1\n",
      "6 potential_wetland\n",
      "7 cwa2\n",
      "8 Index\n",
      "9 cwa5\n",
      "10 cwa4\n",
      "11 longitude\n",
      "12 cwa3\n",
      "13 rha_determination\n",
      "14 cwa6\n",
      "15 cwa1\n",
      "16 rha2\n",
      "17 niccdcdpct\n",
      "18 slopegradd\n",
      "19 iccdcdpct\n",
      "20 pondfreqpr\n",
      "21 awmmfpwwta\n",
      "22 wtdepaprju\n",
      "23 aws050wta\n",
      "24 aws0100wta\n",
      "25 mukey\n",
      "26 hydclprs\n",
      "27 wtdepannmi\n",
      "28 aws0150wta\n",
      "29 urbrecptwt\n",
      "30 brockdepmi\n",
      "31 niccdcd\n",
      "32 aws025wta\n",
      "33 slopegradw\n",
      "34 elevation_stdev_200m\n",
      "35 slope_max_200m\n",
      "36 elevation_min_200m\n",
      "37 slope_mean_200m\n",
      "38 slope_stdev_200m\n",
      "39 elevation_max_200m\n",
      "40 slope_min_200m\n",
      "41 elevation_mean_200m\n",
      "42 fl_gnis_name_ind_mean_200m\n",
      "43 fl_startflag_sum_200m\n",
      "44 wb_ftype_connector_200m\n",
      "45 wb_gnis_name_ind_count_200m\n",
      "46 fl_streamorde_mean_200m\n",
      "47 wb_area_mean_200m\n",
      "48 fl_areasqkm_count_200m\n",
      "49 fl_areasqkm_sum_200m\n",
      "50 fl_divergence_mean_200m\n",
      "51 fl_intephem_mean_200m\n",
      "52 fl_totdasqkm_mean_200m\n",
      "53 fl_divergence_count_200m\n",
      "54 fl_length_sum_200m\n",
      "55 fl_streamorde_count_200m\n",
      "56 wb_gnis_name_ind_mean_200m\n",
      "57 wb_ftype_artificialpath_200m\n",
      "58 fl_gnis_name_ind_sum_200m\n",
      "59 fl_totdasqkm_count_200m\n",
      "60 fl_streamorde_sum_200m\n",
      "61 fl_ftype_pipeline_200m\n",
      "62 wb_area_sum_200m\n",
      "63 fl_ftype_coastline_200m\n",
      "64 fl_length_mean_200m\n",
      "65 wb_ftype_coastline_200m\n",
      "66 wb_area_count_200m\n",
      "67 fl_divergence_sum_200m\n",
      "68 wb_ftype_streamriver_200m\n",
      "69 fl_startflag_mean_200m\n",
      "70 fl_intephem_sum_200m\n",
      "71 fl_intephem_count_200m\n",
      "72 fl_flow_type_count_200m\n",
      "73 fl_startflag_count_200m\n",
      "74 fl_flow_type_sum_200m\n",
      "75 fl_totdasqkm_sum_200m\n",
      "76 fl_ftype_connector_200m\n",
      "77 fl_ftype_canalditch_200m\n",
      "78 wb_ftype_pipeline_200m\n",
      "79 fl_length_count_200m\n",
      "80 fl_gnis_name_ind_count_200m\n",
      "81 wb_gnis_name_ind_sum_200m\n",
      "82 fl_ftype_artificialpath_200m\n",
      "83 fl_flow_type_mean_200m\n",
      "84 wb_ftype_canalditch_200m\n",
      "85 fl_ftype_streamriver_200m\n",
      "86 fl_areasqkm_mean_200m\n",
      "87 nwi_CLASS_NAME_moss-lichen_200m\n",
      "88 nwi_SUBSYSTEM_NAME_subtidal_200m\n",
      "89 nwi_SYSTEM_NAME_palustrine_200m\n",
      "90 nwi_SPLIT_SUBCLASS_NAME_broad-leaved_evergreen_200m\n",
      "91 nwi_SUBCLASS_NAME_vegetated_200m\n",
      "92 nwi_SPLIT_SUBCLASS_NAME_aquatic_moss_200m\n",
      "93 nwi_estuarine_and_marine_wetland_200m\n",
      "94 nwi_SUBCLASS_NAME_mollusk_200m\n",
      "95 nwi_WATER_REGIME_NAME_seasonally_flooded_200m\n",
      "96 nwi_SPLIT_SUBCLASS_NAME_lichen_200m\n",
      "97 nwi_SPLIT_SUBCLASS_NAME_vegetated_200m\n",
      "98 nwi_FIRST_MODIFIER_NAME_mixohaline/mixosaline_(brackish)_200m\n",
      "99 nwi_FIRST_MODIFIER_NAME_acid_200m\n",
      "100 nwi_CLASS_NAME_rocky_shore_200m\n",
      "101 nwi_SPLIT_SUBCLASS_NAME_coral_200m\n",
      "102 nwi_CLASS_NAME_reef_200m\n",
      "103 nwi_SPLIT_SUBCLASS_NAME_mud_200m\n",
      "104 nwi_SUBCLASS_NAME_bedrock_200m\n",
      "105 nwi_FIRST_MODIFIER_NAME_oligohaline_200m\n",
      "106 nwi_SYSTEM_NAME_marine_200m\n",
      "107 nwi_FIRST_MODIFIER_NAME_artificial_substrate_200m\n",
      "108 nwi_lake_200m\n",
      "109 nwi_SUBCLASS_NAME_aquatic_moss_200m\n",
      "110 nwi_SUBCLASS_NAME_coral_200m\n",
      "111 nwi_SUBSYSTEM_NAME_littoral_200m\n",
      "112 nwi_SPLIT_SUBCLASS_NAME_zzz_200m\n",
      "113 nwi_SPLIT_SUBCLASS_NAME_non_persistent_200m\n",
      "114 nwi_WATER_REGIME_SUBGROUP_zzz_200m\n",
      "115 nwi_SPLIT_SUBCLASS_NAME_broad-leaved_deciduous_200m\n",
      "116 nwi_SPLIT_SUBCLASS_NAME_rubble_200m\n",
      "117 nwi_SUBCLASS_NAME_persistent_200m\n",
      "118 nwi_SPLIT_SUBCLASS_NAME_evergreen_200m\n",
      "119 nwi_SPLIT_CLASS_NAME_unconsolidated_shore_200m\n",
      "120 nwi_SPLIT_SUBCLASS_NAME_dead_200m\n",
      "121 nwi_SUBCLASS_NAME_evergreen_200m\n",
      "122 nwi_SPLIT_SUBCLASS_NAME_needle-leaved_deciduous_200m\n",
      "123 nwi_SUBCLASS_NAME_deciduous_200m\n",
      "124 nwi_SUBSYSTEM_NAME_lower_perennial_200m\n",
      "125 nwi_SUBSYSTEM_NAME_tidal_200m\n",
      "126 nwi_SPLIT_SUBCLASS_NAME_needle-leaved_evergreen_200m\n",
      "127 nwi_WATER_REGIME_NAME_temporary_flooded_200m\n",
      "128 nwi_SUBCLASS_NAME_floating_vascular_200m\n",
      "129 nwi_SPLIT_CLASS_NAME_rocky_shore_200m\n",
      "130 nwi_CLASS_NAME_unconsolidated_bottom_200m\n",
      "131 nwi_SUBCLASS_NAME_mud_200m\n",
      "132 nwi_FIRST_MODIFIER_NAME_organic_200m\n",
      "133 nwi_WATER_REGIME_NAME_artificially_flooded_200m\n",
      "134 nwi_FIRST_MODIFIER_NAME_beaver_200m\n",
      "135 nwi_other_200m\n",
      "136 nwi_freshwater_emergent_wetland_200m\n",
      "137 nwi_freshwater_pond_200m\n",
      "138 nwi_SUBSYSTEM_NAME_unknown_perennial_200m\n",
      "139 nwi_SPLIT_CLASS_NAME_unconsolidated_bottom_200m\n",
      "140 nwi_SPLIT_SUBCLASS_NAME_cobble-gravel_200m\n",
      "141 nwi_SUBCLASS_NAME_zzz_200m\n",
      "142 nwi_FIRST_MODIFIER_NAME_farmed_200m\n",
      "143 nwi_SPLIT_CLASS_NAME_emergent_200m\n",
      "144 nwi_WATER_REGIME_SUBGROUP_saltwater_tidal_200m\n",
      "145 nwi_WATER_REGIME_NAME_seasonally_saturated_200m\n",
      "146 nwi_SPLIT_SUBCLASS_NAME_deciduous_200m\n",
      "147 nwi_SPLIT_CLASS_NAME_scrub-shrub_200m\n",
      "148 nwi_FIRST_MODIFIER_NAME_polyhaline_200m\n",
      "149 nwi_riverine_200m\n",
      "150 nwi_CLASS_NAME_forested_200m\n",
      "151 nwi_SPLIT_CLASS_NAME_forested_200m\n",
      "152 nwi_SUBCLASS_NAME_algal_200m\n",
      "153 nwi_estuarine_and_marine_deepwater_200m\n",
      "154 nwi_SPLIT_SUBCLASS_NAME_moss_200m\n",
      "155 nwi_CLASS_NAME_aquatic_bed_200m\n",
      "156 nwi_WATER_REGIME_NAME_seasonally_flooded/saturated_200m\n",
      "157 nwi_SPLIT_SUBCLASS_NAME_floating_vascular_200m\n",
      "158 nwi_SUBCLASS_NAME_non_persistent_200m\n",
      "159 nwi_SUBCLASS_NAME_rooted_vascular_200m\n",
      "160 nwi_FIRST_MODIFIER_NAME_euthaline/eusaline_200m\n",
      "161 nwi_SPLIT_CLASS_NAME_aquatic_bed_200m\n",
      "162 nwi_SUBCLASS_NAME_cobble-gravel_200m\n",
      "163 nwi_CLASS_NAME_emergent_200m\n",
      "164 nwi_FIRST_MODIFIER_NAME_spoil_200m\n",
      "165 nwi_SUBCLASS_NAME_phragmites_australis_200m\n",
      "166 nwi_SUBCLASS_NAME_broad-leaved_evergreen_200m\n",
      "167 nwi_WATER_REGIME_NAME_temporary_flooded-tidal_200m\n",
      "168 nwi_WATER_REGIME_SUBGROUP_freshwater_tidal_200m\n",
      "169 nwi_WATER_REGIME_NAME_zzz_200m\n",
      "170 nwi_SPLIT_SUBCLASS_NAME_rooted_vascular_200m\n",
      "171 nwi_SUBSYSTEM_NAME_intertidal_200m\n",
      "172 nwi_SPLIT_SUBCLASS_NAME_bedrock_200m\n",
      "173 nwi_FIRST_MODIFIER_NAME_diked/impounded_200m\n",
      "174 nwi_CLASS_NAME_scrub-shrub_200m\n",
      "175 nwi_SUBCLASS_NAME_broad-leaved_deciduous_200m\n",
      "176 nwi_FIRST_MODIFIER_NAME_alkaline_200m\n",
      "177 nwi_freshwater_forested_200m\n",
      "178 nwi_CLASS_NAME_unconsolidated_shore_200m\n",
      "179 nwi_SPLIT_CLASS_NAME_reef_200m\n",
      "180 nwi_SYSTEM_NAME_estuarine_200m\n",
      "181 nwi_SPLIT_SUBCLASS_NAME_mollusk_200m\n",
      "182 nwi_WATER_REGIME_NAME_irregularly_flooded_200m\n",
      "183 nwi_SUBCLASS_NAME_needle-leaved_deciduous_200m\n",
      "184 nwi_WATER_REGIME_NAME_permanently_flooded-tidal_200m\n",
      "185 nwi_SUBCLASS_NAME_lichen_200m\n",
      "186 nwi_CLASS_NAME_streambed_200m\n",
      "187 nwi_SPLIT_SUBCLASS_NAME_organic_200m\n",
      "188 nwi_SUBCLASS_NAME_organic_200m\n",
      "189 nwi_SUBCLASS_NAME_sand_200m\n",
      "190 nwi_WATER_REGIME_NAME_permanently_flooded_200m\n",
      "191 nwi_WATER_REGIME_NAME_semipermanently_flooded-tidal_200m\n",
      "192 nwi_SUBCLASS_NAME_dead_200m\n",
      "193 nwi_SUBSYSTEM_NAME_limnetic_200m\n",
      "194 nwi_SUBSYSTEM_NAME_intermittent_200m\n",
      "195 nwi_SPLIT_SUBCLASS_NAME_algal_200m\n",
      "196 nwi_WATER_REGIME_NAME_seasonally_flooded-tidal_200m\n",
      "197 nwi_WATER_REGIME_NAME_intermittently_flooded_200m\n",
      "198 nwi_feature_count_200m\n",
      "199 nwi_SPLIT_CLASS_NAME_moss-lichen_200m\n",
      "200 nwi_SYSTEM_NAME_riverine_200m\n",
      "201 nwi_WATER_REGIME_NAME_continuously__saturated_200m\n",
      "202 nwi_WATER_REGIME_NAME_intermittently_exposed_200m\n",
      "203 nwi_WATER_REGIME_NAME_irregularly_exposed_200m\n",
      "204 nwi_SPLIT_SUBCLASS_NAME_phragmites_australis_200m\n",
      "205 nwi_SPLIT_SUBCLASS_NAME_persistent_200m\n",
      "206 nwi_SUBCLASS_NAME_moss_200m\n",
      "207 nwi_SUBCLASS_NAME_rubble_200m\n",
      "208 nwi_FIRST_MODIFIER_NAME_excavated_200m\n",
      "209 nwi_CLASS_NAME_zzz_200m\n",
      "210 nwi_WATER_REGIME_NAME_regularly_flooded_200m\n",
      "211 nwi_CLASS_NAME_rock_bottom_200m\n",
      "212 nwi_FIRST_MODIFIER_NAME_mesohaline_200m\n",
      "213 nwi_WATER_REGIME_NAME_subtidal_200m\n",
      "214 nwi_WATER_REGIME_NAME_semipermanently_flooded_200m\n",
      "215 nwi_SYSTEM_NAME_lacustrine_200m\n",
      "216 nwi_SPLIT_SUBCLASS_NAME_sand_200m\n",
      "217 nwi_FIRST_MODIFIER_NAME_hyperhaline/hypersaline_200m\n",
      "218 nwi_FIRST_MODIFIER_NAME_zzz_200m\n",
      "219 nwi_SUBSYSTEM_NAME_upper_perennial_200m\n",
      "220 nwi_SUBCLASS_NAME_needle-leaved_evergreen_200m\n",
      "221 nwi_WATER_REGIME_SUBGROUP_nontidal_200m\n",
      "222 nwi_SPLIT_CLASS_NAME_zzz_200m\n",
      "223 nwi_FIRST_MODIFIER_NAME_mineral_200m\n",
      "224 nwi_FIRST_MODIFIER_NAME_partially_drained/ditched_200m\n",
      "225 nwi_shrub_wetland_200m\n",
      "226 nwi_FIRST_MODIFIER_NAME_managed_200m\n",
      "227 elevation_min_1000m\n",
      "228 elevation_mean_1000m\n",
      "229 slope_stdev_1000m\n",
      "230 elevation_stdev_1000m\n",
      "231 slope_max_1000m\n",
      "232 slope_min_1000m\n",
      "233 elevation_max_1000m\n",
      "234 slope_mean_1000m\n",
      "235 fl_length_count_1000m\n",
      "236 fl_areasqkm_sum_1000m\n",
      "237 wb_gnis_name_ind_sum_1000m\n",
      "238 fl_streamorde_sum_1000m\n",
      "239 wb_area_sum_1000m\n",
      "240 fl_divergence_mean_1000m\n",
      "241 fl_flow_type_count_1000m\n",
      "242 wb_ftype_artificialpath_1000m\n",
      "243 wb_gnis_name_ind_mean_1000m\n",
      "244 fl_gnis_name_ind_count_1000m\n",
      "245 fl_startflag_sum_1000m\n",
      "246 wb_area_mean_1000m\n",
      "247 fl_startflag_mean_1000m\n",
      "248 fl_ftype_connector_1000m\n",
      "249 fl_totdasqkm_count_1000m\n",
      "250 fl_gnis_name_ind_sum_1000m\n",
      "251 fl_ftype_artificialpath_1000m\n",
      "252 fl_ftype_pipeline_1000m\n",
      "253 fl_startflag_count_1000m\n",
      "254 wb_ftype_coastline_1000m\n",
      "255 wb_ftype_connector_1000m\n",
      "256 fl_totdasqkm_mean_1000m\n",
      "257 fl_intephem_count_1000m\n",
      "258 fl_flow_type_sum_1000m\n",
      "259 wb_gnis_name_ind_count_1000m\n",
      "260 wb_ftype_streamriver_1000m\n",
      "261 fl_divergence_count_1000m\n",
      "262 fl_streamorde_mean_1000m\n",
      "263 fl_intephem_mean_1000m\n",
      "264 fl_ftype_coastline_1000m\n",
      "265 fl_intephem_sum_1000m\n",
      "266 fl_totdasqkm_sum_1000m\n",
      "267 fl_areasqkm_mean_1000m\n",
      "268 fl_divergence_sum_1000m\n",
      "269 fl_streamorde_count_1000m\n",
      "270 fl_areasqkm_count_1000m\n",
      "271 wb_ftype_pipeline_1000m\n",
      "272 wb_area_count_1000m\n",
      "273 wb_ftype_canalditch_1000m\n",
      "274 fl_flow_type_mean_1000m\n",
      "275 fl_ftype_canalditch_1000m\n",
      "276 fl_gnis_name_ind_mean_1000m\n",
      "277 fl_ftype_streamriver_1000m\n",
      "278 nwi_SUBCLASS_NAME_broad-leaved_deciduous_1000m\n",
      "279 nwi_SUBSYSTEM_NAME_intertidal_1000m\n",
      "280 nwi_SPLIT_SUBCLASS_NAME_moss_1000m\n",
      "281 nwi_SUBCLASS_NAME_floating_vascular_1000m\n",
      "282 nwi_SUBCLASS_NAME_dead_1000m\n",
      "283 nwi_SUBCLASS_NAME_broad-leaved_evergreen_1000m\n",
      "284 nwi_WATER_REGIME_NAME_intermittently_exposed_1000m\n",
      "285 nwi_SPLIT_SUBCLASS_NAME_mollusk_1000m\n",
      "286 nwi_WATER_REGIME_NAME_seasonally_flooded-tidal_1000m\n",
      "287 nwi_FIRST_MODIFIER_NAME_polyhaline_1000m\n",
      "288 nwi_SUBSYSTEM_NAME_unknown_perennial_1000m\n",
      "289 nwi_FIRST_MODIFIER_NAME_acid_1000m\n",
      "290 nwi_WATER_REGIME_NAME_seasonally_flooded/saturated_1000m\n",
      "291 nwi_WATER_REGIME_NAME_semipermanently_flooded_1000m\n",
      "292 nwi_SPLIT_SUBCLASS_NAME_vegetated_1000m\n",
      "293 nwi_SUBSYSTEM_NAME_tidal_1000m\n",
      "294 nwi_SUBCLASS_NAME_rubble_1000m\n",
      "295 nwi_estuarine_and_marine_wetland_1000m\n",
      "296 nwi_SUBCLASS_NAME_aquatic_moss_1000m\n",
      "297 nwi_FIRST_MODIFIER_NAME_hyperhaline/hypersaline_1000m\n",
      "298 nwi_SYSTEM_NAME_lacustrine_1000m\n",
      "299 nwi_freshwater_pond_1000m\n",
      "300 nwi_FIRST_MODIFIER_NAME_farmed_1000m\n",
      "301 nwi_SPLIT_SUBCLASS_NAME_bedrock_1000m\n",
      "302 nwi_SUBCLASS_NAME_mollusk_1000m\n",
      "303 nwi_SPLIT_SUBCLASS_NAME_needle-leaved_evergreen_1000m\n",
      "304 nwi_SUBCLASS_NAME_mud_1000m\n",
      "305 nwi_SPLIT_SUBCLASS_NAME_needle-leaved_deciduous_1000m\n",
      "306 nwi_SUBCLASS_NAME_bedrock_1000m\n",
      "307 nwi_FIRST_MODIFIER_NAME_oligohaline_1000m\n",
      "308 nwi_SPLIT_SUBCLASS_NAME_phragmites_australis_1000m\n",
      "309 nwi_SUBCLASS_NAME_zzz_1000m\n",
      "310 nwi_SPLIT_SUBCLASS_NAME_broad-leaved_deciduous_1000m\n",
      "311 nwi_SPLIT_SUBCLASS_NAME_organic_1000m\n",
      "312 nwi_SUBCLASS_NAME_sand_1000m\n",
      "313 nwi_SUBSYSTEM_NAME_upper_perennial_1000m\n",
      "314 nwi_WATER_REGIME_NAME_subtidal_1000m\n",
      "315 nwi_SUBCLASS_NAME_lichen_1000m\n",
      "316 nwi_riverine_1000m\n",
      "317 nwi_freshwater_forested_1000m\n",
      "318 nwi_SPLIT_SUBCLASS_NAME_broad-leaved_evergreen_1000m\n",
      "319 nwi_FIRST_MODIFIER_NAME_mineral_1000m\n",
      "320 nwi_CLASS_NAME_unconsolidated_bottom_1000m\n",
      "321 nwi_FIRST_MODIFIER_NAME_excavated_1000m\n",
      "322 nwi_WATER_REGIME_NAME_irregularly_flooded_1000m\n",
      "323 nwi_FIRST_MODIFIER_NAME_euthaline/eusaline_1000m\n",
      "324 nwi_WATER_REGIME_NAME_intermittently_flooded_1000m\n",
      "325 nwi_estuarine_and_marine_deepwater_1000m\n",
      "326 nwi_SYSTEM_NAME_estuarine_1000m\n",
      "327 nwi_CLASS_NAME_streambed_1000m\n",
      "328 nwi_SPLIT_CLASS_NAME_reef_1000m\n",
      "329 nwi_SPLIT_SUBCLASS_NAME_evergreen_1000m\n",
      "330 nwi_SUBCLASS_NAME_needle-leaved_deciduous_1000m\n",
      "331 nwi_SUBCLASS_NAME_persistent_1000m\n",
      "332 nwi_SPLIT_CLASS_NAME_zzz_1000m\n",
      "333 nwi_SPLIT_SUBCLASS_NAME_algal_1000m\n",
      "334 nwi_FIRST_MODIFIER_NAME_beaver_1000m\n",
      "335 nwi_SPLIT_CLASS_NAME_forested_1000m\n",
      "336 nwi_CLASS_NAME_reef_1000m\n",
      "337 nwi_WATER_REGIME_NAME_zzz_1000m\n",
      "338 nwi_SUBCLASS_NAME_non_persistent_1000m\n",
      "339 nwi_WATER_REGIME_NAME_regularly_flooded_1000m\n",
      "340 nwi_SPLIT_SUBCLASS_NAME_deciduous_1000m\n",
      "341 nwi_lake_1000m\n",
      "342 nwi_SPLIT_SUBCLASS_NAME_dead_1000m\n",
      "343 nwi_WATER_REGIME_NAME_temporary_flooded-tidal_1000m\n",
      "344 nwi_SUBSYSTEM_NAME_lower_perennial_1000m\n",
      "345 nwi_CLASS_NAME_zzz_1000m\n",
      "346 nwi_SPLIT_SUBCLASS_NAME_lichen_1000m\n",
      "347 nwi_WATER_REGIME_NAME_seasonally_saturated_1000m\n",
      "348 nwi_WATER_REGIME_NAME_irregularly_exposed_1000m\n",
      "349 nwi_FIRST_MODIFIER_NAME_partially_drained/ditched_1000m\n",
      "350 nwi_SPLIT_CLASS_NAME_rocky_shore_1000m\n",
      "351 nwi_SPLIT_SUBCLASS_NAME_sand_1000m\n",
      "352 nwi_WATER_REGIME_NAME_permanently_flooded_1000m\n",
      "353 nwi_SPLIT_SUBCLASS_NAME_rubble_1000m\n",
      "354 nwi_feature_count_1000m\n",
      "355 nwi_SPLIT_SUBCLASS_NAME_floating_vascular_1000m\n",
      "356 nwi_SUBCLASS_NAME_phragmites_australis_1000m\n",
      "357 nwi_SUBCLASS_NAME_needle-leaved_evergreen_1000m\n",
      "358 nwi_SPLIT_SUBCLASS_NAME_coral_1000m\n",
      "359 nwi_other_1000m\n",
      "360 nwi_SPLIT_SUBCLASS_NAME_cobble-gravel_1000m\n",
      "361 nwi_SPLIT_CLASS_NAME_unconsolidated_shore_1000m\n",
      "362 nwi_FIRST_MODIFIER_NAME_alkaline_1000m\n",
      "363 nwi_CLASS_NAME_unconsolidated_shore_1000m\n",
      "364 nwi_SUBCLASS_NAME_deciduous_1000m\n",
      "365 nwi_SPLIT_SUBCLASS_NAME_non_persistent_1000m\n",
      "366 nwi_WATER_REGIME_SUBGROUP_saltwater_tidal_1000m\n",
      "367 nwi_SUBSYSTEM_NAME_limnetic_1000m\n",
      "368 nwi_SPLIT_SUBCLASS_NAME_zzz_1000m\n",
      "369 nwi_FIRST_MODIFIER_NAME_artificial_substrate_1000m\n",
      "370 nwi_WATER_REGIME_SUBGROUP_freshwater_tidal_1000m\n",
      "371 nwi_WATER_REGIME_SUBGROUP_nontidal_1000m\n",
      "372 nwi_CLASS_NAME_rock_bottom_1000m\n",
      "373 nwi_SPLIT_CLASS_NAME_unconsolidated_bottom_1000m\n",
      "374 nwi_FIRST_MODIFIER_NAME_spoil_1000m\n",
      "375 nwi_SUBCLASS_NAME_organic_1000m\n",
      "376 nwi_FIRST_MODIFIER_NAME_mesohaline_1000m\n",
      "377 nwi_WATER_REGIME_NAME_permanently_flooded-tidal_1000m\n",
      "378 nwi_SYSTEM_NAME_marine_1000m\n",
      "379 nwi_SUBSYSTEM_NAME_intermittent_1000m\n",
      "380 nwi_SYSTEM_NAME_riverine_1000m\n",
      "381 nwi_CLASS_NAME_rocky_shore_1000m\n",
      "382 nwi_SUBCLASS_NAME_moss_1000m\n",
      "383 nwi_SUBCLASS_NAME_coral_1000m\n",
      "384 nwi_WATER_REGIME_NAME_continuously__saturated_1000m\n",
      "385 nwi_FIRST_MODIFIER_NAME_zzz_1000m\n",
      "386 nwi_freshwater_emergent_wetland_1000m\n",
      "387 nwi_SPLIT_SUBCLASS_NAME_rooted_vascular_1000m\n",
      "388 nwi_SYSTEM_NAME_palustrine_1000m\n",
      "389 nwi_SPLIT_SUBCLASS_NAME_mud_1000m\n",
      "390 nwi_WATER_REGIME_NAME_temporary_flooded_1000m\n",
      "391 nwi_SPLIT_CLASS_NAME_emergent_1000m\n",
      "392 nwi_SPLIT_SUBCLASS_NAME_aquatic_moss_1000m\n",
      "393 nwi_SPLIT_CLASS_NAME_scrub-shrub_1000m\n",
      "394 nwi_SUBCLASS_NAME_rooted_vascular_1000m\n",
      "395 nwi_shrub_wetland_1000m\n",
      "396 nwi_FIRST_MODIFIER_NAME_diked/impounded_1000m\n",
      "397 nwi_SUBCLASS_NAME_cobble-gravel_1000m\n",
      "398 nwi_CLASS_NAME_aquatic_bed_1000m\n",
      "399 nwi_WATER_REGIME_NAME_semipermanently_flooded-tidal_1000m\n",
      "400 nwi_FIRST_MODIFIER_NAME_organic_1000m\n",
      "401 nwi_SPLIT_CLASS_NAME_moss-lichen_1000m\n",
      "402 nwi_CLASS_NAME_emergent_1000m\n",
      "403 nwi_SPLIT_CLASS_NAME_aquatic_bed_1000m\n",
      "404 nwi_CLASS_NAME_moss-lichen_1000m\n",
      "405 nwi_WATER_REGIME_SUBGROUP_zzz_1000m\n",
      "406 nwi_FIRST_MODIFIER_NAME_mixohaline/mixosaline_(brackish)_1000m\n",
      "407 nwi_SUBSYSTEM_NAME_littoral_1000m\n",
      "408 nwi_SPLIT_SUBCLASS_NAME_persistent_1000m\n",
      "409 nwi_SUBCLASS_NAME_evergreen_1000m\n",
      "410 nwi_FIRST_MODIFIER_NAME_managed_1000m\n",
      "411 nwi_SUBCLASS_NAME_algal_1000m\n",
      "412 nwi_CLASS_NAME_forested_1000m\n",
      "413 nwi_CLASS_NAME_scrub-shrub_1000m\n",
      "414 nwi_SUBSYSTEM_NAME_subtidal_1000m\n",
      "415 nwi_WATER_REGIME_NAME_artificially_flooded_1000m\n",
      "416 nwi_WATER_REGIME_NAME_seasonally_flooded_1000m\n",
      "417 nwi_SUBCLASS_NAME_vegetated_1000m\n",
      "418 cwa_determination_groups\n"
     ]
    }
   ],
   "source": [
    "df_num_features = pd.DataFrame(df.describe().columns)\n",
    "for count, col in enumerate(df.describe().columns):\n",
    "  print(count, col)\n",
    "\n",
    "# 5, 7, 14, 17, 19:445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQVQGqHhGkE_"
   },
   "source": [
    "## Numerical Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "viN9PWn5PY7H",
    "outputId": "25a607e3-e822-47b5-908e-ff201a1ac251"
   },
   "outputs": [],
   "source": [
    "# NOTE: for kNN which uses only lat, lon, have to pass lat, lon as first two cols\n",
    "\n",
    "if INPUT_FILE_NAME == \"Merge_all_datasets/2021.03.31_200m_1000m\":\n",
    "    # numerical features of interest: \n",
    "    ssurgo = list(set(range(17, 34)) - set([22])) # 22 = mukey\n",
    "    nhd = list(range(42, 87)) + list(range(235, 278)) \n",
    "    nwi = list(range(87, 227)) + list(range(278, 418)) \n",
    "    srtm = list(range(34, 42)) + list(range(227, 235)) \n",
    "    # closest_wb_fl = list(range(456, 462)) \n",
    "\n",
    "    if run_models:\n",
    "#         imp_num_feature_list = [2, 9, 10] + ssurgo + nhd + nwi + srtm\n",
    "        imp_num_feature_list = ssurgo + nhd + nwi + srtm # remove lat, lon, pot wetland\n",
    "\n",
    "        imp_num_feature = df_num_features.loc[imp_num_feature_list]\n",
    "        imp_num_feature = list(imp_num_feature.values.flatten())\n",
    "        file_param_dict[\"imp_num_feature\"] = imp_num_feature\n",
    "    else:\n",
    "        imp_num_feature = file_param_dict[\"imp_num_feature\"]\n",
    "        \n",
    "        \n",
    "if INPUT_FILE_NAME == \"Merge_all_datasets/2021.03.31_1000m_2500m\":\n",
    "    # numerical features of interest: \n",
    "    ssurgo = list(set(range(17, 34)) - set([22])) # 22 = mukey\n",
    "    nhd = list(range(51, 94)) + list(range(241, 284)) \n",
    "    nwi = list(range(94, 233)) + list(range(284, 424)) \n",
    "    srtm = list(range(34, 51)) + list(range(233, 241)) \n",
    "    # closest_wb_fl = list(range(456, 462)) \n",
    "\n",
    "    if run_models:\n",
    "        imp_num_feature_list = [2, 9, 10] + ssurgo + nhd + nwi + srtm\n",
    "\n",
    "        imp_num_feature = df_num_features.loc[imp_num_feature_list]\n",
    "        imp_num_feature = list(imp_num_feature.values.flatten())\n",
    "        file_param_dict[\"imp_num_feature\"] = imp_num_feature\n",
    "    else:\n",
    "        imp_num_feature = file_param_dict[\"imp_num_feature\"]        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfKbTgYTGohQ"
   },
   "source": [
    "## Categorical Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'county',\n",
       " 'da_number',\n",
       " 'date_issued_or_denied',\n",
       " 'district',\n",
       " 'drclassdcd',\n",
       " 'drclasswet',\n",
       " 'east_coast',\n",
       " 'engcmssdcd',\n",
       " 'engcmssmp',\n",
       " 'engdwbdcd',\n",
       " 'engdwbll',\n",
       " 'engdwbml',\n",
       " 'engdwobdcd',\n",
       " 'englrsdcd',\n",
       " 'engsldcd',\n",
       " 'engsldcp',\n",
       " 'engstafdcd',\n",
       " 'engstafll',\n",
       " 'engstafml',\n",
       " 'flodfreqdc',\n",
       " 'flodfreqma',\n",
       " 'forpehrtdc',\n",
       " 'huc4',\n",
       " 'huc6',\n",
       " 'hydgrpdcd',\n",
       " 'jurisdiction_type',\n",
       " 'mustatus',\n",
       " 'nwi_wetland_list_1000m',\n",
       " 'nwi_wetland_list_200m',\n",
       " 'state',\n",
       " 'urbrecptdc'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek at categorical features\n",
    "set(df.columns) - set(df.describe().columns)\n",
    "# len(set(df.describe().columns))\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "n5JCwDs_Q8pW"
   },
   "outputs": [],
   "source": [
    "# call out the important categorical features\n",
    "\n",
    "\n",
    "# imp_cat_feature = ['district', 'flodfreqdc', 'drclassdcd', 'county', 'jurisdiction_type'] # baseline\n",
    "# # imp_cat_feature = ['flodfreqdc', 'drclassdcd','jurisdiction_type'] # v9.5 \n",
    "\n",
    "# if run_models:\n",
    "#     imp_cat_feature = ['county',\n",
    "#      'district',\n",
    "#      'drclassdcd',\n",
    "#      'drclasswet',\n",
    "#      'engcmssdcd',\n",
    "#      'engcmssmp',\n",
    "#      'engdwbdcd',\n",
    "#      'engdwbll',\n",
    "#      'engdwbml',\n",
    "#      'engdwobdcd',\n",
    "#      'englrsdcd',\n",
    "#      'engsldcd',\n",
    "#      'engsldcp',\n",
    "#      'engstafdcd',\n",
    "#      'engstafll',\n",
    "#      'engstafml',\n",
    "#      'flodfreqdc',\n",
    "#      'flodfreqma',\n",
    "#      'forpehrtdc',\n",
    "#      'huc4',\n",
    "#      'hydgrpdcd',\n",
    "#      'jurisdiction_type',\n",
    "#      'state',\n",
    "#      'urbrecptdc',\n",
    "#      'east_coast']\n",
    "#     file_param_dict[\"imp_cat_feature\"] = imp_cat_feature\n",
    "    \n",
    "#remove district and county\n",
    "if run_models: \n",
    "    imp_cat_feature = ['drclassdcd',\n",
    "     'drclasswet',\n",
    "     'engcmssdcd',\n",
    "     'engcmssmp',\n",
    "     'engdwbdcd',\n",
    "     'engdwbll',\n",
    "     'engdwbml',\n",
    "     'engdwobdcd',\n",
    "     'englrsdcd',\n",
    "     'engsldcd',\n",
    "     'engsldcp',\n",
    "     'engstafdcd',\n",
    "     'engstafll',\n",
    "     'engstafml',\n",
    "     'flodfreqdc',\n",
    "     'flodfreqma',\n",
    "     'forpehrtdc',\n",
    "     'huc4',\n",
    "     'hydgrpdcd',\n",
    "     'jurisdiction_type',\n",
    "     'state',\n",
    "     'urbrecptdc',\n",
    "     'east_coast']\n",
    "    file_param_dict[\"imp_cat_feature\"] = imp_cat_feature    \n",
    "    \n",
    "else:\n",
    "    imp_cat_feature = file_param_dict[\"imp_cat_feature\"]\n",
    "    \n",
    "# imp_cat_feature = ['jurisdiction_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VweeykE-4Ter"
   },
   "source": [
    "# Order Train-Dev-Test splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqbXGvZIRHGi",
    "outputId": "6238c23e-8db0-4cc0-fe3c-71f547ef6e6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2850, 423)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-arrange so numerical columns go first, then the categorical\n",
    "df1 = df[imp_num_feature]\n",
    "df2 = df[imp_cat_feature]\n",
    "\n",
    "# train\n",
    "df_X_combined_ordered = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "# dev\n",
    "df_dev_X = pd.concat([df_dev[imp_num_feature], df_dev[imp_cat_feature]], axis=1)\n",
    "\n",
    "\n",
    "# test\n",
    "df_test_X = pd.concat([df_test[imp_num_feature], df_test[imp_cat_feature]], axis=1)\n",
    "\n",
    "\n",
    "df_X_combined_ordered.columns #44\n",
    "df_X_combined_ordered.shape # (10000, 44)\n",
    "df_test_X.shape # (4500, 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['niccdcdpct',\n",
       " 'slopegradd',\n",
       " 'iccdcdpct',\n",
       " 'pondfreqpr',\n",
       " 'awmmfpwwta',\n",
       " 'aws050wta',\n",
       " 'aws0100wta',\n",
       " 'mukey',\n",
       " 'hydclprs',\n",
       " 'wtdepannmi',\n",
       " 'aws0150wta',\n",
       " 'urbrecptwt',\n",
       " 'brockdepmi',\n",
       " 'niccdcd',\n",
       " 'aws025wta',\n",
       " 'slopegradw',\n",
       " 'fl_gnis_name_ind_mean_200m',\n",
       " 'fl_startflag_sum_200m',\n",
       " 'wb_ftype_connector_200m',\n",
       " 'wb_gnis_name_ind_count_200m',\n",
       " 'fl_streamorde_mean_200m',\n",
       " 'wb_area_mean_200m',\n",
       " 'fl_areasqkm_count_200m',\n",
       " 'fl_areasqkm_sum_200m',\n",
       " 'fl_divergence_mean_200m',\n",
       " 'fl_intephem_mean_200m',\n",
       " 'fl_totdasqkm_mean_200m',\n",
       " 'fl_divergence_count_200m',\n",
       " 'fl_length_sum_200m',\n",
       " 'fl_streamorde_count_200m',\n",
       " 'wb_gnis_name_ind_mean_200m',\n",
       " 'wb_ftype_artificialpath_200m',\n",
       " 'fl_gnis_name_ind_sum_200m',\n",
       " 'fl_totdasqkm_count_200m',\n",
       " 'fl_streamorde_sum_200m',\n",
       " 'fl_ftype_pipeline_200m',\n",
       " 'wb_area_sum_200m',\n",
       " 'fl_ftype_coastline_200m',\n",
       " 'fl_length_mean_200m',\n",
       " 'wb_ftype_coastline_200m',\n",
       " 'wb_area_count_200m',\n",
       " 'fl_divergence_sum_200m',\n",
       " 'wb_ftype_streamriver_200m',\n",
       " 'fl_startflag_mean_200m',\n",
       " 'fl_intephem_sum_200m',\n",
       " 'fl_intephem_count_200m',\n",
       " 'fl_flow_type_count_200m',\n",
       " 'fl_startflag_count_200m',\n",
       " 'fl_flow_type_sum_200m',\n",
       " 'fl_totdasqkm_sum_200m',\n",
       " 'fl_ftype_connector_200m',\n",
       " 'fl_ftype_canalditch_200m',\n",
       " 'wb_ftype_pipeline_200m',\n",
       " 'fl_length_count_200m',\n",
       " 'fl_gnis_name_ind_count_200m',\n",
       " 'wb_gnis_name_ind_sum_200m',\n",
       " 'fl_ftype_artificialpath_200m',\n",
       " 'fl_flow_type_mean_200m',\n",
       " 'wb_ftype_canalditch_200m',\n",
       " 'fl_ftype_streamriver_200m',\n",
       " 'fl_areasqkm_mean_200m',\n",
       " 'fl_length_count_1000m',\n",
       " 'fl_areasqkm_sum_1000m',\n",
       " 'wb_gnis_name_ind_sum_1000m',\n",
       " 'fl_streamorde_sum_1000m',\n",
       " 'wb_area_sum_1000m',\n",
       " 'fl_divergence_mean_1000m',\n",
       " 'fl_flow_type_count_1000m',\n",
       " 'wb_ftype_artificialpath_1000m',\n",
       " 'wb_gnis_name_ind_mean_1000m',\n",
       " 'fl_gnis_name_ind_count_1000m',\n",
       " 'fl_startflag_sum_1000m',\n",
       " 'wb_area_mean_1000m',\n",
       " 'fl_startflag_mean_1000m',\n",
       " 'fl_ftype_connector_1000m',\n",
       " 'fl_totdasqkm_count_1000m',\n",
       " 'fl_gnis_name_ind_sum_1000m',\n",
       " 'fl_ftype_artificialpath_1000m',\n",
       " 'fl_ftype_pipeline_1000m',\n",
       " 'fl_startflag_count_1000m',\n",
       " 'wb_ftype_coastline_1000m',\n",
       " 'wb_ftype_connector_1000m',\n",
       " 'fl_totdasqkm_mean_1000m',\n",
       " 'fl_intephem_count_1000m',\n",
       " 'fl_flow_type_sum_1000m',\n",
       " 'wb_gnis_name_ind_count_1000m',\n",
       " 'wb_ftype_streamriver_1000m',\n",
       " 'fl_divergence_count_1000m',\n",
       " 'fl_streamorde_mean_1000m',\n",
       " 'fl_intephem_mean_1000m',\n",
       " 'fl_ftype_coastline_1000m',\n",
       " 'fl_intephem_sum_1000m',\n",
       " 'fl_totdasqkm_sum_1000m',\n",
       " 'fl_areasqkm_mean_1000m',\n",
       " 'fl_divergence_sum_1000m',\n",
       " 'fl_streamorde_count_1000m',\n",
       " 'fl_areasqkm_count_1000m',\n",
       " 'wb_ftype_pipeline_1000m',\n",
       " 'wb_area_count_1000m',\n",
       " 'wb_ftype_canalditch_1000m',\n",
       " 'fl_flow_type_mean_1000m',\n",
       " 'fl_ftype_canalditch_1000m',\n",
       " 'fl_gnis_name_ind_mean_1000m',\n",
       " 'fl_ftype_streamriver_1000m',\n",
       " 'nwi_CLASS_NAME_moss-lichen_200m',\n",
       " 'nwi_SUBSYSTEM_NAME_subtidal_200m',\n",
       " 'nwi_SYSTEM_NAME_palustrine_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_broad-leaved_evergreen_200m',\n",
       " 'nwi_SUBCLASS_NAME_vegetated_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_aquatic_moss_200m',\n",
       " 'nwi_estuarine_and_marine_wetland_200m',\n",
       " 'nwi_SUBCLASS_NAME_mollusk_200m',\n",
       " 'nwi_WATER_REGIME_NAME_seasonally_flooded_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_lichen_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_vegetated_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_mixohaline/mixosaline_(brackish)_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_acid_200m',\n",
       " 'nwi_CLASS_NAME_rocky_shore_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_coral_200m',\n",
       " 'nwi_CLASS_NAME_reef_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_mud_200m',\n",
       " 'nwi_SUBCLASS_NAME_bedrock_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_oligohaline_200m',\n",
       " 'nwi_SYSTEM_NAME_marine_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_artificial_substrate_200m',\n",
       " 'nwi_lake_200m',\n",
       " 'nwi_SUBCLASS_NAME_aquatic_moss_200m',\n",
       " 'nwi_SUBCLASS_NAME_coral_200m',\n",
       " 'nwi_SUBSYSTEM_NAME_littoral_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_zzz_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_non_persistent_200m',\n",
       " 'nwi_WATER_REGIME_SUBGROUP_zzz_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_broad-leaved_deciduous_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_rubble_200m',\n",
       " 'nwi_SUBCLASS_NAME_persistent_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_evergreen_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_unconsolidated_shore_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_dead_200m',\n",
       " 'nwi_SUBCLASS_NAME_evergreen_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_needle-leaved_deciduous_200m',\n",
       " 'nwi_SUBCLASS_NAME_deciduous_200m',\n",
       " 'nwi_SUBSYSTEM_NAME_lower_perennial_200m',\n",
       " 'nwi_SUBSYSTEM_NAME_tidal_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_needle-leaved_evergreen_200m',\n",
       " 'nwi_WATER_REGIME_NAME_temporary_flooded_200m',\n",
       " 'nwi_SUBCLASS_NAME_floating_vascular_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_rocky_shore_200m',\n",
       " 'nwi_CLASS_NAME_unconsolidated_bottom_200m',\n",
       " 'nwi_SUBCLASS_NAME_mud_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_organic_200m',\n",
       " 'nwi_WATER_REGIME_NAME_artificially_flooded_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_beaver_200m',\n",
       " 'nwi_other_200m',\n",
       " 'nwi_freshwater_emergent_wetland_200m',\n",
       " 'nwi_freshwater_pond_200m',\n",
       " 'nwi_SUBSYSTEM_NAME_unknown_perennial_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_unconsolidated_bottom_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_cobble-gravel_200m',\n",
       " 'nwi_SUBCLASS_NAME_zzz_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_farmed_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_emergent_200m',\n",
       " 'nwi_WATER_REGIME_SUBGROUP_saltwater_tidal_200m',\n",
       " 'nwi_WATER_REGIME_NAME_seasonally_saturated_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_deciduous_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_scrub-shrub_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_polyhaline_200m',\n",
       " 'nwi_riverine_200m',\n",
       " 'nwi_CLASS_NAME_forested_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_forested_200m',\n",
       " 'nwi_SUBCLASS_NAME_algal_200m',\n",
       " 'nwi_estuarine_and_marine_deepwater_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_moss_200m',\n",
       " 'nwi_CLASS_NAME_aquatic_bed_200m',\n",
       " 'nwi_WATER_REGIME_NAME_seasonally_flooded/saturated_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_floating_vascular_200m',\n",
       " 'nwi_SUBCLASS_NAME_non_persistent_200m',\n",
       " 'nwi_SUBCLASS_NAME_rooted_vascular_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_euthaline/eusaline_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_aquatic_bed_200m',\n",
       " 'nwi_SUBCLASS_NAME_cobble-gravel_200m',\n",
       " 'nwi_CLASS_NAME_emergent_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_spoil_200m',\n",
       " 'nwi_SUBCLASS_NAME_phragmites_australis_200m',\n",
       " 'nwi_SUBCLASS_NAME_broad-leaved_evergreen_200m',\n",
       " 'nwi_WATER_REGIME_NAME_temporary_flooded-tidal_200m',\n",
       " 'nwi_WATER_REGIME_SUBGROUP_freshwater_tidal_200m',\n",
       " 'nwi_WATER_REGIME_NAME_zzz_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_rooted_vascular_200m',\n",
       " 'nwi_SUBSYSTEM_NAME_intertidal_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_bedrock_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_diked/impounded_200m',\n",
       " 'nwi_CLASS_NAME_scrub-shrub_200m',\n",
       " 'nwi_SUBCLASS_NAME_broad-leaved_deciduous_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_alkaline_200m',\n",
       " 'nwi_freshwater_forested_200m',\n",
       " 'nwi_CLASS_NAME_unconsolidated_shore_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_reef_200m',\n",
       " 'nwi_SYSTEM_NAME_estuarine_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_mollusk_200m',\n",
       " 'nwi_WATER_REGIME_NAME_irregularly_flooded_200m',\n",
       " 'nwi_SUBCLASS_NAME_needle-leaved_deciduous_200m',\n",
       " 'nwi_WATER_REGIME_NAME_permanently_flooded-tidal_200m',\n",
       " 'nwi_SUBCLASS_NAME_lichen_200m',\n",
       " 'nwi_CLASS_NAME_streambed_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_organic_200m',\n",
       " 'nwi_SUBCLASS_NAME_organic_200m',\n",
       " 'nwi_SUBCLASS_NAME_sand_200m',\n",
       " 'nwi_WATER_REGIME_NAME_permanently_flooded_200m',\n",
       " 'nwi_WATER_REGIME_NAME_semipermanently_flooded-tidal_200m',\n",
       " 'nwi_SUBCLASS_NAME_dead_200m',\n",
       " 'nwi_SUBSYSTEM_NAME_limnetic_200m',\n",
       " 'nwi_SUBSYSTEM_NAME_intermittent_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_algal_200m',\n",
       " 'nwi_WATER_REGIME_NAME_seasonally_flooded-tidal_200m',\n",
       " 'nwi_WATER_REGIME_NAME_intermittently_flooded_200m',\n",
       " 'nwi_feature_count_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_moss-lichen_200m',\n",
       " 'nwi_SYSTEM_NAME_riverine_200m',\n",
       " 'nwi_WATER_REGIME_NAME_continuously__saturated_200m',\n",
       " 'nwi_WATER_REGIME_NAME_intermittently_exposed_200m',\n",
       " 'nwi_WATER_REGIME_NAME_irregularly_exposed_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_phragmites_australis_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_persistent_200m',\n",
       " 'nwi_SUBCLASS_NAME_moss_200m',\n",
       " 'nwi_SUBCLASS_NAME_rubble_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_excavated_200m',\n",
       " 'nwi_CLASS_NAME_zzz_200m',\n",
       " 'nwi_WATER_REGIME_NAME_regularly_flooded_200m',\n",
       " 'nwi_CLASS_NAME_rock_bottom_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_mesohaline_200m',\n",
       " 'nwi_WATER_REGIME_NAME_subtidal_200m',\n",
       " 'nwi_WATER_REGIME_NAME_semipermanently_flooded_200m',\n",
       " 'nwi_SYSTEM_NAME_lacustrine_200m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_sand_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_hyperhaline/hypersaline_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_zzz_200m',\n",
       " 'nwi_SUBSYSTEM_NAME_upper_perennial_200m',\n",
       " 'nwi_SUBCLASS_NAME_needle-leaved_evergreen_200m',\n",
       " 'nwi_WATER_REGIME_SUBGROUP_nontidal_200m',\n",
       " 'nwi_SPLIT_CLASS_NAME_zzz_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_mineral_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_partially_drained/ditched_200m',\n",
       " 'nwi_shrub_wetland_200m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_managed_200m',\n",
       " 'nwi_SUBCLASS_NAME_broad-leaved_deciduous_1000m',\n",
       " 'nwi_SUBSYSTEM_NAME_intertidal_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_moss_1000m',\n",
       " 'nwi_SUBCLASS_NAME_floating_vascular_1000m',\n",
       " 'nwi_SUBCLASS_NAME_dead_1000m',\n",
       " 'nwi_SUBCLASS_NAME_broad-leaved_evergreen_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_intermittently_exposed_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_mollusk_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_seasonally_flooded-tidal_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_polyhaline_1000m',\n",
       " 'nwi_SUBSYSTEM_NAME_unknown_perennial_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_acid_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_seasonally_flooded/saturated_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_semipermanently_flooded_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_vegetated_1000m',\n",
       " 'nwi_SUBSYSTEM_NAME_tidal_1000m',\n",
       " 'nwi_SUBCLASS_NAME_rubble_1000m',\n",
       " 'nwi_estuarine_and_marine_wetland_1000m',\n",
       " 'nwi_SUBCLASS_NAME_aquatic_moss_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_hyperhaline/hypersaline_1000m',\n",
       " 'nwi_SYSTEM_NAME_lacustrine_1000m',\n",
       " 'nwi_freshwater_pond_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_farmed_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_bedrock_1000m',\n",
       " 'nwi_SUBCLASS_NAME_mollusk_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_needle-leaved_evergreen_1000m',\n",
       " 'nwi_SUBCLASS_NAME_mud_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_needle-leaved_deciduous_1000m',\n",
       " 'nwi_SUBCLASS_NAME_bedrock_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_oligohaline_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_phragmites_australis_1000m',\n",
       " 'nwi_SUBCLASS_NAME_zzz_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_broad-leaved_deciduous_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_organic_1000m',\n",
       " 'nwi_SUBCLASS_NAME_sand_1000m',\n",
       " 'nwi_SUBSYSTEM_NAME_upper_perennial_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_subtidal_1000m',\n",
       " 'nwi_SUBCLASS_NAME_lichen_1000m',\n",
       " 'nwi_riverine_1000m',\n",
       " 'nwi_freshwater_forested_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_broad-leaved_evergreen_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_mineral_1000m',\n",
       " 'nwi_CLASS_NAME_unconsolidated_bottom_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_excavated_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_irregularly_flooded_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_euthaline/eusaline_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_intermittently_flooded_1000m',\n",
       " 'nwi_estuarine_and_marine_deepwater_1000m',\n",
       " 'nwi_SYSTEM_NAME_estuarine_1000m',\n",
       " 'nwi_CLASS_NAME_streambed_1000m',\n",
       " 'nwi_SPLIT_CLASS_NAME_reef_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_evergreen_1000m',\n",
       " 'nwi_SUBCLASS_NAME_needle-leaved_deciduous_1000m',\n",
       " 'nwi_SUBCLASS_NAME_persistent_1000m',\n",
       " 'nwi_SPLIT_CLASS_NAME_zzz_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_algal_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_beaver_1000m',\n",
       " 'nwi_SPLIT_CLASS_NAME_forested_1000m',\n",
       " 'nwi_CLASS_NAME_reef_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_zzz_1000m',\n",
       " 'nwi_SUBCLASS_NAME_non_persistent_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_regularly_flooded_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_deciduous_1000m',\n",
       " 'nwi_lake_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_dead_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_temporary_flooded-tidal_1000m',\n",
       " 'nwi_SUBSYSTEM_NAME_lower_perennial_1000m',\n",
       " 'nwi_CLASS_NAME_zzz_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_lichen_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_seasonally_saturated_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_irregularly_exposed_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_partially_drained/ditched_1000m',\n",
       " 'nwi_SPLIT_CLASS_NAME_rocky_shore_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_sand_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_permanently_flooded_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_rubble_1000m',\n",
       " 'nwi_feature_count_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_floating_vascular_1000m',\n",
       " 'nwi_SUBCLASS_NAME_phragmites_australis_1000m',\n",
       " 'nwi_SUBCLASS_NAME_needle-leaved_evergreen_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_coral_1000m',\n",
       " 'nwi_other_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_cobble-gravel_1000m',\n",
       " 'nwi_SPLIT_CLASS_NAME_unconsolidated_shore_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_alkaline_1000m',\n",
       " 'nwi_CLASS_NAME_unconsolidated_shore_1000m',\n",
       " 'nwi_SUBCLASS_NAME_deciduous_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_non_persistent_1000m',\n",
       " 'nwi_WATER_REGIME_SUBGROUP_saltwater_tidal_1000m',\n",
       " 'nwi_SUBSYSTEM_NAME_limnetic_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_zzz_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_artificial_substrate_1000m',\n",
       " 'nwi_WATER_REGIME_SUBGROUP_freshwater_tidal_1000m',\n",
       " 'nwi_WATER_REGIME_SUBGROUP_nontidal_1000m',\n",
       " 'nwi_CLASS_NAME_rock_bottom_1000m',\n",
       " 'nwi_SPLIT_CLASS_NAME_unconsolidated_bottom_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_spoil_1000m',\n",
       " 'nwi_SUBCLASS_NAME_organic_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_mesohaline_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_permanently_flooded-tidal_1000m',\n",
       " 'nwi_SYSTEM_NAME_marine_1000m',\n",
       " 'nwi_SUBSYSTEM_NAME_intermittent_1000m',\n",
       " 'nwi_SYSTEM_NAME_riverine_1000m',\n",
       " 'nwi_CLASS_NAME_rocky_shore_1000m',\n",
       " 'nwi_SUBCLASS_NAME_moss_1000m',\n",
       " 'nwi_SUBCLASS_NAME_coral_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_continuously__saturated_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_zzz_1000m',\n",
       " 'nwi_freshwater_emergent_wetland_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_rooted_vascular_1000m',\n",
       " 'nwi_SYSTEM_NAME_palustrine_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_mud_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_temporary_flooded_1000m',\n",
       " 'nwi_SPLIT_CLASS_NAME_emergent_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_aquatic_moss_1000m',\n",
       " 'nwi_SPLIT_CLASS_NAME_scrub-shrub_1000m',\n",
       " 'nwi_SUBCLASS_NAME_rooted_vascular_1000m',\n",
       " 'nwi_shrub_wetland_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_diked/impounded_1000m',\n",
       " 'nwi_SUBCLASS_NAME_cobble-gravel_1000m',\n",
       " 'nwi_CLASS_NAME_aquatic_bed_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_semipermanently_flooded-tidal_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_organic_1000m',\n",
       " 'nwi_SPLIT_CLASS_NAME_moss-lichen_1000m',\n",
       " 'nwi_CLASS_NAME_emergent_1000m',\n",
       " 'nwi_SPLIT_CLASS_NAME_aquatic_bed_1000m',\n",
       " 'nwi_CLASS_NAME_moss-lichen_1000m',\n",
       " 'nwi_WATER_REGIME_SUBGROUP_zzz_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_mixohaline/mixosaline_(brackish)_1000m',\n",
       " 'nwi_SUBSYSTEM_NAME_littoral_1000m',\n",
       " 'nwi_SPLIT_SUBCLASS_NAME_persistent_1000m',\n",
       " 'nwi_SUBCLASS_NAME_evergreen_1000m',\n",
       " 'nwi_FIRST_MODIFIER_NAME_managed_1000m',\n",
       " 'nwi_SUBCLASS_NAME_algal_1000m',\n",
       " 'nwi_CLASS_NAME_forested_1000m',\n",
       " 'nwi_CLASS_NAME_scrub-shrub_1000m',\n",
       " 'nwi_SUBSYSTEM_NAME_subtidal_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_artificially_flooded_1000m',\n",
       " 'nwi_WATER_REGIME_NAME_seasonally_flooded_1000m',\n",
       " 'nwi_SUBCLASS_NAME_vegetated_1000m',\n",
       " 'elevation_stdev_200m',\n",
       " 'slope_max_200m',\n",
       " 'elevation_min_200m',\n",
       " 'slope_mean_200m',\n",
       " 'slope_stdev_200m',\n",
       " 'elevation_max_200m',\n",
       " 'slope_min_200m',\n",
       " 'elevation_mean_200m',\n",
       " 'elevation_min_1000m',\n",
       " 'elevation_mean_1000m',\n",
       " 'slope_stdev_1000m',\n",
       " 'elevation_stdev_1000m',\n",
       " 'slope_max_1000m',\n",
       " 'slope_min_1000m',\n",
       " 'elevation_max_1000m',\n",
       " 'slope_mean_1000m']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_num_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdBKul2wROi4",
    "outputId": "fb607dae-a36a-4e9b-e4be-eb54ae133426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([31.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  2.]),\n",
       " array([0.00070822, 0.01004485, 0.01938149, 0.02871813, 0.03805477,\n",
       "        0.04739141, 0.05672805, 0.06606468, 0.07540132, 0.08473796,\n",
       "        0.0940746 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fraction of nan's in each numerical variable\n",
    "count = 0\n",
    "errors = 0\n",
    "nan_dist = []\n",
    "nan_vars = []\n",
    "for var in df_X_combined_ordered.describe().columns:\n",
    "    try:\n",
    "        if np.mean(df_X_combined_ordered[str(var)].isna()) != 0:\n",
    "            nan_vars.append(var)\n",
    "            count += 1\n",
    "            nan_dist.append(np.mean(df_X_combined_ordered[str(var)].isna()))\n",
    "#             print(var, round(np.mean(df_X_combined_ordered[str(var)].isna()), 2))\n",
    "    except Exception as e:\n",
    "        errors += 1\n",
    "        print(var, \"<-------------------\")\n",
    "print(count, errors    )\n",
    "plt.hist(nan_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute nearest 10 neighbor average for all nan values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_nan(lat, lon, value, var):\n",
    "    if np.isnan(value):\n",
    "        return knn_model_dict[var].predict(pd.DataFrame([[lat, lon]], columns=[\"latitude\", \"longitude\"]))[0]\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn_model_dict = {}\n",
    "\n",
    "if not no_lat_lon:\n",
    "    for var in nan_vars:\n",
    "        knn = KNeighborsRegressor(n_neighbors=30)\n",
    "        temp_X = df_X_combined_ordered[~df_X_combined_ordered[var].isna()][[\"latitude\", \"longitude\"]]\n",
    "        temp_Y = df_X_combined_ordered[var][~df_X_combined_ordered[var].isna()]\n",
    "        knn.fit(temp_X, temp_Y)\n",
    "        knn_model_dict[var] = knn\n",
    "        df_X_combined_ordered[var] = df_X_combined_ordered.apply(lambda x: impute_nan(x.latitude, x.longitude, x[var], var), axis=1)\n",
    "        df_dev_X[var] = df_dev_X.apply(lambda x: impute_nan(x.latitude, x.longitude, x[var], var), axis=1)\n",
    "        df_test_X[var] = df_test_X.apply(lambda x: impute_nan(x.latitude, x.longitude, x[var], var), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "D4kq__Giqima"
   },
   "outputs": [],
   "source": [
    "# impute 0's into wb_area_mean, fl_length_sum, fl_length_mean because they were\n",
    "# assigned np.nan if they were absent\n",
    "# A non-existent water feature should be assigned 0 given definition of each\n",
    "\n",
    "def fill_na(df):\n",
    "  try:\n",
    "    df.fl_length_sum_200m = df.fl_length_sum_200m.fillna(0)\n",
    "    df.fl_length_mean_200m = df.fl_length_sum_200m.fillna(0)\n",
    "    df.fl_length_sum_2500m = df.fl_length_sum_200m.fillna(0)\n",
    "    df.fl_length_mean_2500m = df.fl_length_sum_200m.fillna(0)\n",
    "  except:\n",
    "    pass\n",
    "  return df\n",
    "\n",
    "# No need for fill_na() since imputing by knn\n",
    "\n",
    "if no_lat_lon:\n",
    "    df_X_combined_ordered = fill_na(df_X_combined_ordered)\n",
    "    df_dev_X_combined_ordered = fill_na(df_dev_X)\n",
    "    df_test_X_combined_ordered = fill_na(df_test_X)\n",
    "else:\n",
    "    df_X_combined_ordered = df_X_combined_ordered\n",
    "    df_dev_X_combined_ordered = df_dev_X\n",
    "    df_test_X_combined_ordered = df_test_X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qy2KEjaNq487",
    "outputId": "077aa965-5d64-4ad9-abc7-001580eb74d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "niccdcdpct 0.01\n",
      "slopegradd 0.01\n",
      "iccdcdpct 0.01\n",
      "pondfreqpr 0.01\n",
      "awmmfpwwta 0.01\n",
      "aws050wta 0.01\n",
      "aws0100wta 0.01\n",
      "mukey 0.01\n",
      "hydclprs 0.01\n",
      "wtdepannmi 0.01\n",
      "aws0150wta 0.01\n",
      "urbrecptwt 0.01\n",
      "brockdepmi 0.01\n",
      "niccdcd 0.08\n",
      "aws025wta 0.01\n",
      "slopegradw 0.01\n",
      "elevation_stdev_200m 0.0\n",
      "slope_max_200m 0.0\n",
      "elevation_min_200m 0.0\n",
      "slope_mean_200m 0.0\n",
      "slope_stdev_200m 0.0\n",
      "elevation_max_200m 0.0\n",
      "slope_min_200m 0.0\n",
      "elevation_mean_200m 0.0\n",
      "elevation_min_1000m 0.0\n",
      "elevation_mean_1000m 0.0\n",
      "slope_stdev_1000m 0.0\n",
      "elevation_stdev_1000m 0.0\n",
      "slope_max_1000m 0.0\n",
      "slope_min_1000m 0.0\n",
      "elevation_max_1000m 0.0\n",
      "slope_mean_1000m 0.0\n",
      "\n",
      "Dev\n",
      "niccdcdpct 0.01\n",
      "slopegradd 0.01\n",
      "iccdcdpct 0.01\n",
      "pondfreqpr 0.01\n",
      "awmmfpwwta 0.01\n",
      "aws050wta 0.01\n",
      "aws0100wta 0.01\n",
      "mukey 0.01\n",
      "hydclprs 0.01\n",
      "wtdepannmi 0.01\n",
      "aws0150wta 0.01\n",
      "urbrecptwt 0.01\n",
      "brockdepmi 0.01\n",
      "niccdcd 0.07\n",
      "aws025wta 0.01\n",
      "slopegradw 0.01\n",
      "elevation_stdev_200m 0.0\n",
      "slope_max_200m 0.0\n",
      "elevation_min_200m 0.0\n",
      "slope_mean_200m 0.0\n",
      "slope_stdev_200m 0.0\n",
      "elevation_max_200m 0.0\n",
      "slope_min_200m 0.0\n",
      "elevation_mean_200m 0.0\n",
      "elevation_min_1000m 0.0\n",
      "elevation_mean_1000m 0.0\n",
      "slope_stdev_1000m 0.0\n",
      "elevation_stdev_1000m 0.0\n",
      "slope_max_1000m 0.0\n",
      "slope_min_1000m 0.0\n",
      "elevation_max_1000m 0.0\n",
      "slope_mean_1000m 0.0\n",
      "\n",
      "Test\n",
      "niccdcdpct 0.01\n",
      "slopegradd 0.01\n",
      "iccdcdpct 0.01\n",
      "pondfreqpr 0.01\n",
      "awmmfpwwta 0.01\n",
      "aws050wta 0.01\n",
      "aws0100wta 0.01\n",
      "mukey 0.01\n",
      "hydclprs 0.01\n",
      "wtdepannmi 0.01\n",
      "aws0150wta 0.01\n",
      "urbrecptwt 0.01\n",
      "brockdepmi 0.01\n",
      "niccdcd 0.08\n",
      "aws025wta 0.01\n",
      "slopegradw 0.01\n",
      "elevation_stdev_200m 0.0\n",
      "slope_max_200m 0.0\n",
      "elevation_min_200m 0.0\n",
      "slope_mean_200m 0.0\n",
      "slope_stdev_200m 0.0\n",
      "elevation_max_200m 0.0\n",
      "slope_min_200m 0.0\n",
      "elevation_mean_200m 0.0\n",
      "elevation_min_1000m 0.0\n",
      "elevation_mean_1000m 0.0\n",
      "slope_stdev_1000m 0.0\n",
      "elevation_stdev_1000m 0.0\n",
      "slope_max_1000m 0.0\n",
      "slope_min_1000m 0.0\n",
      "elevation_max_1000m 0.0\n",
      "slope_mean_1000m 0.0\n"
     ]
    }
   ],
   "source": [
    "# fraction of nan's in each variable\n",
    "def print_na(df_X_combined_ordered):\n",
    "  for var in df_X_combined_ordered.describe().columns:\n",
    "    try:\n",
    "        if np.mean(df_X_combined_ordered[str(var)].isna()) != 0:\n",
    "          print(var, round(np.mean(df_X_combined_ordered[str(var)].isna()), 2))\n",
    "    except Exception as e:\n",
    "        print(var)\n",
    "        print(e)\n",
    "        pass\n",
    "        \n",
    "print(\"Train\")    \n",
    "print_na(df_X_combined_ordered)      \n",
    "print()\n",
    "print(\"Dev\")\n",
    "print_na(df_dev_X_combined_ordered)\n",
    "print()\n",
    "print(\"Test\")\n",
    "print_na(df_test_X_combined_ordered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiZZiHI7rroC"
   },
   "source": [
    "# Offline OHE to keep track of variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "5wgvKVZ7rNb8"
   },
   "outputs": [],
   "source": [
    "# ohe-hot-encode the columns\n",
    "# get_dummies only encodes cat columns\n",
    "df_X_combined_dummies_ordered = pd.get_dummies(df_X_combined_ordered)\n",
    "# df_X_combined_dummies_ordered.columns # 90\n",
    "\n",
    "df_dev_X_combined_dummies_ordered = pd.get_dummies(df_dev_X_combined_ordered)\n",
    "df_test_X_combined_dummies_ordered = pd.get_dummies(df_test_X_combined_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2DzQYz-guOe",
    "outputId": "d15cc667-b613-4161-fdee-cb63bd03ce29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8472, 423)\n",
      "(2840, 423)\n",
      "(2850, 423)\n",
      "(8472, 753)\n",
      "(2840, 725)\n",
      "(2850, 723)\n"
     ]
    }
   ],
   "source": [
    "print(df_X_combined_ordered.shape)\n",
    "print(df_dev_X_combined_ordered.shape)\n",
    "print(df_test_X_combined_ordered.shape)\n",
    "print(df_X_combined_dummies_ordered.shape)\n",
    "print(df_dev_X_combined_dummies_ordered.shape)\n",
    "print(df_test_X_combined_dummies_ordered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1Eq49x-r55M"
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "YoBhg5wPrxlx"
   },
   "outputs": [],
   "source": [
    "# impute categorical data\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "  \"\"\"\n",
    "  By inheriting TransformerMixin, you get fit_transform method for free \n",
    "  if you implement fit and transform methods\n",
    "  \"\"\" \n",
    "\n",
    "  def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "\n",
    "        Columns of dtype object are imputed with the most frequent value \n",
    "        in column.\n",
    "        Columns of other types are imputed with median of column.\n",
    "        \"\"\"\n",
    "  def fit(self, X, y=None):\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].median() for c in X], \n",
    "            index=X.columns)\n",
    "        return self\n",
    "\n",
    "  def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "2E_VtoXpr8W9"
   },
   "outputs": [],
   "source": [
    "# Pipeline for numerical columns\n",
    "# 1. fill NA's with median values\n",
    "# 2. scale them\n",
    "\n",
    "# num_pipeline_impute_ss = Pipeline([        # should be list of tuples\n",
    "#                           (\"num_imputer\", SimpleImputer(strategy=\"median\")),\n",
    "#                           (\"std_scaler\", StandardScaler())\n",
    "#                           ])                      \n",
    "\n",
    "# num_pipeline_impute_ss = Pipeline([        # should be list of tuples\n",
    "#                           (\"num_imputer\", SimpleImputer(strategy=\"median\")),\n",
    "#                           (\"robust_scaler\", RobustScaler())\n",
    "#                           ])                      \n",
    "\n",
    "num_pipeline_impute_ss = Pipeline([        # should be list of tuples\n",
    "                          (\"num_imputer\", SimpleImputer(strategy=\"median\"))\n",
    "                          ])                      \n",
    "\n",
    "\n",
    "# Pipleline for categorical columns\n",
    "# 1. fill NA's with most frequent values\n",
    "# 2. one hot code\n",
    "\n",
    "# cat_pipeline_impute_ohe = Pipeline([(\"cat_imputer\", DataFrameImputer()),\n",
    "#                          (\"one_hot_encoder\", OneHotEncoder(drop=\"first\", \\\n",
    "#                                                            sparse=False))\n",
    "#                          ])\n",
    "\n",
    "\n",
    "# you want to do the following where you handle_unknown categories in the \n",
    "# test data by ignoring them. However, in the imeplementation, I am using\n",
    "# df_X_combined_dummies_ordered to indicate the numerical and cat columns \n",
    "# hence need to fix the df_X_combined_dummies_ordered such that the first \n",
    "# ohe is not dropped (as is being done in immediately above)\n",
    "\n",
    "cat_pipeline_impute_ohe = Pipeline([(\"cat_imputer\", DataFrameImputer()),\n",
    "                         (\"one_hot_encoder\", OneHotEncoder(sparse=False,\n",
    "                                                           handle_unknown = \"ignore\"))\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "T6zsqDgLsIhp"
   },
   "outputs": [],
   "source": [
    "numericals_list = list(df_X_combined_ordered.describe().columns)\n",
    "categories_list = list(set(df_X_combined_ordered.columns) - set(numericals_list))\n",
    "\n",
    "# here trying to do numerical and categorical transformation in isolation\n",
    "# this because ColumnTransformer removes column name information :-(\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# only the cat columns will be one-hot encoded\n",
    "partial_transformer_impute_ohe = ColumnTransformer([\n",
    "                                   (\"categorical_ohe\", cat_pipeline_impute_ohe,\\\n",
    "                                    categories_list)\n",
    "])\n",
    "\n",
    "# only the numerical columns withh get standard scaling\n",
    "partial_transformer_impute_ss = ColumnTransformer([\n",
    "                                   (\"numerical_ss_impute\", num_pipeline_impute_ss,\\\n",
    "                                    numericals_list)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation of Dev and Test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7DxNTfIFtT9y",
    "outputId": "5d8a5f9d-f079-43d8-b8db-65afc2d25027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8472, 400)\n",
      "(2840, 400)\n",
      "(2850, 400)\n"
     ]
    }
   ],
   "source": [
    "# Pass the numerical columns through Numerical Pipeline \n",
    "\n",
    "# train\n",
    "full_data_ohe_ss_imputed = (partial_transformer_impute_ss\n",
    "                            .fit(df_X_combined_ordered[numericals_list])\n",
    "                            .transform(df_X_combined_ordered[numericals_list])) \n",
    "print(full_data_ohe_ss_imputed.shape)\n",
    "\n",
    "# dev\n",
    "dev_ohe_ss_imputed = (partial_transformer_impute_ss\n",
    "                            .fit(df_X_combined_ordered[numericals_list])\n",
    "                            .transform(df_dev_X_combined_ordered[numericals_list])) \n",
    "print(dev_ohe_ss_imputed.shape)\n",
    "\n",
    "\n",
    "# test\n",
    "test_ohe_ss_imputed = (partial_transformer_impute_ss\n",
    "                            .fit(df_X_combined_ordered[numericals_list])\n",
    "                            .transform(df_test_X_combined_ordered[numericals_list])) \n",
    "print(test_ohe_ss_imputed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQD-xNjqtUA9",
    "outputId": "9bf01104-653e-4175-e099-3c7a0296e530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8472, 353)\n",
      "(2840, 353)\n",
      "(2850, 353)\n"
     ]
    }
   ],
   "source": [
    "# Pass the cat columns through Categorical Pipeline\n",
    "\n",
    "# train\n",
    "cat_data_OHE = (partial_transformer_impute_ohe\n",
    "                .fit(df_X_combined_ordered)\n",
    "                .transform(df_X_combined_ordered))\n",
    "print(cat_data_OHE.shape)\n",
    "\n",
    "# test\n",
    "dev_cat_data_OHE = (partial_transformer_impute_ohe\n",
    "                .fit(df_X_combined_ordered)\n",
    "                .transform(df_dev_X_combined_ordered))\n",
    "print(dev_cat_data_OHE.shape)\n",
    "\n",
    "# test\n",
    "test_cat_data_OHE = (partial_transformer_impute_ohe\n",
    "                .fit(df_X_combined_ordered)\n",
    "                .transform(df_test_X_combined_ordered))\n",
    "print(test_cat_data_OHE.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy X and Y arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgK2Nv2HycZo",
    "outputId": "9af08aa1-945f-49a2-a36b-42064875d6d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8472, 753) (8472,) (2840, 753) (2840,) (2850, 753) (2850,)\n"
     ]
    }
   ],
   "source": [
    "# join the arrays into one array that can be passed into models\n",
    "\n",
    "# train\n",
    "X = np.hstack((full_data_ohe_ss_imputed, cat_data_OHE))\n",
    "Y = np.array(df.cwa_determination)\n",
    "Y_groups = np.array(df.cwa_determination_groups)\n",
    "\n",
    "# dev\n",
    "dev_X = np.hstack((dev_ohe_ss_imputed, dev_cat_data_OHE))\n",
    "dev_Y = np.array(df_dev.cwa_determination)\n",
    "dev_Y_groups = np.array(df_dev.cwa_determination_groups)\n",
    "\n",
    "# test\n",
    "test_X = np.hstack((test_ohe_ss_imputed, test_cat_data_OHE))\n",
    "test_Y = np.array(df_test.cwa_determination)\n",
    "test_Y_groups = np.array(df_test.cwa_determination_groups)\n",
    "\n",
    "print(X.shape, Y.shape, dev_X.shape, dev_Y.shape, test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "vNnvAK30tUDx"
   },
   "outputs": [],
   "source": [
    "# Convert numerical and cat transforms back to dataframe (for housekeeping)\n",
    "\n",
    "# convert numerical arrays into dataframe\n",
    "\n",
    "def make_dataframe(full_data_ohe_ss_imputed, cat_data_OHE):\n",
    "  df_num_data_ohe_ss = (pd.DataFrame(\n",
    "      full_data_ohe_ss_imputed,\n",
    "      columns=list(df_X_combined_dummies_ordered[numericals_list].columns)\n",
    "  ))\n",
    "\n",
    "  # # convert cat arrays into dataframe\n",
    "  ohe_categories_list = (list(set(df_X_combined_dummies_ordered.columns) - set(numericals_list)))\n",
    "  df_cat_data_OHE = (pd.DataFrame(\n",
    "      cat_data_OHE,\n",
    "      columns=list(df_X_combined_dummies_ordered[ohe_categories_list].columns))\n",
    "  )\n",
    "\n",
    "  # concatenate into one dataframe\n",
    "\n",
    "  return pd.concat([df_num_data_ohe_ss, df_cat_data_OHE], axis=1)\n",
    "\n",
    "\n",
    "df_train_X_dummies = make_dataframe(full_data_ohe_ss_imputed, cat_data_OHE)\n",
    "df_dev_X_dummies = make_dataframe(dev_ohe_ss_imputed, dev_cat_data_OHE)\n",
    "df_test_X_dummies = make_dataframe(test_ohe_ss_imputed, test_cat_data_OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "iY1gOlOk5-ZM"
   },
   "outputs": [],
   "source": [
    "if stop_before_models:\n",
    "    stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8472, 753)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "if False: # True if you want to run this\n",
    "    # define inliers as negatives and outliers as positive examples\n",
    "    inliers = Y == 0\n",
    "    outliers = Y == 1\n",
    "    X_inliers = X[inliers]\n",
    "    Y_inliers = Y[inliers]\n",
    "\n",
    "    clf = OneClassSVM(gamma='auto').fit(X_inliers)\n",
    "    \n",
    "    # predict on filtered train, train and dev data\n",
    "    X_inliers_predict = clf.predict(X_inliers)\n",
    "    X_predict = clf.predict(X)\n",
    "    dev_predict = clf.predict(dev_X)\n",
    "    \n",
    "    # transform on train and dev data\n",
    "    train_score_samples = clf.score_samples(X)\n",
    "    dev_score_samples = clf.score_samples(dev_X)\n",
    "\n",
    "    # replace 1's by 0's (1 of OneClassSVM is the inlier or the majority class which is 0)\n",
    "    # replace 1's by -1's (define outliers as minority class)\n",
    "    dev_predict[dev_predict == 1] = 0\n",
    "    dev_predict[dev_predict == -1] = 1\n",
    "    print(np.mean(dev_predict == dev_Y)) # 0.38839590443686006\n",
    "    \n",
    "    # do same on filtered X data\n",
    "    X_inliers_predict[X_inliers_predict == 1] = 0\n",
    "    X_inliers_predict[X_inliers_predict == -1] = 1\n",
    "    print(np.mean(X_inliers_predict == Y_inliers)) # 0.5502357635110627\n",
    "\n",
    "    # do same on train data\n",
    "    X_predict[X_predict == 1] = 0\n",
    "    X_predict[X_predict == -1] = 1\n",
    "    print(np.mean(X_predict == Y)) # 0.708762296957218\n",
    "\n",
    "    plt.hist(dev_score_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mahalanobis Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "# dist = DistanceMetric.get_metric(\"mahalanobis\", V=cov.get_mahalanobis_matrix())\n",
    "# dist = DistanceMetric.get_metric(\"mahalanobis\", V=np.cov(X))\n",
    "# dist.pairwise(X)\n",
    "\n",
    "# np.linalg.det(np.cov(X))\n",
    "# np.linalg.det(np.linalg.pinv(np.cov(X)))\n",
    "# np.linalg.cond(X)\n",
    "# np.linalg.pinv(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from metric_learn import Covariance\n",
    "# from sklearn.datasets import load_iris\n",
    "# iris = load_iris()['data']\n",
    "# cov = Covariance().fit(iris)\n",
    "# x = cov.transform(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA and Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P2(n_components, data): # from Project 3!\n",
    "  \"\"\"\n",
    "  Takes target dimensionality reduction (k) and the data to reduce\n",
    "  Returns the reduced data\n",
    "  \"\"\"\n",
    "  \n",
    "  pca = PCA(n_components)\n",
    "  pca.fit(data)\n",
    "  return pca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # True if you want to run this\n",
    "    n_components = 475 # maximum is X.shape[1]\n",
    "    d = 2\n",
    "    fig, axes = plt.subplots(d, d, figsize=(10, 10))\n",
    "    # Dimension reduction\n",
    "    pca = P2(n_components=n_components, data=X)\n",
    "    X = pca.transform(X)\n",
    "\n",
    "    import seaborn as sns\n",
    "    colors = [\"g\", \"r\"]\n",
    "\n",
    "    for i in range(d**2):\n",
    "        pc_i, pc_i_1 = X[:, i], X[:, i+1]\n",
    "        sns.scatterplot(ax=axes[i//d, i%d], x=pc_i, y=pc_i_1, hue=np.array(Y).flatten())\n",
    "        axes[i//d, i%d].set_xlabel(\"PC\" + str(i+1))\n",
    "        axes[i//d, i%d].set_ylabel(\"PC\" + str(i+2))\n",
    "        \n",
    "    dev_X = pca.transform(dev_X)\n",
    "    test_X = pca.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZOqLgq5EsPm"
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmWtOA8lEThm",
    "outputId": "3a4a38ac-dfe3-4cc8-ddd0-80ae86b3eec8"
   },
   "outputs": [],
   "source": [
    "# print(sorted(metrics.SCORERS.keys()))\n",
    "# sorted(metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_search.__dir__()\n",
    "# random_search.return_train_score\n",
    "\n",
    "# random_search.scoring # roc_auc\n",
    "# random_search.best_score_ # \n",
    "# random_search.scorer_ # make_scorer(roc_auc_score, needs_threshold=True)\n",
    "\n",
    "# random_search.cv_results_\n",
    "# random_search.predict_proba(X)\n",
    "# random_search.predict_log_proba(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_taken(start, end):\n",
    "    delta = end - start\n",
    "    print(\"Time taken (min):\", round(delta.seconds/60, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(fitted_model, test_X, test_Y, model_name):\n",
    "\n",
    "    y_predict_proba = fitted_model.predict_proba(test_X)[:, 1]\n",
    "    pv = ppv_npv_opt_th(test_Y, y_predict_proba)\n",
    "#     print(\"{}: {}ppv = {}, npv = {}\".format(fitted_model.estimator, \" \"*(13 - len(str(fitted_model.estimator))), round(pv[0], 4), round(pv[1], 4)))\n",
    "    print(\"{}: {}ppv = {}, npv = {} @ threshold = {}\".format(model_name, \" \"*(13 - len(model_name)), round(pv[0], 4), round(pv[1], 4), round(pv[2], 4)))\n",
    "\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html\n",
    "    # AP summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold\n",
    "    print(\"average_precision_score:\", round(metrics.average_precision_score(test_Y, fitted_model.predict_proba(test_X)[:, 1], average=\"weighted\"), 5))\n",
    "        \n",
    "    y_prob = fitted_model.predict_proba(test_X)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_Y, y_prob[:, 1], pos_label=1)\n",
    "    print(\"roc_auc\",\":\", round(metrics.auc(fpr, tpr), 5))\n",
    "        \n",
    "    print(\"Classification Report:\") # threshold agnostic because you pass in the test labels instead of scores (probabilities)\n",
    "    print(classification_report(test_Y, fitted_model.predict(test_X)))\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(test_Y, fitted_model.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_roc_auc(fitted_model, test_X, test_Y):\n",
    "    y_prob = fitted_model.predict_proba(test_X)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_Y, y_prob[:, 1], pos_label=1)\n",
    "    return round(metrics.auc(fpr, tpr), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 0.2525)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ppv_npv_opt_th(y_true=np.array([1,0,1]), y_predict_proba=np.array([0.5, 0.25, 0.3])):\n",
    "    \"\"\"\n",
    "    Inputs: y_true labels and prediction scores\n",
    "    Outputs: optimized positive predictive value and negative predictive values per this reference\n",
    "    https://arxiv.org/pdf/2007.05073.pdf\n",
    "    \"\"\"\n",
    "    min_ppv_npv_list = []\n",
    "    th_list = np.linspace(0, 1, 100)\n",
    "    for th in th_list:\n",
    "        y_predict = 1 * (y_predict_proba > th)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_predict).ravel()\n",
    "        ppv = tp / (tp + fp) \n",
    "        npv = tn / (fn + tn)\n",
    "        min_ppv_npv = np.min(np.nan_to_num(np.array((ppv, npv))))\n",
    "        min_ppv_npv_list.append(min_ppv_npv)\n",
    "    max_ppv_npv = np.nanmax(np.array(min_ppv_npv_list))\n",
    "    opt_th_index = np.array(min_ppv_npv_list).argmax(axis=0)\n",
    "    opt_th = th_list[opt_th_index]\n",
    "    opt_y_predict = 1 * (y_predict_proba > opt_th)\n",
    "    opt_tn, opt_fp, opt_fn, opt_tp = confusion_matrix(y_true, opt_y_predict).ravel()\n",
    "    opt_ppv = opt_tp / (opt_tp + opt_fp) \n",
    "    opt_npv = opt_tn / (opt_fn + opt_tn)\n",
    "    return opt_ppv, opt_npv, round(opt_th, 4)\n",
    "ppv_npv_opt_th()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ppv_npv(y_true, y_predict):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_predict).ravel()\n",
    "    ppv = tp / (tp + fp) \n",
    "    npv = tn / (fn + tn)    \n",
    "    return ppv, npv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['latitude', 'cwa7', 'cwa8', 'jurisdiction_type', 'cwa9',\n",
       "       'cwa_determination', 'rha1', 'date_issued_or_denied',\n",
       "       'potential_wetland', 'cwa2',\n",
       "       ...\n",
       "       'nwi_FIRST_MODIFIER_NAME_managed_1000m',\n",
       "       'nwi_SUBCLASS_NAME_algal_1000m', 'nwi_CLASS_NAME_forested_1000m',\n",
       "       'nwi_CLASS_NAME_scrub-shrub_1000m', 'nwi_SUBSYSTEM_NAME_subtidal_1000m',\n",
       "       'nwi_WATER_REGIME_NAME_artificially_flooded_1000m',\n",
       "       'nwi_WATER_REGIME_NAME_seasonally_flooded_1000m',\n",
       "       'nwi_SUBCLASS_NAME_vegetated_1000m', 'cwa_determination_groups',\n",
       "       'east_coast'],\n",
       "      dtype='object', length=450)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.log(df.closest_wb_distance_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.log(df.closest_fl_distance_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.log(df.closest_fl_area_sqkm.apply(lambda x: x if x > 0 else np.nan)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.log(df.closest_wb_area_sqkm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.log(df.closest_fl_elevation.apply(lambda x: x if x > 0 else np.nan)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ez1BBgTW_Bk"
   },
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-nU49jh6tULS",
    "outputId": "166d48d9-0f92-4c84-a479-c662c5172834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-e90f4c406724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m                                scoring=optimize_ppv_npv_scorer))\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mrandom_search_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lgbm\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_search_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file_params\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_param_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1619\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1620\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1), EXIT(1)}"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/binilg/lightgbm-with-randomsearchcv-and-feature-imp\n",
    "# Implementation: https://www.kaggle.com/mlisovyi/lightgbm-hyperparameter-optimisation-lb-0-761\n",
    "# Documentation: https://lightgbm.readthedocs.io/en/latest/Features.html\n",
    "# LightGBM Classifier: https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#\n",
    "\n",
    "from optimize_ppv_npv_scorer_ import optimize_ppv_npv_scorer\n",
    "\n",
    "import lightgbm\n",
    "param_dict = {\n",
    "    'learning_rate': [0.05],\n",
    "    'num_leaves': [90,200],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'max_depth' : [5,6,7,8],\n",
    "    'random_state' : [501], \n",
    "    'colsample_bytree' : [0.5,0.7],\n",
    "    'subsample' : [0.5,0.7],\n",
    "    'min_split_gain' : [0.01],\n",
    "    'min_data_in_leaf':[10],\n",
    "#     'metric':['auc']\n",
    "    }\n",
    "#modelling\n",
    "clf = lightgbm.LGBMClassifier()\n",
    "\n",
    "if run_models:\n",
    "    random_search_model = (RandomizedSearchCV(clf, \n",
    "                               param_dict, \n",
    "                               verbose=1, \n",
    "                               cv=10, \n",
    "                               n_jobs = -1, \n",
    "                               n_iter=10,\n",
    "                               scoring=optimize_ppv_npv_scorer))\n",
    "        # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    random_search_model.fit(X, Y)\n",
    "    model_dict[\"lgbm\"] = random_search_model.best_estimator_\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "    \n",
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "lgbm = model_dict[\"lgbm\"]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(lgbm, dev_X, dev_Y, model_name=\"lgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "id": "SaFbWsFQX5Vs",
    "outputId": "f00a317c-8b5f-4dd4-e538-8056b8a803be"
   },
   "outputs": [],
   "source": [
    "#Feature importance for top 50 predictors\n",
    "predictors = [x for x in df_X_combined_dummies_ordered.columns]\n",
    "feat_imp = pd.Series(lgbm.feature_importances_, predictors).sort_values(ascending=False)\n",
    "feat_imp = feat_imp[0:50]\n",
    "plt.rcParams['figure.figsize'] = 20, 5\n",
    "feat_imp.plot(kind='bar', title='Feature Importance')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/binilg/lightgbm-with-randomsearchcv-and-feature-imp\n",
    "# Implementation: https://www.kaggle.com/mlisovyi/lightgbm-hyperparameter-optimisation-lb-0-761\n",
    "# Documentation: https://lightgbm.readthedocs.io/en/latest/Features.html\n",
    "# LightGBM Classifier: https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#\n",
    "\n",
    "from optimize_ppv_npv_scorer_ import optimize_ppv_npv_scorer\n",
    "\n",
    "import lightgbm\n",
    "param_dict = {\n",
    "    'learning_rate': [0.05],\n",
    "    'num_leaves': [90,200],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['multiclass'],\n",
    "    'max_depth' : [5,6,7,8],\n",
    "    'random_state' : [501], \n",
    "    'colsample_bytree' : [0.5,0.7],\n",
    "    'subsample' : [0.5,0.7],\n",
    "    'min_split_gain' : [0.01],\n",
    "    'min_data_in_leaf':[10],\n",
    "#     'metric':['auc']\n",
    "    }\n",
    "#modelling\n",
    "clf = lightgbm.LGBMClassifier()\n",
    "\n",
    "if run_models:\n",
    "    random_search_model = (RandomizedSearchCV(clf, \n",
    "                               param_dict, \n",
    "                               verbose=1, \n",
    "                               cv=10, \n",
    "                               n_jobs = -1, \n",
    "                               n_iter=10,\n",
    "                               scoring=optimize_ppv_npv_scorer))\n",
    "        # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    random_search_model.fit(X, Y_groups)\n",
    "    model_dict[\"lgbm_groups\"] = random_search_model.best_estimator_\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "    \n",
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "lgbm_groups = model_dict[\"lgbm_groups\"]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1 = Y_groups == 1\n",
    "group_2 = Y_groups == 2\n",
    "group_3 = Y_groups == 3\n",
    "\n",
    "print(np.mean(Y_groups[group_1] == lgbm_groups.predict(X[group_1])))\n",
    "print(np.mean(Y_groups[group_2] == lgbm_groups.predict(X[group_2])))\n",
    "print(np.mean(Y_groups[group_3] == lgbm_groups.predict(X[group_3])))\n",
    "\n",
    "train_predict = lgbm_groups.predict(X)\n",
    "pd.DataFrame(train_predict).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_group_1 = dev_Y_groups == 1\n",
    "dev_group_2 = dev_Y_groups == 2\n",
    "dev_group_3 = dev_Y_groups == 3\n",
    "\n",
    "print(np.mean(dev_Y_groups[dev_group_1] == lgbm_groups.predict(dev_X[dev_group_1])))\n",
    "print(np.mean(dev_Y_groups[dev_group_2] == lgbm_groups.predict(dev_X[dev_group_2])))\n",
    "print(np.mean(dev_Y_groups[dev_group_3] == lgbm_groups.predict(dev_X[dev_group_3])))\n",
    "\n",
    "dev_predict = lgbm_groups.predict(dev_X)\n",
    "pd.DataFrame(dev_predict).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(test_Y_groups).value_counts())\n",
    "\n",
    "test_group_1 = test_Y_groups == 1\n",
    "test_group_2 = test_Y_groups == 2\n",
    "test_group_3 = test_Y_groups == 3\n",
    "\n",
    "print(np.mean(test_Y_groups[test_group_1] == lgbm_groups.predict(test_X[test_group_1])))\n",
    "print(np.mean(test_Y_groups[test_group_2] == lgbm_groups.predict(test_X[test_group_2])))\n",
    "print(np.mean(test_Y_groups[test_group_3] == lgbm_groups.predict(test_X[test_group_3])))\n",
    "\n",
    "test_predict = lgbm_groups.predict(test_X)\n",
    "print(pd.DataFrame(test_predict).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following for \n",
    "# 1: 1,2,3,5\n",
    "# 2: 4,6,7\n",
    "# 3: 8 ,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1 = Y_groups == 1\n",
    "group_2 = Y_groups == 2\n",
    "group_3 = Y_groups == 3\n",
    "\n",
    "print(np.mean(Y_groups[group_1] == lgbm_groups.predict(X[group_1])))\n",
    "print(np.mean(Y_groups[group_2] == lgbm_groups.predict(X[group_2])))\n",
    "print(np.mean(Y_groups[group_3] == lgbm_groups.predict(X[group_3])))\n",
    "\n",
    "train_predict = lgbm_groups.predict(X)\n",
    "pd.DataFrame(train_predict).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_group_1 = dev_Y_groups == 1\n",
    "dev_group_2 = dev_Y_groups == 2\n",
    "dev_group_3 = dev_Y_groups == 3\n",
    "\n",
    "print(np.mean(dev_Y_groups[dev_group_1] == lgbm_groups.predict(dev_X[dev_group_1])))\n",
    "print(np.mean(dev_Y_groups[dev_group_2] == lgbm_groups.predict(dev_X[dev_group_2])))\n",
    "print(np.mean(dev_Y_groups[dev_group_3] == lgbm_groups.predict(dev_X[dev_group_3])))\n",
    "\n",
    "dev_predict = lgbm_groups.predict(dev_X)\n",
    "pd.DataFrame(dev_predict).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_group_1 = test_Y_groups == 1\n",
    "test_group_2 = test_Y_groups == 2\n",
    "test_group_3 = test_Y_groups == 3\n",
    "\n",
    "print(np.mean(test_Y_groups[test_group_1] == lgbm_groups.predict(test_X[test_group_1])))\n",
    "print(np.mean(test_Y_groups[test_group_2] == lgbm_groups.predict(test_X[test_group_2])))\n",
    "print(np.mean(test_Y_groups[test_group_3] == lgbm_groups.predict(test_X[test_group_3])))\n",
    "\n",
    "test_predict = lgbm_groups.predict(test_X)\n",
    "pd.DataFrame(test_predict).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM: Second level learner to minimize False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(lgbm, X, Y, model_name=\"lgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify all the true and false negatives on train data\n",
    "\n",
    "lgbm = model_dict[\"lgbm\"]  \n",
    "\n",
    "negs = model_dict[\"lgbm\"].predict(X) == 0\n",
    "X_negs = X[negs]\n",
    "Y_negs = Y[negs]\n",
    "np.mean(Y_negs) # 13% of the predicted negatives are true negatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    'learning_rate': [0.05],\n",
    "    'num_leaves': [90,200],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'max_depth' : [5,6,7,8],\n",
    "    'random_state' : [501], \n",
    "    'colsample_bytree' : [0.5,0.7],\n",
    "    'subsample' : [0.5,0.7],\n",
    "    'min_split_gain' : [0.01],\n",
    "    'min_data_in_leaf':[10],\n",
    "#     'metric':['auc']\n",
    "    }\n",
    "clf = lightgbm.LGBMClassifier()\n",
    "\n",
    "if run_models:\n",
    "    random_search_model = (RandomizedSearchCV(clf, \n",
    "                               param_dict, \n",
    "                               verbose=1, \n",
    "                               cv=10, \n",
    "                               n_jobs = -1, \n",
    "                               n_iter=10,\n",
    "                               scoring='precision'))\n",
    "        # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    random_search_model.fit(X_negs, Y_negs)\n",
    "    model_dict[\"lgbm_second_level\"] = random_search_model.best_estimator_\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "    \n",
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "lgbm_second_level = model_dict[\"lgbm_second_level\"]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_negs = model_dict[\"lgbm\"].predict(dev_X) == 0\n",
    "dev_X_negs = dev_X[dev_negs]\n",
    "dev_Y_negs = dev_Y[dev_negs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(lgbm_second_level, dev_X_negs, dev_Y_negs, model_name=\"lgbm_second_level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the size of our encoded representations\n",
    "encoding_dim = 100 # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    " \n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(X.shape[1],))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(413, activation='sigmoid')(encoded)\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "# configure our model to use a per-pixel binary crossentropy loss, and the Adadelta optimizer:\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = X\n",
    "x_test = dev_X\n",
    "# normalize all values between 0 and 1 and we will flatten the 28x28 images into vectors of size 784.\n",
    "x_train = x_train.astype('float32') / np.float(x_train.shape[1] - 1)\n",
    "x_test = x_test.astype('float32') / np.float(x_test.shape[1] - 1)\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_autoencoder:\n",
    "    autoencoder.fit(x_train, x_train,\n",
    "    epochs=50,\n",
    "    batch_size=x_train.shape[1],\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, x_test))\n",
    "    # encode and decode some digits\n",
    "    # note that we take them from the *test* set\n",
    "    encoded_imgs = encoder.predict(x_test)\n",
    "    decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/binilg/lightgbm-with-randomsearchcv-and-feature-imp\n",
    "# Implementation: https://www.kaggle.com/mlisovyi/lightgbm-hyperparameter-optimisation-lb-0-761\n",
    "# Documentation: https://lightgbm.readthedocs.io/en/latest/Features.html\n",
    "# LightGBM Classifier: https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#\n",
    "\n",
    "encoded_train_imgs = encoder.predict(x_train)\n",
    "from optimize_ppv_npv_scorer_ import optimize_ppv_npv_scorer\n",
    "\n",
    "import lightgbm\n",
    "param_dict = {\n",
    "    'learning_rate': [0.05],\n",
    "    'num_leaves': [90,200],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'max_depth' : [5,6,7,8],\n",
    "    'random_state' : [501], \n",
    "    'colsample_bytree' : [0.5,0.7],\n",
    "    'subsample' : [0.5,0.7],\n",
    "    'min_split_gain' : [0.01],\n",
    "    'min_data_in_leaf':[10],\n",
    "#     'metric':['auc']\n",
    "    }\n",
    "#modelling\n",
    "\n",
    "if run_autoencoder:\n",
    "    clf = lightgbm.LGBMClassifier()\n",
    "\n",
    "    if run_models:\n",
    "        random_search_model = (RandomizedSearchCV(clf, \n",
    "                                   param_dict, \n",
    "                                   verbose=1, \n",
    "                                   cv=10, \n",
    "                                   n_jobs = -1, \n",
    "                                   n_iter=10,\n",
    "                                   scoring=optimize_ppv_npv_scorer))\n",
    "            # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "        random_search_model.fit(encoded_train_imgs, Y)\n",
    "        model_dict[\"lgbm_autoencoder\"] = random_search_model\n",
    "        model_dict[\"file_params\"] = file_param_dict\n",
    "        pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "\n",
    "    model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "    lgbm_autoencoder = model_dict[\"lgbm_autoencoder\"]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_autoencoder:\n",
    "    model_results(lgbm_autoencoder, encoded_train_imgs, Y, model_name=\"lgbm_autoencoder\")\n",
    "    model_results(lgbm_autoencoder, encoded_imgs, dev_Y, model_name=\"lgbm_autoencoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Model\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/05.12-gaussian-mixtures.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(2, random_state=random_state)\n",
    "labels = kmeans.fit(X).predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(labels == Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def plot_kmeans(kmeans, X, n_clusters=4, rseed=0, ax=None):\n",
    "    labels = kmeans.fit_predict(X)\n",
    "\n",
    "    # plot the input data\n",
    "    ax = ax or plt.gca()\n",
    "    ax.axis('equal')\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)\n",
    "\n",
    "    # plot the representation of the KMeans model\n",
    "    centers = kmeans.cluster_centers_\n",
    "    radii = [cdist(X[labels == i], [center]).max()\n",
    "             for i, center in enumerate(centers)]\n",
    "    for c, r in zip(centers, radii):\n",
    "        ax.add_patch(plt.Circle(c, r, fc='#CCCCCC', lw=3, alpha=0.5, zorder=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=random_state)\n",
    "plot_kmeans(kmeans, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working because determinant of covariance matrix is 0 due to multicollinearity\n",
    "# from sklearn.mixture import GaussianMixture as GMM\n",
    "# gmm = GMM(n_components=4).fit(X)\n",
    "# labels = gmm.predict(X)\n",
    "# plt.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_knn:\n",
    "    knn = KNeighborsClassifier(n_neighbors=30)\n",
    "    X_ = X.copy()[:, :2]\n",
    "    knn.fit(X_, Y)\n",
    "    \n",
    "    model_dict[\"knn\"] = knn.best_estimator_\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "    \n",
    "    model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "    knn = model_dict[\"knn\"]  \n",
    "    model_results(knn, dev_X.copy()[:, :2], dev_Y, model_name=\"knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Second Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_knn:\n",
    "    knn = KNeighborsClassifier(n_neighbors=30)\n",
    "    X_ = X_negs.copy()[:, :2]\n",
    "    knn.fit(X_, Y_negs)\n",
    "    \n",
    "    model_dict[\"knn\"] = knn.best_estimator_\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "    \n",
    "    model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "    knn = model_dict[\"knn\"]  \n",
    "    model_results(knn, dev_X_negs.copy()[:, :2], dev_Y_negs, model_name=\"knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_svc:\n",
    "    param_dict = {'kernel': ['rbf'],\n",
    "                  'C': [1, 10, 100]}\n",
    "\n",
    "    # param_dict = {}\n",
    "\n",
    "    clf = SVC(gamma='scale', probability=True)\n",
    "    # clf.fit(X_negs, Y_negs)\n",
    "    if run_models:\n",
    "        random_search_model = (RandomizedSearchCV(clf, \n",
    "                                   param_dict, \n",
    "                                   verbose=1, \n",
    "                                   cv=10, \n",
    "                                   n_jobs = -1, \n",
    "                                   n_iter=10,\n",
    "                                   scoring='roc_auc'))\n",
    "            # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "        random_search_model.fit(X, Y)\n",
    "        model_dict[\"svc\"] = random_search_model.best_estimator_\n",
    "        model_dict[\"file_params\"] = file_param_dict\n",
    "        pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "\n",
    "    model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "    svc = model_dict[\"svc\"] \n",
    "    model_results(svc, dev_X, dev_Y, model_name=\"svc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classifier (on negative predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {'kernel': ['rbf'],\n",
    "              'C': [1, 10, 100]}\n",
    "\n",
    "# param_dict = {}\n",
    "\n",
    "if run_svc_second_level:\n",
    "    clf = SVC(gamma='scale')\n",
    "    # clf.fit(X_negs, Y_negs)\n",
    "    if run_models:\n",
    "        random_search_model = (RandomizedSearchCV(clf, \n",
    "                                   param_dict, \n",
    "                                   verbose=1, \n",
    "                                   cv=10, \n",
    "                                   n_jobs = -1, \n",
    "                                   n_iter=10,\n",
    "                                   scoring='roc_auc'))\n",
    "            # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "        random_search_model.fit(X_negs, Y_negs)\n",
    "        model_dict[\"svc_second_level\"] = random_search_model.best_estimator_\n",
    "        model_dict[\"file_params\"] = file_param_dict\n",
    "        pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "\n",
    "    model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "    svc_second_level = model_dict[\"svc_second_level\"]\n",
    "    confusion_matrix(dev_Y_negs, svc_second_level.predict(dev_X_negs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpKXfQfXzKLf"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzQrUXTW6J6b",
    "outputId": "506c9dc8-7ddd-46a3-f171-91e9993e52c9"
   },
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqOn82eq0Hsy"
   },
   "outputs": [],
   "source": [
    "\n",
    "# build a classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "param_dict = {\"C\":np.logspace(-3,3,7), \n",
    "              \"penalty\":[\"l1\", \"l2\", \"elasticnet\"],\n",
    "              \"l1_ratio\":np.linspace(0,1,10),\n",
    "              \"solver\":[\"saga\"]\n",
    "              }# l1 lasso l2 ridge\n",
    "\n",
    "# run randomized search\n",
    "if run_logistic:\n",
    "    random_search_model = RandomizedSearchCV(clf, \n",
    "                                       param_distributions=param_dict,\n",
    "                                       n_iter=20, \n",
    "                                       scoring=optimize_ppv_npv_scorer, \n",
    "                                       cv=10, \n",
    "                                       n_jobs=-1)\n",
    "\n",
    "\n",
    "    # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    random_search_model.fit(X, Y)\n",
    "    model_dict[\"lr\"] = random_search_model.best_estimator_\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYoge1Lo5Xy5",
    "outputId": "608485a4-911d-4c7f-b89b-b2ae06d5b4c8"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "    lr = model_dict[\"lr\"]\n",
    "    model_results(lr, dev_X, dev_Y, model_name=\"lr\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure if useful\n",
    "# precision, recall, thresholds = metrics.precision_recall_curve(test_Y, lr.predict_proba(test_X)[:, 1], pos_label=1)\n",
    "\n",
    "# metrics.plot_precision_recall_curve(lr, test_X, test_Y, response_method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLlnRF_s062y"
   },
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ug-A0ZPMDgZ7"
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8k3ZsgjHNjC"
   },
   "outputs": [],
   "source": [
    "# build a classifier\n",
    "clf = XGBRFClassifier()\n",
    "\n",
    "# A parameter grid for XGBoost\n",
    "# https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost\n",
    "param_dict = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n",
    "# run randomized search\n",
    "if run_models:\n",
    "    random_search_model = RandomizedSearchCV(clf, \n",
    "                                   param_distributions=param_dict,\n",
    "                                   n_iter=1, \n",
    "                                   scoring=optimize_ppv_npv_scorer, \n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1)\n",
    "\n",
    "\n",
    "    # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    random_search_model.fit(X, Y)\n",
    "    model_dict[\"xgb\"] = random_search_model.best_estimator_\n",
    "    model_dict[\"file_params\"] = file_param_dict    \n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "xgb = model_dict[\"xgb\"]\n",
    "y_predict = lr.predict(test_X) \n",
    "\n",
    "# threshold is taken as 0.5, as proven here\n",
    "# y_predict_ = 1 * (lr.predict_proba(test_X)[:, 1]>0.5) # \n",
    "# np.mean(y_predict == y_predict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(xgb, dev_X, dev_Y, model_name=\"xgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "DqyeGmeqZXnZ",
    "outputId": "36dc804f-a60b-4a0c-87dd-d4a9bc62411f"
   },
   "outputs": [],
   "source": [
    "# #Feature importance for top 50 predictors\n",
    "# predictors = [x for x in df_X_combined_dummies_ordered.columns]\n",
    "# feat_imp = pd.Series(xgb.best_estimator_.feature_importances_, predictors).sort_values(ascending=False)\n",
    "# feat_imp = feat_imp[0:50]\n",
    "# plt.rcParams['figure.figsize'] = 20, 5\n",
    "# feat_imp.plot(kind='bar', title='Feature Importance')\n",
    "# plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3RElmg55sOb"
   },
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers, meta_classifier, use_probas=False, cv=2, \n",
    "# use_features_in_secondary=False, stratify=True, shuffle=True, verbose=0, store_train_meta_features=False, use_clones=True)\n",
    "\n",
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "# xgb = model_dict[\"xgb\"]\n",
    "lgbm = model_dict[\"lgbm\"]\n",
    "# knn = model_dict[\"knn\"]\n",
    "\n",
    "try:\n",
    "    knn = model_dict[\"knn\"]\n",
    "except:\n",
    "    knn = None\n",
    "\n",
    "try:\n",
    "    svc = model_dict[\"svc\"]\n",
    "except:\n",
    "    svc = None\n",
    "\n",
    "if run_models:\n",
    "    stack_gen_model = (StackingCVClassifier(classifiers=[xgb,\n",
    "                                                         lgbm], \n",
    "                                            meta_classifier=xgb,\n",
    "                                            use_features_in_secondary=False,\n",
    "                                            use_probas=True,\n",
    "                                           random_state=random_state))\n",
    "\n",
    "    stack_gen_model.fit(X, Y)\n",
    "    model_dict[\"stacking\"] = stack_gen_model\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "    \n",
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "stacking = model_dict[\"stacking\"]\n",
    "y_predict = stacking.predict(test_X) \n",
    "y_score = stacking.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute ROC curve and ROC area for each class\n",
    "# n_classes = 2\n",
    "# fpr = dict()\n",
    "# tpr = dict()\n",
    "# roc_auc = dict()\n",
    "\n",
    "\n",
    "# fpr, tpr, _ = roc_curve(test_Y, y_score[:, 1])\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# roc_auc\n",
    "\n",
    "# # # Compute micro-average ROC curve and ROC area\n",
    "# # fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_Y.ravel(), y_score.ravel())\n",
    "# # roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# # plt.figure()\n",
    "# # lw = 2\n",
    "# # plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "# #          lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "# # plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "# # plt.xlim([0.0, 1.0])\n",
    "# # plt.ylim([0.0, 1.05])\n",
    "# # plt.xlabel('False Positive Rate')\n",
    "# # plt.ylabel('True Positive Rate')\n",
    "# # plt.title('Receiver operating characteristic example')\n",
    "# # plt.legend(loc=\"lower right\")\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(stacking, test_X, test_Y, model_name=\"stacking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Efv12Vc6ijNT"
   },
   "outputs": [],
   "source": [
    "if run_models:\n",
    "    vc_clf = (VotingClassifier(estimators=[(\"xbg\", model_dict[\"xgb\"]), \n",
    "                                           (\"lightgbm\", model_dict[\"lgbm\"]),\n",
    "                                          (\"stacking\", model_dict[\"stacking\"])],\n",
    "                                           voting=\"soft\",\n",
    "                                           flatten_transform=False))\n",
    "\n",
    "    vc_fit = vc_clf.fit(dev_X, dev_Y)\n",
    "    model_dict[\"voting_clf\"] = vc_fit\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "\n",
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "voting_clf = model_dict[\"voting_clf\"]\n",
    "y_predict = voting_clf.predict(test_X) \n",
    "y_score = voting_clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(voting_clf, test_X, test_Y, model_name=\"voting_clf\")\n",
    "# find_roc_auc(vc_fit, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"ppv and npv on Test:\")\n",
    "for model in model_dict.keys():\n",
    "    if model not in [\"knn\", \"file_params\", \"lgbm_autoencoder\", \"svc_second_level\", \"lgbm_second_level\"]:\n",
    "        y_predict_proba = model_dict[model].predict_proba(test_X)[:, 1]\n",
    "        pv = ppv_npv_opt_th(test_Y, y_predict_proba)\n",
    "        print(\"{}: {}ppv = {}, npv = {} @ threshold = {}\".format(model, \" \"*(13 - len(model)), round(pv[0], 4), round(pv[1], 4), round(pv[2], 4)))\n",
    "    \n",
    "print(\"=========================================\")\n",
    "print(\"ROC_AUC on Test\")\n",
    "for model in model_dict.keys():\n",
    "    if model not in [\"knn\", \"file_params\", \"lgbm_autoencoder\", \"svc_second_level\", \"lgbm_second_level\"]:\n",
    "        y_predict = model_dict[model].predict(test_X)\n",
    "        print(\"{}:{}{}\".format(model, \" \"*(13 - len(model)), find_roc_auc(model_dict.get(model), test_X, test_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ppv and npv on Dev:\")\n",
    "for model in model_dict.keys():\n",
    "    if model not in [\"knn\", \"file_params\", \"lgbm_autoencoder\", \"svc_second_level\", \"lgbm_second_level\"]:\n",
    "        y_predict_proba = model_dict[model].predict_proba(dev_X)[:, 1]\n",
    "        pv = ppv_npv_opt_th(dev_Y, y_predict_proba)\n",
    "        print(\"{}: {}ppv = {}, npv = {} @ threshold = {}\".format(model, \" \"*(13 - len(model)), round(pv[0], 4), round(pv[1], 4), round(pv[2], 4)))\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"ROC_AUC on Dev\")\n",
    "for model in model_dict.keys():\n",
    "    if model not in [\"knn\", \"file_params\", \"lgbm_autoencoder\", \"svc_second_level\", \"lgbm_second_level\"]:\n",
    "        print(\"{}:{}{}\".format(model, \" \"*(13 - len(model)), find_roc_auc(model_dict.get(model), dev_X, dev_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ppv and npv on Train:\")\n",
    "for model in model_dict.keys():\n",
    "    if model not in [\"knn\", \"file_params\", \"lgbm_autoencoder\", \"svc_second_level\", \"lgbm_second_level\"]:\n",
    "        y_predict_proba = model_dict[model].predict_proba(X)[:, 1]\n",
    "        pv = ppv_npv_opt_th(Y, y_predict_proba)\n",
    "        print(\"{}: {}ppv = {}, npv = {} @ threshold = {}\".format(model, \" \"*(13 - len(model)), round(pv[0], 4), round(pv[1], 4), round(pv[2], 4)))\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"ROC_AUC on Training\")\n",
    "for model in model_dict.keys():\n",
    "    if model not in [\"knn\", \"file_params\", \"lgbm_autoencoder\", \"svc_second_level\", \"lgbm_second_level\"]:\n",
    "        print(\"{}:{}{}\".format(model, \" \"*(13 - len(model)), find_roc_auc(model_dict.get(model), X, Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Index\" in df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = np.array(df_test)\n",
    "model = \"lgbm\"\n",
    "y_predict = model_dict[model].predict(test_X)\n",
    "array2 = y_predict.reshape(y_predict.shape[0],1)\n",
    "array3 = np.hstack((array1, array2))\n",
    "df_pred = pd.DataFrame(array3, columns = list(df_test.columns) + [\"predictions\"])\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false negatives\n",
    "\n",
    "df_fn = df_pred[(df_pred.predictions == 0) & (df_pred.cwa_determination == 1)]\n",
    "df_fn.head()\n",
    "\n",
    "# true negatives\n",
    "\n",
    "df_tn = df_pred[(df_pred.predictions == 0) & (df_pred.cwa_determination == 0)]\n",
    "df_tn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cols = ['cwa1', 'cwa2', 'cwa3', 'cwa4', 'cwa5', 'cwa6' , 'cwa7', 'cwa8', 'cwa9', 'cwa_determination','longitude', 'latitude', 'Index','da_number',\n",
    "       'jurisdiction_type', 'potential_wetland', \"predictions\"]\n",
    "df_fn[imp_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fn.drop('geometry', axis=1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(df_fn.columns[50:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_tn.closest_wb_distance_m.mean())\n",
    "# print(df_fn.closest_wb_distance_m.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## which states have the most false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fn_tn = pd.concat([pd.DataFrame(df_fn.district).value_counts(), pd.DataFrame(df_tn.district).value_counts()], axis=1)\n",
    "df_fn_tn.columns = [\"FN\", \"TN\"]\n",
    "df_fn_tn[\"1-npv\"] = df_fn_tn.apply(lambda x: round(x.FN/(x.FN + x.TN), 2), axis=1)#.sort_values(ascending=False)\n",
    "df_fn_tn.sort_values(by=\"1-npv\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_tn.district).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_value(feature=\"closest_wb_elevation\"):\n",
    "    import scipy\n",
    "    try:\n",
    "        return (scipy.stats.ttest_ind(np.array(df_tn[feature], dtype=float), \n",
    "                           np.array(df_fn[feature], dtype=float), \n",
    "                           nan_policy='omit'))[1]\n",
    "    except Exception as e:\n",
    "#         print(e)\n",
    "        pass\n",
    "p_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df_fn.columns:\n",
    "    try:\n",
    "        if p_value(feature) < 0.0001:\n",
    "            if feature in imp_num_feature:\n",
    "                delta = (np.nanmean(np.array(df_tn[feature], dtype=float)) \n",
    "                         - np.nanmean(np.array(df_fn[feature], dtype=float)))\n",
    "                print (feature, \":\", delta)\n",
    "    except Exception as e:\n",
    "#         print(feature, \"XXXX\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df_fn.columns:\n",
    "    try:\n",
    "        if p_value(feature) < 0.001:\n",
    "            if feature in imp_num_feature:\n",
    "                delta = (np.nanmean(np.array(df_tn[feature], dtype=float)) \n",
    "                         - np.nanmean(np.array(df_fn[feature], dtype=float)))\n",
    "                print (feature, \":\", delta)\n",
    "    except Exception as e:\n",
    "#         print(feature, \"XXXX\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df_fn.columns:\n",
    "    try:\n",
    "        if p_value(feature) < 0.01:\n",
    "            if feature in imp_num_feature:\n",
    "                delta = (np.nanmean(np.array(df_tn[feature], dtype=float)) \n",
    "                         - np.nanmean(np.array(df_fn[feature], dtype=float)))\n",
    "                print (feature, \":\", delta)\n",
    "    except Exception as e:\n",
    "#         print(feature, \"XXXX\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df_fn.columns:\n",
    "    try:\n",
    "        if p_value(feature) < 0.1:\n",
    "            if feature in imp_num_feature:\n",
    "                delta = (np.nanmean(np.array(df_tn[feature], dtype=float)) \n",
    "                         - np.nanmean(np.array(df_fn[feature], dtype=float)))\n",
    "                print (feature, \":\", delta)\n",
    "    except Exception as e:\n",
    "#         print(feature, \"XXXX\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"lgbm\"\n",
    "model_results(model_dict[model], test_X, test_Y, model)\n",
    "confusion_matrix(test_Y, model_dict[model].predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_thresholding(threshold=0.5):\n",
    "    y_threshold = (model_dict[\"lgbm\"].predict_proba(test_X)[:, 1] > threshold) * 1\n",
    "    np.mean(y_threshold == test_Y)\n",
    "    print(classification_report(test_Y, y_threshold))\n",
    "    print(\"confusion matrix:\")\n",
    "    print(confusion_matrix(test_Y, y_threshold))\n",
    "do_thresholding()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_thresholding(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_thresholding(0.6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_thresholding(0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_thresholding(0.4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_thresholding(0.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_thresholding(0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_thresholding(0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_thresholding(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_pred[~df_pred.county.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df_pred.county.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred[\"count_1_pred_by_county\"] = df_pred.groupby([\"county\"])[\"predictions\"].transform(np.mean)#apply(lambda x: np.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.groupby_agg(\n",
    "#     by='item',\n",
    "#     agg='mean',\n",
    "#     agg_column_name='MRP',\n",
    "#     new_column_name='Avg_MRP'\n",
    "# )\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean(x):\n",
    "    return np.mean(x)\n",
    "\n",
    "df_pred[\"percent_1_actual\"] = df_pred.groupby(\"county\")[\"cwa_determination\"].transform(find_mean)\n",
    "df_pred[\"percent_1_predictions\"] = df_pred.groupby(\"county\")[\"predictions\"].transform(find_mean)\n",
    "df_pred[\"pred_over_actual\"] = df_pred.percent_1_predictions / (df_pred.percent_1_actual + 0.00000001)\n",
    "\n",
    "ratio_list = []\n",
    "for groupby in df_pred.groupby(\"county\"):\n",
    "    if 10000 > np.mean(np.array(groupby[1].pred_over_actual)):# > 1:\n",
    "        ratio_list.append(np.mean(np.array(groupby[1].pred_over_actual)))\n",
    "#         print(groupby[0], np.mean(np.array(groupby[1].pred_over_actual)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ratio_list, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in which counties are false positives more:\n",
    "\n",
    "for groupby in df_pred.groupby(\"county\"):\n",
    "    if 10000 > np.mean(np.array(groupby[1].pred_over_actual)) > 1:\n",
    "        print(groupby[0], np.mean(np.array(groupby[1].pred_over_actual)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in which counties are false negatives more:\n",
    "count = 0\n",
    "for groupby in df_pred.groupby(\"county\"):\n",
    "    if np.mean(np.array(groupby[1].pred_over_actual)) < 0.5:\n",
    "        count += 1\n",
    "#         print(groupby[0], np.mean(np.array(groupby[1].pred_over_actual)))\n",
    "print(count)    \n",
    "# are there 463 counties where there is no prediction of 1? out of 689 total counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_pred.groupby(\"county\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_pred.county.unique()) # 689\n",
    "len(df_pred.district.unique()) # 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look by district. These are the districts where there are no 1's being predicted\n",
    "\n",
    "def find_mean(x):\n",
    "    return np.mean(x)\n",
    "\n",
    "df_pred[\"percent_1_actual_by_district\"] = df_pred.groupby(\"district\")[\"cwa_determination\"].transform(find_mean)\n",
    "df_pred[\"percent_1_predictions_by_district\"] = df_pred.groupby(\"district\")[\"predictions\"].transform(find_mean)\n",
    "df_pred[\"pred_over_actual_by_district\"] = df_pred.percent_1_predictions / (df_pred.percent_1_actual + 0.00000001)\n",
    "\n",
    "ratio_list = []\n",
    "print(\"District           pred/act    tot_cnt    actual_1's,  pred_1's\")\n",
    "for groupby in df_pred.groupby(\"district\"):\n",
    "#     if not np.mean(np.array(groupby[1].pred_over_actual_district)):# > 1:\n",
    "    ratio_list.append(np.mean(np.array(groupby[1].pred_over_actual)))\n",
    "    (print(groupby[0], \" \" * (20 - len(groupby[0])), round(np.mean(np.array(groupby[1].pred_over_actual)), 2), \n",
    "           \" \" * (10 - len(str(round(np.mean(np.array(groupby[1].pred_over_actual)), 2)))), groupby[1].cwa_determination.shape[0], \n",
    "           \" \" * (10 - len(str(np.sum(groupby[1].cwa_determination)))), np.sum(groupby[1].cwa_determination),\n",
    "           \" \" * (10 - len(str(np.sum(groupby[1].predictions)))), np.sum(groupby[1].predictions))\n",
    "\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ratio_list, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.district == \"Albuquerque\"][[\"cwa_determination\", \"district\", \"predictions\", \"percent_1_actual\", \n",
    "                                           \"percent_1_predictions_by_district\", \"percent_1_actual_by_district\", \"percent_1_predictions_by_district\", \"pred_over_actual_by_district\"]].head(1)    #.iloc[:, 494:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.district == \"Fort Worth\"][[\"cwa_determination\", \"district\", \"predictions\", \"percent_1_actual\", \n",
    "                                           \"percent_1_predictions_by_district\", \"percent_1_actual_by_district\", \"percent_1_predictions_by_district\", \"pred_over_actual_by_district\"]].head(1)    #.iloc[:, 494:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.district == \"Huntington\"][[\"cwa_determination\", \"district\", \"predictions\", \"percent_1_actual\", \n",
    "                                           \"percent_1_predictions_by_district\", \"percent_1_actual_by_district\", \"percent_1_predictions_by_district\", \"pred_over_actual_by_district\"]].head(1)    #.iloc[:, 494:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.district == \"Louisville\"][[\"cwa_determination\", \"district\", \"predictions\", \"percent_1_actual\", \n",
    "                                           \"percent_1_predictions_by_district\", \"percent_1_actual_by_district\", \"percent_1_predictions_by_district\", \"pred_over_actual_by_district\"]].head(1)    #.iloc[:, 494:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.district == \"Nashville\"][[\"cwa_determination\", \"district\", \"predictions\", \"percent_1_actual\", \n",
    "                                           \"percent_1_predictions_by_district\", \"percent_1_actual_by_district\", \"percent_1_predictions_by_district\", \"pred_over_actual_by_district\"]].head(1)    #.iloc[:, 494:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.district == \"St. Louis\"][[\"cwa_determination\", \"district\", \"predictions\", \"percent_1_actual\", \n",
    "                                           \"percent_1_predictions_by_district\", \"percent_1_actual_by_district\", \"percent_1_predictions_by_district\", \"pred_over_actual_by_district\"]].head(1)    #.iloc[:, 494:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.district == \"Tulsa\"][[\"cwa_determination\", \"district\", \"predictions\", \"percent_1_actual\", \n",
    "                                           \"percent_1_predictions_by_district\", \"percent_1_actual_by_district\", \"percent_1_predictions_by_district\", \"pred_over_actual_by_district\"]].head(1)    #.iloc[:, 494:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.district == \"Vicksburg\"][[\"cwa_determination\", \"district\", \"predictions\", \"percent_1_actual\", \n",
    "                                           \"percent_1_predictions_by_district\", \"percent_1_actual_by_district\", \"percent_1_predictions_by_district\", \"pred_over_actual_by_district\"]].head(1)    #.iloc[:, 494:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.district == \"Walla Walla\"][[\"cwa_determination\", \"district\", \"predictions\", \"percent_1_actual\", \n",
    "                                           \"percent_1_predictions_by_district\", \"percent_1_actual_by_district\", \"percent_1_predictions_by_district\", \"pred_over_actual_by_district\"]].head(1)    #.iloc[:, 494:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred.groupby(\"county\")[\"predictions\"].apply(find_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean(df):\n",
    "    try:\n",
    "        result = df[~df.isna()].mean()\n",
    "        if not np.isnan(result):\n",
    "            return result\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "    \n",
    "def find_sum(df):\n",
    "    return np.sum(np.array(df))\n",
    "\n",
    "df_pred.groupby([\"county\"])[\"predictions\"].transform(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.county == \"Horry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotly maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fn_ = df_fn.copy()\n",
    "df_tn_ = df_tn.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false negatives\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df_fn_['longitude'], df_fn_['latitude'])]\n",
    "gdf = GeoDataFrame(df_fn_, geometry=geometry)   \n",
    "\n",
    "#this is a simple map that goes with geopandas\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "north_america = world[world.continent == \"North America\"]\n",
    "gdf.plot(ax=north_america.plot(figsize=(20, 12)), marker='o', color='red', markersize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true negatives\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df_tn_['longitude'], df_tn_['latitude'])]\n",
    "gdf = GeoDataFrame(df_tn_, geometry=geometry)   \n",
    "\n",
    "#this is a simple map that goes with geopandas\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "north_america = world[world.continent == \"North America\"]\n",
    "gdf.plot(ax=north_america.plot(figsize=(20, 12)), marker='o', color='red', markersize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not false negatives\n",
    "df_not_fn = df_pred[~((df_pred.predictions == 0) & (df_pred.cwa_determination == 1))]\n",
    "\n",
    "df_not_fn_ = df_not_fn.copy()\n",
    "geometry = [Point(xy) for xy in zip(df_not_fn_['longitude'], df_not_fn_['latitude'])]\n",
    "gdf = GeoDataFrame(df_not_fn_, geometry=geometry)   \n",
    "\n",
    "gdf.plot(ax=north_america.plot(figsize=(20, 12)), marker='o', color='red', markersize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false positives\n",
    "df_fp = df_pred[(df_pred.predictions == 1) & (df_pred.cwa_determination == 0)]\n",
    "df_fp_ = df_fp.copy()\n",
    "\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df_fp_['longitude'], df_fp_['latitude'])]\n",
    "gdf = GeoDataFrame(df_fp_, geometry=geometry)   \n",
    "\n",
    "gdf.plot(ax=north_america.plot(figsize=(20, 12)), marker='o', color='red', markersize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All good predictions\n",
    "df_good_preds = df_pred[((df_pred.predictions == 0) & (df_pred.cwa_determination == 0)) | ((df_pred.predictions == 1) & (df_pred.cwa_determination == 1))]\n",
    "\n",
    "df_good_preds_ = df_good_preds.copy()\n",
    "geometry = [Point(xy) for xy in zip(df_good_preds_['longitude'], df_good_preds_['latitude'])]\n",
    "gdf = GeoDataFrame(df_good_preds_, geometry=geometry)   \n",
    "\n",
    "gdf.plot(ax=north_america.plot(figsize=(20, 12)), marker='o', color='red', markersize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df_pred['longitude'], df_pred['latitude'])]\n",
    "gdf = GeoDataFrame(df_pred, geometry=geometry)   \n",
    "\n",
    "gdf.plot(ax=north_america.plot(figsize=(20, 12)), marker='o', color='red', markersize=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySEfwFTbEOsU"
   },
   "source": [
    "# Break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gximuif9tUZe"
   },
   "outputs": [],
   "source": [
    "df_fn[df_fn.state == '12'][\"hydclprs\"]#['da_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_fn.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJxn_V1lcnUd"
   },
   "outputs": [],
   "source": [
    "model_dict[\"file_params\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2021.03.19_WOTUS_restart_v6.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
