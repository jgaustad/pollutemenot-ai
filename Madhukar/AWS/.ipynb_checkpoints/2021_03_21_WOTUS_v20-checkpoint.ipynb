{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gh39s2KK_dGM"
   },
   "outputs": [],
   "source": [
    "# - v1: works till the categorical pipeline where it errors out for unknown variables\n",
    "# - v2: fully functional\n",
    "# - v3: baseline run (on the old dataset)\n",
    "# - v4: baseline run (on the full 2021.03.17_full_dataset)\n",
    "# - v5: baseline run (on 2021.03.19_full_dataset with all SSURGO variables)\n",
    "# - v6: aoc_roc (on 2021.03.19_full_dataset with all SSURGO variables). Mute the Stacking as it is not possible with RandomizedSearchCV. Have to have a dev split.\n",
    "# - v7: model v7 random state 123 on train/test, model v7.1 random_state 431 on train/dev/test\n",
    "# - v8g: Golden model\n",
    "\n",
    "# - ROC_AUC with lat, lon (baseline)\n",
    "# ====================\n",
    "# lr:           0.64103\n",
    "# xgb:          0.82366\n",
    "# voting_clf:   0.83027\n",
    "# lgbm:         0.86395\n",
    "# stacking:     0.85923\n",
    "\n",
    "\n",
    "# - v9: without lat, lon\n",
    "\n",
    "# - ROC_AUC without lat, lon\n",
    "# =======================\n",
    "# lr:           0.64211\n",
    "# xgb:          0.8031\n",
    "# voting_clf:   0.83105\n",
    "# lgbm:         0.85952\n",
    "# stacking:     0.85427\n",
    "\n",
    "# - v9.1: without lat, lon, potential_wetland\n",
    "\n",
    "# - ROC_AUC without lat, lon, potential_wetland\n",
    "# ===============\n",
    "# lr:           0.63992\n",
    "# xgb:          0.79093\n",
    "# voting_clf:   0.82987\n",
    "# lgbm:         0.85143\n",
    "# stacking:     0.84328\n",
    "\n",
    "# - v9.2: without lat, lon, potential_wetland, district\n",
    "\n",
    "# - ROC_AUC without lat, lon, potential_wetland, district\n",
    "# ===============\n",
    "# lr:           0.64208\n",
    "# xgb:          0.77907\n",
    "# voting_clf:   0.79829\n",
    "# lgbm:         0.82675\n",
    "# stacking:     0.82185\n",
    "\n",
    "# - v9.3: without lat, lon, potential_wetland, district and flodfreqdc and drclassdcd as ordinal\n",
    "\n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.6382\n",
    "# xgb:          0.73089\n",
    "# voting_clf:   0.79126\n",
    "# lgbm:         0.82512\n",
    "# stacking:     0.8195\n",
    "\n",
    "# - v9.4: without lat, lon, potential_wetland, district, county \n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.6395\n",
    "# xgb:          0.74096\n",
    "# voting_clf:   0.7911\n",
    "# lgbm:         0.82448\n",
    "# stacking:     0.82343\n",
    "\n",
    "# - v9.5: without lat, lon, potential_wetland, district, county, mukey\n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.65309\n",
    "# xgb:          0.75117\n",
    "# voting_clf:   0.77845\n",
    "# lgbm:         0.80626\n",
    "# stacking:     0.80424\n",
    "\n",
    "# - v9.5: without lat, lon, potential_wetland, district, county, mukey, and filtering out bad latitude\n",
    "# THIS IS SUSPECT. CANT REPEAT IT.\n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.63894\n",
    "# xgb:          0.74922\n",
    "# voting_clf:   0.79839\n",
    "# lgbm:         0.86986\n",
    "# stacking:     0.86281\n",
    "\n",
    "# - v9,5_r2: supposed to be repeat of v9.5 but unsuccessful (probably bcoz of wrong cat features)\n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.64148\n",
    "# xgb:          0.7066\n",
    "# lgbm:         0.79702\n",
    "# stacking:     0.78626\n",
    "# voting_clf:   0.7632\n",
    "\n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.62669\n",
    "# xgb:          0.71814\n",
    "# lgbm:         0.8006\n",
    "# stacking:     0.80005\n",
    "# voting_clf:   0.7683\n",
    "\n",
    "# - v9.6: baseline and filtering out bad latitude\n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.6306\n",
    "# xgb:          0.79659\n",
    "# voting_clf:   0.82816\n",
    "# lgbm:         0.85251\n",
    "# stacking:     0.84547\n",
    "\n",
    "# - v9.6_r2: baseline and filtering out bad latitude\n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.6302\n",
    "# xgb:          0.81153\n",
    "# voting_clf:   0.83019\n",
    "# lgbm:         0.85353\n",
    "# stacking:     0.85285\n",
    "\n",
    "\n",
    "# - ROC_AUC with lat, lon (baseline)\n",
    "# ====================\n",
    "# lr:           0.64103\n",
    "# xgb:          0.82366\n",
    "# voting_clf:   0.83027\n",
    "# lgbm:         0.86395\n",
    "# stacking:     0.85923\n",
    "\n",
    "# - v9.4: without lat, lon, potential_wetland, district, county \n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.6395\n",
    "# xgb:          0.74096\n",
    "# voting_clf:   0.7911\n",
    "# lgbm:         0.82448\n",
    "# stacking:     0.82343\n",
    "\n",
    "# - v10: baseline (with huc6, nearest wb/fl parameters added)\n",
    "\n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.64444\n",
    "# xgb:          0.80494\n",
    "# voting_clf:   0.82554\n",
    "# lgbm:         0.85336\n",
    "# stacking:     0.8514\n",
    "\n",
    "# - v10.1: baseline (with huc4, nearest wb/fl parameters added)\n",
    "# -ROC_AUC on Test\n",
    "# ===============\n",
    "\n",
    "# lr:           0.64381\n",
    "# voting_clf:   0.82879\n",
    "# xgb:          0.8032\n",
    "# lgbm:         0.85318\n",
    "# stacking:     0.8495\n",
    "\n",
    "# - ROC_AUC on Test: supposed to be repeat of v10.1, but not sure why results are not reproducible\n",
    "# ===============\n",
    "\n",
    "# lr:           0.64381\n",
    "# voting_clf:   0.77483\n",
    "# xgb:          0.75691\n",
    "# lgbm:         0.79563\n",
    "# stacking:     0.78974\n",
    "\n",
    "# - v10.1_rerun: rerunning again and tested by reading back the model file. reproducible results. \n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.64384\n",
    "# voting_clf:   0.8299\n",
    "# xgb:          0.78993\n",
    "# lgbm:         0.85403\n",
    "# stacking:     0.8468\n",
    "\n",
    "\n",
    "# - v10.2: v10.1 with log transformed closest distances (slight improvement seen)\n",
    "# - ROC_AUC on Test: can not reproduce these results the next day. So rerunning again below:\n",
    "# ===============\n",
    "# lr:           0.64219\n",
    "# voting_clf:   0.82924\n",
    "# xgb:          0.7662\n",
    "# lgbm:         0.85495\n",
    "# stacking:     0.85232\n",
    "\n",
    "# - v10.2_rerun:\n",
    "# - ROC_AUC on Test\n",
    "# ===============\n",
    "# lr:           0.64251\n",
    "# voting_clf:   0.82815\n",
    "# xgb:          0.74756\n",
    "# lgbm:         0.854\n",
    "# stacking:     0.84738\n",
    "\n",
    "# - v12: implemented the ppv/npv version\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7711, npv = 0.7734 @ threshold = 0.4949\n",
    "# lr:            ppv = 0.6522, npv = 0.6365 @ threshold = 0.5152\n",
    "# xgb:           ppv = 0.7448, npv = 0.7208 @ threshold = 0.5152\n",
    "# stacking:      ppv = 0.7691, npv = 0.7698 @ threshold = 0.5354\n",
    "# voting_clf:    ppv = 0.7598, npv = 0.7562 @ threshold = 0.4949\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lr:           0.62682\n",
    "# voting_clf:   0.82891\n",
    "# xgb:          0.7816\n",
    "# lgbm:         0.84274\n",
    "# stacking:     0.83437\n",
    "\n",
    "    \n",
    "    \n",
    "# v13: data stratification by district\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7893, npv = 0.7873 @ threshold = 0.5253\n",
    "# lr:            ppv = 0.7053, npv = 0.6413 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7731, npv = 0.7593 @ threshold = 0.4545\n",
    "# stacking:      ppv = 0.7992, npv = 0.7788 @ threshold = 0.5253\n",
    "# voting_clf:    ppv = 0.7757, npv = 0.771 @ threshold = 0.5152\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "\n",
    "# lr:           0.63472\n",
    "# voting_clf:   0.84121\n",
    "# xgb:          0.81637\n",
    "# lgbm:         0.86547\n",
    "# stacking:     0.86017\n",
    "\n",
    "# v13.1: with use_features_in_secondary=False in Stacking (this is slightly better)\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7885, npv = 0.7862 @ threshold = 0.5253\n",
    "# lr:            ppv = 0.7053, npv = 0.6413 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7619, npv = 0.7509 @ threshold = 0.4646\n",
    "# stacking:      ppv = 0.7752, npv = 0.7748 @ threshold = 0.5657 (notice the threshold has increased slightly, ppv (and npv?) decreased)\n",
    "# voting_clf:    ppv = 0.7806, npv = 0.7711 @ threshold = 0.5051\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "\n",
    "# lr:           0.63471\n",
    "# voting_clf:   0.84039\n",
    "# xgb:          0.80691\n",
    "# lgbm:         0.86276\n",
    "# stacking:     0.86068\n",
    "\n",
    "# v13.2:\n",
    "# Using 475 principal components\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.754, npv = 0.7611 @ threshold = 0.4949\n",
    "# lr:            ppv = 0.7241, npv = 0.6409 @ threshold = 0.5455\n",
    "# xgb:           ppv = 0.712, npv = 0.7091 @ threshold = 0.4343\n",
    "# stacking:      ppv = 0.7581, npv = 0.7472 @ threshold = 0.5152\n",
    "# voting_clf:    ppv = 0.7472, npv = 0.7506 @ threshold = 0.4848\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.82615\n",
    "# lr:           0.63732\n",
    "# xgb:          0.73877\n",
    "# stacking:     0.81755\n",
    "# voting_clf:   0.81281\n",
    "\n",
    "# v15: knn imputing of variables at nan_th = 0.2\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7746, npv = 0.7718 @ threshold = 0.5556\n",
    "# lr:            ppv = 0.7053, npv = 0.6413 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7313, npv = 0.7284 @ threshold = 0.4848\n",
    "# stacking:      ppv = 0.7785, npv = 0.7732 @ threshold = 0.5253\n",
    "# voting_clf:    ppv = 0.7531, npv = 0.7545 @ threshold = 0.5152\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lr:           0.62915\n",
    "# voting_clf:   0.81977\n",
    "# xgb:          0.77361\n",
    "# lgbm:         0.8542\n",
    "# stacking:     0.85236\n",
    "\n",
    "\n",
    "# v17: with svc and knn\n",
    "\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7787, npv = 0.77 @ threshold = 0.5455\n",
    "# lr:            ppv = 0.7053, npv = 0.6413 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7273, npv = 0.7205 @ threshold = 0.5051\n",
    "# stacking:      ppv = 0.784, npv = 0.766 @ threshold = 0.5657\n",
    "# voting_clf:    ppv = 0.7534, npv = 0.7585 @ threshold = 0.5051\n",
    "# lgbm_second_level: ppv = 0.8, npv = 0.6308 @ threshold = 0.5657\n",
    "# svc:           ppv = 0.6718, npv = 0.6441 @ threshold = 0.5859\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.85012\n",
    "# lr:           0.62915\n",
    "# xgb:          0.76222\n",
    "# stacking:     0.84442\n",
    "# voting_clf:   0.82\n",
    "# lgbm_second_level:0.50845\n",
    "# svc:          0.67335\n",
    "\n",
    "# v18: Removed Alaska because no SSURGO data. Also, the saved model works!\n",
    "\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7828, npv = 0.7813 @ threshold = 0.5253\n",
    "# lr:            ppv = 0.7053, npv = 0.6359 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7216, npv = 0.7305 @ threshold = 0.3636\n",
    "# stacking:      ppv = 0.758, npv = 0.7954 @ threshold = 0.4242\n",
    "# voting_clf:    ppv = 0.7854, npv = 0.765 @ threshold = 0.5152\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.8642\n",
    "# lr:           0.63127\n",
    "# xgb:          0.77811\n",
    "# stacking:     0.85698\n",
    "# voting_clf:   0.83492\n",
    "\n",
    "# v21: 1000m and 2500m data\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7762, npv = 0.7737 @ threshold = 0.5556\n",
    "# lgbm_groups:   ppv = 0.649, npv = 0.6461 @ threshold = 0.1111\n",
    "# lr:            ppv = 1.0, npv = 0.6252 @ threshold = 0.6364\n",
    "# xgb:           ppv = 0.7304, npv = 0.7347 @ threshold = 0.6061\n",
    "# stacking:      ppv = 0.7869, npv = 0.7513 @ threshold = 0.5354\n",
    "# voting_clf:    ppv = 0.7614, npv = 0.7614 @ threshold = 0.5455\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.85726\n",
    "# lgbm_groups:  0.68616\n",
    "# lr:           0.62552\n",
    "# xgb:          0.79837\n",
    "# stacking:     0.84893\n",
    "# voting_clf:   0.83079\n",
    "\n",
    "# v22: 200m and 1000m... clearly this is the best. Next thing to try is capture the seasonality of the nearby wbs and fls\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7881, npv = 0.7837 @ threshold = 0.5354\n",
    "# lgbm_groups:   ppv = 0.6699, npv = 0.6475 @ threshold = 0.1111\n",
    "# lr:            ppv = 0.7473, npv = 0.6368 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7412, npv = 0.7333 @ threshold = 0.4343\n",
    "# stacking:      ppv = 0.7808, npv = 0.7836 @ threshold = 0.4545\n",
    "# voting_clf:    ppv = 0.7759, npv = 0.7733 @ threshold = 0.5051\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.8641\n",
    "# lgbm_groups:  0.66912\n",
    "# lr:           0.64632\n",
    "# xgb:          0.78758\n",
    "# stacking:     0.85629\n",
    "# voting_clf:   0.84187\n",
    "\n",
    "# v22.1: remove Charleston that contributed the most to fn's in v22\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.8063, npv = 0.805 @ threshold = 0.5657\n",
    "# lgbm_groups:   ppv = 0.6667, npv = 0.6606 @ threshold = 0.0909\n",
    "# lr:            ppv = 0.7471, npv = 0.6427 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7738, npv = 0.7726 @ threshold = 0.4949\n",
    "# stacking:      ppv = 0.7994, npv = 0.7991 @ threshold = 0.5758\n",
    "# voting_clf:    ppv = 0.7906, npv = 0.7922 @ threshold = 0.5556\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.88234\n",
    "# lgbm_groups:  0.69274\n",
    "# lr:           0.65399\n",
    "# xgb:          0.83822\n",
    "# stacking:     0.8749\n",
    "# voting_clf:   0.86033    \n",
    "\n",
    "# \"east_coast = [\"Galveston\", \"New Orleans\", \n",
    "# \"Mobile\", \"Jacksonville\", \"Savannah\", \"Charleston\", 'Wilmington', \"Norfolk\", \"Baltimore\", \"Philadelphia\"]\n",
    "# clear but small improvement but the problem is Charleston was filtered out\n",
    "\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.8074, npv = 0.8068 @ threshold = 0.5657\n",
    "# lgbm_groups:   ppv = 0.6823, npv = 0.6554 @ threshold = 0.101\n",
    "# lr:            ppv = 0.7471, npv = 0.6427 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7807, npv = 0.7757 @ threshold = 0.5253\n",
    "# stacking:      ppv = 0.7992, npv = 0.8091 @ threshold = 0.5556\n",
    "# voting_clf:    ppv = 0.7957, npv = 0.7966 @ threshold = 0.5455\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.88673\n",
    "# lgbm_groups:  0.68095\n",
    "# lr:           0.65398\n",
    "# xgb:          0.84006\n",
    "# stacking:     0.88012\n",
    "# voting_clf:   0.86537\n",
    "\n",
    "\n",
    "# east_coast = [\"New Orleans\", \"Charleston\"]  but the problem is Charleston was filtered out\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.8079, npv = 0.8078 @ threshold = 0.5758\n",
    "# lgbm_groups:   ppv = 0.6776, npv = 0.6583 @ threshold = 0.0909\n",
    "# lr:            ppv = 0.7471, npv = 0.6427 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7495, npv = 0.7353 @ threshold = 0.5253\n",
    "# stacking:      ppv = 0.8023, npv = 0.8002 @ threshold = 0.5758\n",
    "# voting_clf:    ppv = 0.7912, npv = 0.7915 @ threshold = 0.5253\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.8876\n",
    "# lgbm_groups:  0.68694\n",
    "# lr:           0.65398\n",
    "# xgb:          0.82051\n",
    "# stacking:     0.88411\n",
    "# voting_clf:   0.86108\n",
    "\n",
    "# east_coast = [\"New Orleans\", \"Charleston\"]  with Charleston included\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7797, npv = 0.7796 @ threshold = 0.5253\n",
    "# lgbm_groups:   ppv = 0.652, npv = 0.6459 @ threshold = 0.1111\n",
    "# lr:            ppv = 0.7473, npv = 0.6368 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7587, npv = 0.7543 @ threshold = 0.4646\n",
    "# stacking:      ppv = 0.7835, npv = 0.7811 @ threshold = 0.5253\n",
    "# voting_clf:    ppv = 0.7691, npv = 0.7706 @ threshold = 0.5152\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.85836\n",
    "# lgbm_groups:  0.67909\n",
    "# lr:           0.64631\n",
    "# xgb:          0.82203\n",
    "# stacking:     0.84927\n",
    "# voting_clf:   0.83851\n",
    "\n",
    "\n",
    "# v23: best so far. v22 with east_coast variable\n",
    "# \"east_coast = [\"Galveston\", \"New Orleans\", \n",
    "# \"Mobile\", \"Jacksonville\", \"Savannah\", \"Charleston\", 'Wilmington', \"Norfolk\", \"Baltimore\", \"Philadelphia\"]\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7841, npv = 0.778 @ threshold = 0.5354\n",
    "# lgbm_groups:   ppv = 0.6432, npv = 0.6432 @ threshold = 0.1212\n",
    "# lr:            ppv = 0.7473, npv = 0.6368 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7236, npv = 0.7226 @ threshold = 0.5152\n",
    "# stacking:      ppv = 0.7843, npv = 0.7784 @ threshold = 0.5253\n",
    "# voting_clf:    ppv = 0.7728, npv = 0.7706 @ threshold = 0.5253\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.85921\n",
    "# lgbm_groups:  0.66969\n",
    "# lr:           0.64629\n",
    "# xgb:          0.78917\n",
    "# stacking:     0.84483\n",
    "# voting_clf:   0.83592\n",
    "\n",
    "\n",
    "\n",
    "# v24: without lat, lon, potential_wetland, district, county, mukey\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7711, npv = 0.7684 @ threshold = 0.5152\n",
    "# lgbm_groups:   ppv = 0.6779, npv = 0.6412 @ threshold = 0.1313\n",
    "# lr:            ppv = 0.7473, npv = 0.6368 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7458, npv = 0.7338 @ threshold = 0.5152\n",
    "# stacking:      ppv = 0.7683, npv = 0.7651 @ threshold = 0.5354\n",
    "# voting_clf:    ppv = 0.7667, npv = 0.76 @ threshold = 0.5455\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.84013\n",
    "# lgbm_groups:  0.64607\n",
    "# lr:           0.64698\n",
    "# xgb:          0.79118\n",
    "# stacking:     0.83714\n",
    "# voting_clf:   0.82432\n",
    "\n",
    "# v24_not_saved: without lat, lon, potential_wetland, district, county, mukey with lr in the stacking\n",
    "# ppv and npv on Test:\n",
    "# lgbm:          ppv = 0.7711, npv = 0.7684 @ threshold = 0.5152\n",
    "# lgbm_groups:   ppv = 0.6779, npv = 0.6412 @ threshold = 0.1313\n",
    "# lr:            ppv = 0.7473, npv = 0.6368 @ threshold = 0.5051\n",
    "# xgb:           ppv = 0.7458, npv = 0.7338 @ threshold = 0.5152\n",
    "# stacking:      ppv = 0.7674, npv = 0.7598 @ threshold = 0.5455\n",
    "# voting_clf:    ppv = 0.7667, npv = 0.76 @ threshold = 0.5455\n",
    "# =========================================\n",
    "# ROC_AUC on Test\n",
    "# lgbm:         0.84013\n",
    "# lgbm_groups:  0.64607\n",
    "# lr:           0.64698\n",
    "# xgb:          0.79118\n",
    "# stacking:     0.83563\n",
    "# voting_clf:   0.82432\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wj4LjNpHOzc9",
    "outputId": "6b01c399-d6fc-46c6-f622-ac200674afb8"
   },
   "outputs": [],
   "source": [
    "# !pip install lightgbm\n",
    "# !pip install xgboost\n",
    "# !pip install mlxtend\n",
    "# !pip install seaborn\n",
    "# !pip install shapely\n",
    "# !pip install geopandas\n",
    "# !pip install metric_learn\n",
    "# import pickle\n",
    "\n",
    "# !pip3 install keras\n",
    "# !pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6CJ-2pyO-Pu"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from optimize_ppv_npv_scorer_ import optimize_ppv_npv_scorer\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# SK-learn libraries for machine learning\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import *\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import xgboost\n",
    "import lightgbm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants and Data imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE_NAME = \"Merge_all_datasets/2021.03.31_200m_1000m\"\n",
    "FILE_VERSION = \"v24\"\n",
    "\n",
    "run_models = True # BEWARE! This overwrites the models stored on disk\n",
    "run_logistic = True\n",
    "no_lat_lon = True\n",
    "\n",
    "run_svc = False\n",
    "run_autoencoder = False\n",
    "run_knn = False\n",
    "run_svc_second_level = False\n",
    "\n",
    "# file params\n",
    "golden_models = [\"v21\", \"v22\", \"v23\"]\n",
    "stop_before_models = False\n",
    "\n",
    "\n",
    "if run_models:\n",
    "    model_dict = {}\n",
    "    file_param_dict = {}\n",
    "    random_state = 123 # for train, dev, test splits\n",
    "    dev = True\n",
    "    file_param_dict[\"random_state\"] = random_state\n",
    "    file_param_dict[\"dev\"] = dev\n",
    "    file_param_dict[\"input_file_name\"] = INPUT_FILE_NAME\n",
    "\n",
    "else:\n",
    "    model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "    try:\n",
    "        file_param_dict = model_dict[\"file_params\"]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "        \n",
    "    random_state = file_param_dict[\"random_state\"]\n",
    "    dev = file_param_dict[\"dev\"]\n",
    "    INPUT_FILE_NAME = file_param_dict[\"input_file_name\"]\n",
    "\n",
    "if FILE_VERSION in golden_models:\n",
    "    if run_models:\n",
    "        print(\"Warning: you are overwriting golden model\")\n",
    "        stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1q95q-9wPEky"
   },
   "outputs": [],
   "source": [
    "df_full = pd.read_pickle(\"../../../data/\" + INPUT_FILE_NAME)\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CWA determinations as groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_full = pd.read_pickle(\"../../../data/\" + INPUT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_full.columns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: 1,2,3,5\n",
    "# 2: 4,6,7\n",
    "# 3: 8 ,9\n",
    "\n",
    "def check_box_grouping(x):\n",
    "    if x.cwa1 + x.cwa2 + x.cwa3 + x.cwa5 > 0:\n",
    "        return 1\n",
    "    elif x.cwa4 + x.cwa6 + x.cwa7 > 0:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "    \n",
    "    \n",
    "def check_box_grouping(x):\n",
    "    if x.cwa1 + x.cwa3 + x.cwa5 > 0:\n",
    "        return 1\n",
    "    elif  x.cwa2 + x.cwa4 + x.cwa6 + x.cwa7 > 0:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[\"cwa_determination_groups\"] = df_full.apply(lambda x: check_box_grouping(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove longitude > -50 (bad datapoints)\n",
    "\n",
    "df_full = df_full[df_full.longitude < -50]\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce East Coast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "east_coast = [\"Galveston\", \"New Orleans\", \"Mobile\", \"Jacksonville\", \"Savannah\", \"Charleston\", 'Wilmington', \"Norfolk\", \"Baltimore\", \"Philadelphia\"]\n",
    "# east_coast = [\"New Orleans\", \"Charleston\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[\"east_coast\"] = df_full.apply(lambda x: \"yes\" if x.district in east_coast else \"no\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vmXibdpmoSgz"
   },
   "outputs": [],
   "source": [
    "df_full = df_full[df_full.district != \"Alaska\"] # no SSURGO data for Alaska Charleston\n",
    "# df_full = df_full[df_full.district != \"Charleston\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V4OSS7EfFWLD",
    "outputId": "5cba5f6a-118e-4979-8194-000e45123b90"
   },
   "outputs": [],
   "source": [
    "# any records where the cwa_determination is contrary to expectations?\n",
    "good_records = (df_full.apply(lambda x: \n",
    "               (np.sum(x.cwa1 + x.cwa2 + x.cwa3 + x.cwa4 + x.cwa5 + \n",
    "                       x.cwa6 + x.cwa7 + x.cwa8 + x.cwa9) > 0) * 1 \n",
    "               == x.cwa_determination, \n",
    "               axis=1))\n",
    "\n",
    "print(\"%good records = {}%\".format(round(np.mean(good_records) * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "MUI--cUNFmXp",
    "outputId": "08a07e58-d2a0-4ead-c85a-7e9edbf94883"
   },
   "outputs": [],
   "source": [
    "# peek at not good records\n",
    "df_full[~good_records].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_full.apply(lambda x: np.log(x.closest_wb_distance_m), axis=1))\n",
    "df_full[\"closest_wb_distance_m\"] = df_full.apply(lambda x: np.log(x.closest_wb_distance_m), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_full.apply(lambda x: np.log(x.closest_fl_distance_m), axis=1))\n",
    "df_full[\"closest_fl_distance_m\"] = df_full.apply(lambda x: np.log(x.closest_fl_distance_m), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_full.apply(lambda x: np.log(x.closest_wb_area_sqkm) if x.closest_wb_area_sqkm > 0 else np.nan, axis=1))\n",
    "df_full[\"closest_wb_area_sqkm\"] = df_full.apply(lambda x: np.log(x.closest_wb_area_sqkm) if x.closest_wb_area_sqkm > 0 else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_full.apply(lambda x: np.log(x.closest_fl_area_sqkm) if x.closest_fl_area_sqkm > 0 else np.nan, axis=1))\n",
    "df_full[\"closest_fl_area_sqkm\"] = df_full.apply(lambda x: np.log(x.closest_fl_area_sqkm) if x.closest_fl_area_sqkm > 0 else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_full.apply(lambda x: np.log(x.closest_wb_elevation) if x.closest_wb_elevation > 0 else np.nan, axis=1))\n",
    "df_full[\"closest_wb_elevation\"] = df_full.apply(lambda x: np.log(x.closest_wb_elevation) if x.closest_wb_elevation > 0 else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_full.apply(lambda x: np.log(x.closest_fl_elevation) if x.closest_fl_elevation > 0 else np.nan, axis=1))\n",
    "df_full[\"closest_fl_elevation\"] = df_full.apply(lambda x: np.log(x.closest_fl_elevation) if x.closest_fl_elevation > 0 else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wS52NjAa4kE_"
   },
   "source": [
    "# Train-Dev-Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of nan's in each numerical variable\n",
    "# remove variables that are above nan threshold of nan_th\n",
    "nan_th = 0.2\n",
    "delete_vars = []\n",
    "count = 0\n",
    "errors = 0\n",
    "nan_dist = []\n",
    "for var in df_full.describe().columns:\n",
    "    try:\n",
    "        nan_fraction = np.mean(df_full[str(var)].isna())\n",
    "        if nan_fraction != 0:\n",
    "            count += 1\n",
    "            nan_dist.append(nan_fraction)\n",
    "            if nan_fraction >= nan_th:\n",
    "                delete_vars.append(var)\n",
    "                \n",
    "    except Exception as e:\n",
    "        errors += 1\n",
    "        print(var, \"<-------------------\")\n",
    "print(count, errors)\n",
    "plt.hist(nan_dist)\n",
    "\n",
    "# keep_vars = list(set(df_full.columns) - set(delete_vars)) # wow this is messing up the order\n",
    "\n",
    "keep_vars = []\n",
    "for var in df_full.columns:\n",
    "    if var not in delete_vars:\n",
    "        keep_vars.append(var)\n",
    "df_full = df_full[keep_vars]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tc_mmRYBKxU6"
   },
   "outputs": [],
   "source": [
    "# df_full = df_full[good_records]\n",
    "\n",
    "# if dev:\n",
    "#     df, df_test = train_test_split(df_full, test_size=0.2, random_state = random_state) # 20% test\n",
    "#     df, df_dev = train_test_split(df, test_size=0.25, random_state = random_state) # 60% train, 20% dev\n",
    "# else:\n",
    "#     df, df_test = train_test_split(df_full, test_size=0.2, random_state = random_state) # 80% train, 20% test\n",
    "#     df_dev = df_test.copy()\n",
    "    \n",
    "# # df, df_test = train_test_split(df_full, test_size=0.95, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.district.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for district in df_full.district.unique():\n",
    "df = pd.DataFrame()\n",
    "df_dev = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "df_ = pd.DataFrame()\n",
    "df_dev_ = pd.DataFrame()\n",
    "df_test_ = pd.DataFrame()\n",
    "\n",
    "for group in df_full.groupby(\"district\"):\n",
    "    try:\n",
    "        df_, df_test_ = train_test_split(group[1], test_size=0.2, random_state = random_state) # 20% test\n",
    "        df_, df_dev_ = train_test_split(df_, test_size=0.25, random_state = random_state) # 60% train, 20% dev\n",
    "    except Exception as e:\n",
    "        print(group[0], e)\n",
    "    df = pd.concat([df, df_])\n",
    "    df_dev = pd.concat([df_dev, df_dev_])\n",
    "    df_test = pd.concat([df_test, df_test_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df_dev.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bODkeQCDPr24"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Zs23ZZxPtnN"
   },
   "source": [
    "### Remove cols with all NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBwbLX6YPwT_"
   },
   "outputs": [],
   "source": [
    "nan_cols = []\n",
    "for col in df.columns:\n",
    "  nan_frac = np.mean(df[str(col)].isna())\n",
    "  if nan_frac == 1:\n",
    "    nan_cols.append(col)\n",
    "nan_cols\n",
    "df.drop(nan_cols, inplace=True, axis=1)\n",
    "\n",
    "# two cols are removed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxWXqayaFhXp",
    "outputId": "52c2ceb0-fc0c-49ce-8fb4-4050e7c7f778"
   },
   "outputs": [],
   "source": [
    "\"county\" in df_full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlZ2nLgVPOn1"
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xlE_M1C2PIgp",
    "outputId": "af65405c-4220-4fe4-c5b9-c922d395bfde"
   },
   "outputs": [],
   "source": [
    "df_num_features = pd.DataFrame(df.describe().columns)\n",
    "for count, col in enumerate(df.describe().columns):\n",
    "  print(count, col)\n",
    "\n",
    "# 5, 7, 14, 17, 19:445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQVQGqHhGkE_"
   },
   "source": [
    "## Numerical Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "viN9PWn5PY7H",
    "outputId": "25a607e3-e822-47b5-908e-ff201a1ac251"
   },
   "outputs": [],
   "source": [
    "# NOTE: for kNN which uses only lat, lon, have to pass lat, lon as first two cols\n",
    "\n",
    "if INPUT_FILE_NAME == \"Merge_all_datasets/2021.03.31_200m_1000m\":\n",
    "    # numerical features of interest: \n",
    "    ssurgo = list(set(range(17, 34)) - set([22])) # 22 = mukey\n",
    "    nhd = list(range(42, 87)) + list(range(235, 278)) \n",
    "    nwi = list(range(87, 227)) + list(range(278, 418)) \n",
    "    srtm = list(range(34, 42)) + list(range(227, 235)) \n",
    "    # closest_wb_fl = list(range(456, 462)) \n",
    "\n",
    "    if run_models:\n",
    "#         imp_num_feature_list = [2, 9, 10] + ssurgo + nhd + nwi + srtm\n",
    "        imp_num_feature_list = ssurgo + nhd + nwi + srtm # remove lat, lon, pot wetland\n",
    "\n",
    "        imp_num_feature = df_num_features.loc[imp_num_feature_list]\n",
    "        imp_num_feature = list(imp_num_feature.values.flatten())\n",
    "        file_param_dict[\"imp_num_feature\"] = imp_num_feature\n",
    "    else:\n",
    "        imp_num_feature = file_param_dict[\"imp_num_feature\"]\n",
    "        \n",
    "        \n",
    "if INPUT_FILE_NAME == \"Merge_all_datasets/2021.03.31_1000m_2500m\":\n",
    "    # numerical features of interest: \n",
    "    ssurgo = list(set(range(17, 34)) - set([22])) # 22 = mukey\n",
    "    nhd = list(range(51, 94)) + list(range(241, 284)) \n",
    "    nwi = list(range(94, 233)) + list(range(284, 424)) \n",
    "    srtm = list(range(34, 51)) + list(range(233, 241)) \n",
    "    # closest_wb_fl = list(range(456, 462)) \n",
    "\n",
    "    if run_models:\n",
    "        imp_num_feature_list = [2, 9, 10] + ssurgo + nhd + nwi + srtm\n",
    "\n",
    "        imp_num_feature = df_num_features.loc[imp_num_feature_list]\n",
    "        imp_num_feature = list(imp_num_feature.values.flatten())\n",
    "        file_param_dict[\"imp_num_feature\"] = imp_num_feature\n",
    "    else:\n",
    "        imp_num_feature = file_param_dict[\"imp_num_feature\"]        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfKbTgYTGohQ"
   },
   "source": [
    "## Categorical Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peek at categorical features\n",
    "set(df.columns) - set(df.describe().columns)\n",
    "# len(set(df.describe().columns))\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5JCwDs_Q8pW"
   },
   "outputs": [],
   "source": [
    "# call out the important categorical features\n",
    "\n",
    "\n",
    "# imp_cat_feature = ['district', 'flodfreqdc', 'drclassdcd', 'county', 'jurisdiction_type'] # baseline\n",
    "# # imp_cat_feature = ['flodfreqdc', 'drclassdcd','jurisdiction_type'] # v9.5 \n",
    "\n",
    "# if run_models:\n",
    "#     imp_cat_feature = ['county',\n",
    "#      'district',\n",
    "#      'drclassdcd',\n",
    "#      'drclasswet',\n",
    "#      'engcmssdcd',\n",
    "#      'engcmssmp',\n",
    "#      'engdwbdcd',\n",
    "#      'engdwbll',\n",
    "#      'engdwbml',\n",
    "#      'engdwobdcd',\n",
    "#      'englrsdcd',\n",
    "#      'engsldcd',\n",
    "#      'engsldcp',\n",
    "#      'engstafdcd',\n",
    "#      'engstafll',\n",
    "#      'engstafml',\n",
    "#      'flodfreqdc',\n",
    "#      'flodfreqma',\n",
    "#      'forpehrtdc',\n",
    "#      'huc4',\n",
    "#      'hydgrpdcd',\n",
    "#      'jurisdiction_type',\n",
    "#      'state',\n",
    "#      'urbrecptdc',\n",
    "#      'east_coast']\n",
    "#     file_param_dict[\"imp_cat_feature\"] = imp_cat_feature\n",
    "    \n",
    "#remove district and county\n",
    "if run_models: \n",
    "    imp_cat_feature = ['drclassdcd',\n",
    "     'drclasswet',\n",
    "     'engcmssdcd',\n",
    "     'engcmssmp',\n",
    "     'engdwbdcd',\n",
    "     'engdwbll',\n",
    "     'engdwbml',\n",
    "     'engdwobdcd',\n",
    "     'englrsdcd',\n",
    "     'engsldcd',\n",
    "     'engsldcp',\n",
    "     'engstafdcd',\n",
    "     'engstafll',\n",
    "     'engstafml',\n",
    "     'flodfreqdc',\n",
    "     'flodfreqma',\n",
    "     'forpehrtdc',\n",
    "     'huc4',\n",
    "     'hydgrpdcd',\n",
    "     'jurisdiction_type',\n",
    "     'state',\n",
    "     'urbrecptdc',\n",
    "     'east_coast']\n",
    "    file_param_dict[\"imp_cat_feature\"] = imp_cat_feature    \n",
    "    \n",
    "else:\n",
    "    imp_cat_feature = file_param_dict[\"imp_cat_feature\"]\n",
    "    \n",
    "# imp_cat_feature = ['jurisdiction_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VweeykE-4Ter"
   },
   "source": [
    "# Order Train-Dev-Test splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqbXGvZIRHGi",
    "outputId": "6238c23e-8db0-4cc0-fe3c-71f547ef6e6a"
   },
   "outputs": [],
   "source": [
    "# re-arrange so numerical columns go first, then the categorical\n",
    "df1 = df[imp_num_feature]\n",
    "df2 = df[imp_cat_feature]\n",
    "\n",
    "# train\n",
    "df_X_combined_ordered = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "# dev\n",
    "df_dev_X = pd.concat([df_dev[imp_num_feature], df_dev[imp_cat_feature]], axis=1)\n",
    "\n",
    "\n",
    "# test\n",
    "df_test_X = pd.concat([df_test[imp_num_feature], df_test[imp_cat_feature]], axis=1)\n",
    "\n",
    "\n",
    "df_X_combined_ordered.columns #44\n",
    "df_X_combined_ordered.shape # (10000, 44)\n",
    "df_test_X.shape # (4500, 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_num_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdBKul2wROi4",
    "outputId": "fb607dae-a36a-4e9b-e4be-eb54ae133426"
   },
   "outputs": [],
   "source": [
    "# fraction of nan's in each numerical variable\n",
    "count = 0\n",
    "errors = 0\n",
    "nan_dist = []\n",
    "nan_vars = []\n",
    "for var in df_X_combined_ordered.describe().columns:\n",
    "    try:\n",
    "        if np.mean(df_X_combined_ordered[str(var)].isna()) != 0:\n",
    "            nan_vars.append(var)\n",
    "            count += 1\n",
    "            nan_dist.append(np.mean(df_X_combined_ordered[str(var)].isna()))\n",
    "#             print(var, round(np.mean(df_X_combined_ordered[str(var)].isna()), 2))\n",
    "    except Exception as e:\n",
    "        errors += 1\n",
    "        print(var, \"<-------------------\")\n",
    "print(count, errors    )\n",
    "plt.hist(nan_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute nearest 10 neighbor average for all nan values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_nan(lat, lon, value, var):\n",
    "    if np.isnan(value):\n",
    "        return knn_model_dict[var].predict(pd.DataFrame([[lat, lon]], columns=[\"latitude\", \"longitude\"]))[0]\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn_model_dict = {}\n",
    "\n",
    "if not no_lat_lon:\n",
    "    for var in nan_vars:\n",
    "        knn = KNeighborsRegressor(n_neighbors=30)\n",
    "        temp_X = df_X_combined_ordered[~df_X_combined_ordered[var].isna()][[\"latitude\", \"longitude\"]]\n",
    "        temp_Y = df_X_combined_ordered[var][~df_X_combined_ordered[var].isna()]\n",
    "        knn.fit(temp_X, temp_Y)\n",
    "        knn_model_dict[var] = knn\n",
    "        df_X_combined_ordered[var] = df_X_combined_ordered.apply(lambda x: impute_nan(x.latitude, x.longitude, x[var], var), axis=1)\n",
    "        df_dev_X[var] = df_dev_X.apply(lambda x: impute_nan(x.latitude, x.longitude, x[var], var), axis=1)\n",
    "        df_test_X[var] = df_test_X.apply(lambda x: impute_nan(x.latitude, x.longitude, x[var], var), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4kq__Giqima"
   },
   "outputs": [],
   "source": [
    "# impute 0's into wb_area_mean, fl_length_sum, fl_length_mean because they were\n",
    "# assigned np.nan if they were absent\n",
    "# A non-existent water feature should be assigned 0 given definition of each\n",
    "\n",
    "def fill_na(df):\n",
    "  try:\n",
    "    df.fl_length_sum_200m = df.fl_length_sum_200m.fillna(0)\n",
    "    df.fl_length_mean_200m = df.fl_length_sum_200m.fillna(0)\n",
    "    df.fl_length_sum_2500m = df.fl_length_sum_200m.fillna(0)\n",
    "    df.fl_length_mean_2500m = df.fl_length_sum_200m.fillna(0)\n",
    "  except:\n",
    "    pass\n",
    "  return df\n",
    "\n",
    "# No need for fill_na() since imputing by knn\n",
    "\n",
    "if no_lat_lon:\n",
    "    df_X_combined_ordered = fill_na(df_X_combined_ordered)\n",
    "    df_dev_X_combined_ordered = fill_na(df_dev_X)\n",
    "    df_test_X_combined_ordered = fill_na(df_test_X)\n",
    "else:\n",
    "    df_X_combined_ordered = df_X_combined_ordered\n",
    "    df_dev_X_combined_ordered = df_dev_X\n",
    "    df_test_X_combined_ordered = df_test_X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qy2KEjaNq487",
    "outputId": "077aa965-5d64-4ad9-abc7-001580eb74d8"
   },
   "outputs": [],
   "source": [
    "# fraction of nan's in each variable\n",
    "def print_na(df_X_combined_ordered):\n",
    "  for var in df_X_combined_ordered.describe().columns:\n",
    "    try:\n",
    "        if np.mean(df_X_combined_ordered[str(var)].isna()) != 0:\n",
    "          print(var, round(np.mean(df_X_combined_ordered[str(var)].isna()), 2))\n",
    "    except Exception as e:\n",
    "        print(var)\n",
    "        print(e)\n",
    "        pass\n",
    "        \n",
    "print(\"Train\")    \n",
    "print_na(df_X_combined_ordered)      \n",
    "print()\n",
    "print(\"Dev\")\n",
    "print_na(df_dev_X_combined_ordered)\n",
    "print()\n",
    "print(\"Test\")\n",
    "print_na(df_test_X_combined_ordered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiZZiHI7rroC"
   },
   "source": [
    "# Offline OHE to keep track of variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wgvKVZ7rNb8"
   },
   "outputs": [],
   "source": [
    "# ohe-hot-encode the columns\n",
    "# get_dummies only encodes cat columns\n",
    "df_X_combined_dummies_ordered = pd.get_dummies(df_X_combined_ordered)\n",
    "# df_X_combined_dummies_ordered.columns # 90\n",
    "\n",
    "df_dev_X_combined_dummies_ordered = pd.get_dummies(df_dev_X_combined_ordered)\n",
    "df_test_X_combined_dummies_ordered = pd.get_dummies(df_test_X_combined_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2DzQYz-guOe",
    "outputId": "d15cc667-b613-4161-fdee-cb63bd03ce29"
   },
   "outputs": [],
   "source": [
    "print(df_X_combined_ordered.shape)\n",
    "print(df_dev_X_combined_ordered.shape)\n",
    "print(df_test_X_combined_ordered.shape)\n",
    "print(df_X_combined_dummies_ordered.shape)\n",
    "print(df_dev_X_combined_dummies_ordered.shape)\n",
    "print(df_test_X_combined_dummies_ordered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1Eq49x-r55M"
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YoBhg5wPrxlx"
   },
   "outputs": [],
   "source": [
    "# impute categorical data\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "  \"\"\"\n",
    "  By inheriting TransformerMixin, you get fit_transform method for free \n",
    "  if you implement fit and transform methods\n",
    "  \"\"\" \n",
    "\n",
    "  def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "\n",
    "        Columns of dtype object are imputed with the most frequent value \n",
    "        in column.\n",
    "        Columns of other types are imputed with median of column.\n",
    "        \"\"\"\n",
    "  def fit(self, X, y=None):\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].median() for c in X], \n",
    "            index=X.columns)\n",
    "        return self\n",
    "\n",
    "  def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2E_VtoXpr8W9"
   },
   "outputs": [],
   "source": [
    "# Pipeline for numerical columns\n",
    "# 1. fill NA's with median values\n",
    "# 2. scale them\n",
    "\n",
    "# num_pipeline_impute_ss = Pipeline([        # should be list of tuples\n",
    "#                           (\"num_imputer\", SimpleImputer(strategy=\"median\")),\n",
    "#                           (\"std_scaler\", StandardScaler())\n",
    "#                           ])                      \n",
    "\n",
    "# num_pipeline_impute_ss = Pipeline([        # should be list of tuples\n",
    "#                           (\"num_imputer\", SimpleImputer(strategy=\"median\")),\n",
    "#                           (\"robust_scaler\", RobustScaler())\n",
    "#                           ])                      \n",
    "\n",
    "num_pipeline_impute_ss = Pipeline([        # should be list of tuples\n",
    "                          (\"num_imputer\", SimpleImputer(strategy=\"median\"))\n",
    "                          ])                      \n",
    "\n",
    "\n",
    "# Pipleline for categorical columns\n",
    "# 1. fill NA's with most frequent values\n",
    "# 2. one hot code\n",
    "\n",
    "# cat_pipeline_impute_ohe = Pipeline([(\"cat_imputer\", DataFrameImputer()),\n",
    "#                          (\"one_hot_encoder\", OneHotEncoder(drop=\"first\", \\\n",
    "#                                                            sparse=False))\n",
    "#                          ])\n",
    "\n",
    "\n",
    "# you want to do the following where you handle_unknown categories in the \n",
    "# test data by ignoring them. However, in the imeplementation, I am using\n",
    "# df_X_combined_dummies_ordered to indicate the numerical and cat columns \n",
    "# hence need to fix the df_X_combined_dummies_ordered such that the first \n",
    "# ohe is not dropped (as is being done in immediately above)\n",
    "\n",
    "cat_pipeline_impute_ohe = Pipeline([(\"cat_imputer\", DataFrameImputer()),\n",
    "                         (\"one_hot_encoder\", OneHotEncoder(sparse=False,\n",
    "                                                           handle_unknown = \"ignore\"))\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6zsqDgLsIhp"
   },
   "outputs": [],
   "source": [
    "numericals_list = list(df_X_combined_ordered.describe().columns)\n",
    "categories_list = list(set(df_X_combined_ordered.columns) - set(numericals_list))\n",
    "\n",
    "# here trying to do numerical and categorical transformation in isolation\n",
    "# this because ColumnTransformer removes column name information :-(\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# only the cat columns will be one-hot encoded\n",
    "partial_transformer_impute_ohe = ColumnTransformer([\n",
    "                                   (\"categorical_ohe\", cat_pipeline_impute_ohe,\\\n",
    "                                    categories_list)\n",
    "])\n",
    "\n",
    "# only the numerical columns withh get standard scaling\n",
    "partial_transformer_impute_ss = ColumnTransformer([\n",
    "                                   (\"numerical_ss_impute\", num_pipeline_impute_ss,\\\n",
    "                                    numericals_list)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation of Dev and Test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7DxNTfIFtT9y",
    "outputId": "5d8a5f9d-f079-43d8-b8db-65afc2d25027"
   },
   "outputs": [],
   "source": [
    "# Pass the numerical columns through Numerical Pipeline \n",
    "\n",
    "# train\n",
    "full_data_ohe_ss_imputed = (partial_transformer_impute_ss\n",
    "                            .fit(df_X_combined_ordered[numericals_list])\n",
    "                            .transform(df_X_combined_ordered[numericals_list])) \n",
    "print(full_data_ohe_ss_imputed.shape)\n",
    "\n",
    "# dev\n",
    "dev_ohe_ss_imputed = (partial_transformer_impute_ss\n",
    "                            .fit(df_X_combined_ordered[numericals_list])\n",
    "                            .transform(df_dev_X_combined_ordered[numericals_list])) \n",
    "print(dev_ohe_ss_imputed.shape)\n",
    "\n",
    "\n",
    "# test\n",
    "test_ohe_ss_imputed = (partial_transformer_impute_ss\n",
    "                            .fit(df_X_combined_ordered[numericals_list])\n",
    "                            .transform(df_test_X_combined_ordered[numericals_list])) \n",
    "print(test_ohe_ss_imputed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQD-xNjqtUA9",
    "outputId": "9bf01104-653e-4175-e099-3c7a0296e530"
   },
   "outputs": [],
   "source": [
    "# Pass the cat columns through Categorical Pipeline\n",
    "\n",
    "# train\n",
    "cat_data_OHE = (partial_transformer_impute_ohe\n",
    "                .fit(df_X_combined_ordered)\n",
    "                .transform(df_X_combined_ordered))\n",
    "print(cat_data_OHE.shape)\n",
    "\n",
    "# test\n",
    "dev_cat_data_OHE = (partial_transformer_impute_ohe\n",
    "                .fit(df_X_combined_ordered)\n",
    "                .transform(df_dev_X_combined_ordered))\n",
    "print(dev_cat_data_OHE.shape)\n",
    "\n",
    "# test\n",
    "test_cat_data_OHE = (partial_transformer_impute_ohe\n",
    "                .fit(df_X_combined_ordered)\n",
    "                .transform(df_test_X_combined_ordered))\n",
    "print(test_cat_data_OHE.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy X and Y arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgK2Nv2HycZo",
    "outputId": "9af08aa1-945f-49a2-a36b-42064875d6d6"
   },
   "outputs": [],
   "source": [
    "# join the arrays into one array that can be passed into models\n",
    "\n",
    "# train\n",
    "X = np.hstack((full_data_ohe_ss_imputed, cat_data_OHE))\n",
    "Y = np.array(df.cwa_determination)\n",
    "Y_groups = np.array(df.cwa_determination_groups)\n",
    "\n",
    "# dev\n",
    "dev_X = np.hstack((dev_ohe_ss_imputed, dev_cat_data_OHE))\n",
    "dev_Y = np.array(df_dev.cwa_determination)\n",
    "dev_Y_groups = np.array(df_dev.cwa_determination_groups)\n",
    "\n",
    "# test\n",
    "test_X = np.hstack((test_ohe_ss_imputed, test_cat_data_OHE))\n",
    "test_Y = np.array(df_test.cwa_determination)\n",
    "test_Y_groups = np.array(df_test.cwa_determination_groups)\n",
    "\n",
    "print(X.shape, Y.shape, dev_X.shape, dev_Y.shape, test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNnvAK30tUDx"
   },
   "outputs": [],
   "source": [
    "# Convert numerical and cat transforms back to dataframe (for housekeeping)\n",
    "\n",
    "# convert numerical arrays into dataframe\n",
    "\n",
    "def make_dataframe(full_data_ohe_ss_imputed, cat_data_OHE):\n",
    "  df_num_data_ohe_ss = (pd.DataFrame(\n",
    "      full_data_ohe_ss_imputed,\n",
    "      columns=list(df_X_combined_dummies_ordered[numericals_list].columns)\n",
    "  ))\n",
    "\n",
    "  # # convert cat arrays into dataframe\n",
    "  ohe_categories_list = (list(set(df_X_combined_dummies_ordered.columns) - set(numericals_list)))\n",
    "  df_cat_data_OHE = (pd.DataFrame(\n",
    "      cat_data_OHE,\n",
    "      columns=list(df_X_combined_dummies_ordered[ohe_categories_list].columns))\n",
    "  )\n",
    "\n",
    "  # concatenate into one dataframe\n",
    "\n",
    "  return pd.concat([df_num_data_ohe_ss, df_cat_data_OHE], axis=1)\n",
    "\n",
    "\n",
    "df_train_X_dummies = make_dataframe(full_data_ohe_ss_imputed, cat_data_OHE)\n",
    "df_dev_X_dummies = make_dataframe(dev_ohe_ss_imputed, dev_cat_data_OHE)\n",
    "df_test_X_dummies = make_dataframe(test_ohe_ss_imputed, test_cat_data_OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iY1gOlOk5-ZM"
   },
   "outputs": [],
   "source": [
    "if stop_before_models:\n",
    "    stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "if False: # True if you want to run this\n",
    "    # define inliers as negatives and outliers as positive examples\n",
    "    inliers = Y == 0\n",
    "    outliers = Y == 1\n",
    "    X_inliers = X[inliers]\n",
    "    Y_inliers = Y[inliers]\n",
    "\n",
    "    clf = OneClassSVM(gamma='auto').fit(X_inliers)\n",
    "    \n",
    "    # predict on filtered train, train and dev data\n",
    "    X_inliers_predict = clf.predict(X_inliers)\n",
    "    X_predict = clf.predict(X)\n",
    "    dev_predict = clf.predict(dev_X)\n",
    "    \n",
    "    # transform on train and dev data\n",
    "    train_score_samples = clf.score_samples(X)\n",
    "    dev_score_samples = clf.score_samples(dev_X)\n",
    "\n",
    "    # replace 1's by 0's (1 of OneClassSVM is the inlier or the majority class which is 0)\n",
    "    # replace 1's by -1's (define outliers as minority class)\n",
    "    dev_predict[dev_predict == 1] = 0\n",
    "    dev_predict[dev_predict == -1] = 1\n",
    "    print(np.mean(dev_predict == dev_Y)) # 0.38839590443686006\n",
    "    \n",
    "    # do same on filtered X data\n",
    "    X_inliers_predict[X_inliers_predict == 1] = 0\n",
    "    X_inliers_predict[X_inliers_predict == -1] = 1\n",
    "    print(np.mean(X_inliers_predict == Y_inliers)) # 0.5502357635110627\n",
    "\n",
    "    # do same on train data\n",
    "    X_predict[X_predict == 1] = 0\n",
    "    X_predict[X_predict == -1] = 1\n",
    "    print(np.mean(X_predict == Y)) # 0.708762296957218\n",
    "\n",
    "    plt.hist(dev_score_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mahalanobis Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "# dist = DistanceMetric.get_metric(\"mahalanobis\", V=cov.get_mahalanobis_matrix())\n",
    "# dist = DistanceMetric.get_metric(\"mahalanobis\", V=np.cov(X))\n",
    "# dist.pairwise(X)\n",
    "\n",
    "# np.linalg.det(np.cov(X))\n",
    "# np.linalg.det(np.linalg.pinv(np.cov(X)))\n",
    "# np.linalg.cond(X)\n",
    "# np.linalg.pinv(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from metric_learn import Covariance\n",
    "# from sklearn.datasets import load_iris\n",
    "# iris = load_iris()['data']\n",
    "# cov = Covariance().fit(iris)\n",
    "# x = cov.transform(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA and Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P2(n_components, data): # from Project 3!\n",
    "  \"\"\"\n",
    "  Takes target dimensionality reduction (k) and the data to reduce\n",
    "  Returns the reduced data\n",
    "  \"\"\"\n",
    "  \n",
    "  pca = PCA(n_components)\n",
    "  pca.fit(data)\n",
    "  return pca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # True if you want to run this\n",
    "    n_components = 475 # maximum is X.shape[1]\n",
    "    d = 2\n",
    "    fig, axes = plt.subplots(d, d, figsize=(10, 10))\n",
    "    # Dimension reduction\n",
    "    pca = P2(n_components=n_components, data=X)\n",
    "    X = pca.transform(X)\n",
    "\n",
    "    import seaborn as sns\n",
    "    colors = [\"g\", \"r\"]\n",
    "\n",
    "    for i in range(d**2):\n",
    "        pc_i, pc_i_1 = X[:, i], X[:, i+1]\n",
    "        sns.scatterplot(ax=axes[i//d, i%d], x=pc_i, y=pc_i_1, hue=np.array(Y).flatten())\n",
    "        axes[i//d, i%d].set_xlabel(\"PC\" + str(i+1))\n",
    "        axes[i//d, i%d].set_ylabel(\"PC\" + str(i+2))\n",
    "        \n",
    "    dev_X = pca.transform(dev_X)\n",
    "    test_X = pca.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZOqLgq5EsPm"
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmWtOA8lEThm",
    "outputId": "3a4a38ac-dfe3-4cc8-ddd0-80ae86b3eec8"
   },
   "outputs": [],
   "source": [
    "# print(sorted(metrics.SCORERS.keys()))\n",
    "# sorted(metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_search.__dir__()\n",
    "# random_search.return_train_score\n",
    "\n",
    "# random_search.scoring # roc_auc\n",
    "# random_search.best_score_ # \n",
    "# random_search.scorer_ # make_scorer(roc_auc_score, needs_threshold=True)\n",
    "\n",
    "# random_search.cv_results_\n",
    "# random_search.predict_proba(X)\n",
    "# random_search.predict_log_proba(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_taken(start, end):\n",
    "    delta = end - start\n",
    "    print(\"Time taken (min):\", round(delta.seconds/60, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(fitted_model, test_X, test_Y, model_name):\n",
    "\n",
    "    y_predict_proba = fitted_model.predict_proba(test_X)[:, 1]\n",
    "    pv = ppv_npv_opt_th(test_Y, y_predict_proba)\n",
    "#     print(\"{}: {}ppv = {}, npv = {}\".format(fitted_model.estimator, \" \"*(13 - len(str(fitted_model.estimator))), round(pv[0], 4), round(pv[1], 4)))\n",
    "    print(\"{}: {}ppv = {}, npv = {} @ threshold = {}\".format(model_name, \" \"*(13 - len(model_name)), round(pv[0], 4), round(pv[1], 4), round(pv[2], 4)))\n",
    "\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html\n",
    "    # AP summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold\n",
    "    print(\"average_precision_score:\", round(metrics.average_precision_score(test_Y, fitted_model.predict_proba(test_X)[:, 1], average=\"weighted\"), 5))\n",
    "        \n",
    "    y_prob = fitted_model.predict_proba(test_X)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_Y, y_prob[:, 1], pos_label=1)\n",
    "    print(\"roc_auc\",\":\", round(metrics.auc(fpr, tpr), 5))\n",
    "        \n",
    "    print(\"Classification Report:\") # threshold agnostic because you pass in the test labels instead of scores (probabilities)\n",
    "    print(classification_report(test_Y, fitted_model.predict(test_X)))\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(test_Y, fitted_model.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_roc_auc(fitted_model, test_X, test_Y):\n",
    "    y_prob = fitted_model.predict_proba(test_X)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_Y, y_prob[:, 1], pos_label=1)\n",
    "    return round(metrics.auc(fpr, tpr), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppv_npv_opt_th(y_true=np.array([1,0,1]), y_predict_proba=np.array([0.5, 0.25, 0.3])):\n",
    "    \"\"\"\n",
    "    Inputs: y_true labels and prediction scores\n",
    "    Outputs: optimized positive predictive value and negative predictive values per this reference\n",
    "    https://arxiv.org/pdf/2007.05073.pdf\n",
    "    \"\"\"\n",
    "    min_ppv_npv_list = []\n",
    "    th_list = np.linspace(0, 1, 100)\n",
    "    for th in th_list:\n",
    "        y_predict = 1 * (y_predict_proba > th)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_predict).ravel()\n",
    "        ppv = tp / (tp + fp) \n",
    "        npv = tn / (fn + tn)\n",
    "        min_ppv_npv = np.min(np.nan_to_num(np.array((ppv, npv))))\n",
    "        min_ppv_npv_list.append(min_ppv_npv)\n",
    "    max_ppv_npv = np.nanmax(np.array(min_ppv_npv_list))\n",
    "    opt_th_index = np.array(min_ppv_npv_list).argmax(axis=0)\n",
    "    opt_th = th_list[opt_th_index]\n",
    "    opt_y_predict = 1 * (y_predict_proba > opt_th)\n",
    "    opt_tn, opt_fp, opt_fn, opt_tp = confusion_matrix(y_true, opt_y_predict).ravel()\n",
    "    opt_ppv = opt_tp / (opt_tp + opt_fp) \n",
    "    opt_npv = opt_tn / (opt_fn + opt_tn)\n",
    "    return opt_ppv, opt_npv, round(opt_th, 4)\n",
    "ppv_npv_opt_th()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ppv_npv(y_true, y_predict):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_predict).ravel()\n",
    "    ppv = tp / (tp + fp) \n",
    "    npv = tn / (fn + tn)    \n",
    "    return ppv, npv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.log(df.closest_wb_distance_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.log(df.closest_fl_distance_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.log(df.closest_fl_area_sqkm.apply(lambda x: x if x > 0 else np.nan)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.log(df.closest_wb_area_sqkm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.log(df.closest_fl_elevation.apply(lambda x: x if x > 0 else np.nan)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ez1BBgTW_Bk"
   },
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-nU49jh6tULS",
    "outputId": "166d48d9-0f92-4c84-a479-c662c5172834"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/binilg/lightgbm-with-randomsearchcv-and-feature-imp\n",
    "# Implementation: https://www.kaggle.com/mlisovyi/lightgbm-hyperparameter-optimisation-lb-0-761\n",
    "# Documentation: https://lightgbm.readthedocs.io/en/latest/Features.html\n",
    "# LightGBM Classifier: https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#\n",
    "\n",
    "from optimize_ppv_npv_scorer_ import optimize_ppv_npv_scorer\n",
    "\n",
    "import lightgbm\n",
    "param_dict = {\n",
    "    'learning_rate': [0.05],\n",
    "    'num_leaves': [90,200],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'max_depth' : [5,6,7,8],\n",
    "    'random_state' : [501], \n",
    "    'colsample_bytree' : [0.5,0.7],\n",
    "    'subsample' : [0.5,0.7],\n",
    "    'min_split_gain' : [0.01],\n",
    "    'min_data_in_leaf':[10],\n",
    "#     'metric':['auc']\n",
    "    }\n",
    "#modelling\n",
    "clf = lightgbm.LGBMClassifier()\n",
    "\n",
    "if run_models:\n",
    "    random_search_model = (RandomizedSearchCV(clf, \n",
    "                               param_dict, \n",
    "                               verbose=1, \n",
    "                               cv=10, \n",
    "                               n_jobs = -1, \n",
    "                               n_iter=10,\n",
    "                               scoring=optimize_ppv_npv_scorer))\n",
    "        # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    random_search_model.fit(X, Y)\n",
    "    model_dict[\"lgbm\"] = random_search_model.best_estimator_\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "    \n",
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "lgbm = model_dict[\"lgbm\"]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(lgbm, dev_X, dev_Y, model_name=\"lgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "id": "SaFbWsFQX5Vs",
    "outputId": "f00a317c-8b5f-4dd4-e538-8056b8a803be"
   },
   "outputs": [],
   "source": [
    "#Feature importance for top 50 predictors\n",
    "predictors = [x for x in df_X_combined_dummies_ordered.columns]\n",
    "feat_imp = pd.Series(lgbm.feature_importances_, predictors).sort_values(ascending=False)\n",
    "feat_imp = feat_imp[0:50]\n",
    "plt.rcParams['figure.figsize'] = 20, 5\n",
    "feat_imp.plot(kind='bar', title='Feature Importance')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/binilg/lightgbm-with-randomsearchcv-and-feature-imp\n",
    "# Implementation: https://www.kaggle.com/mlisovyi/lightgbm-hyperparameter-optimisation-lb-0-761\n",
    "# Documentation: https://lightgbm.readthedocs.io/en/latest/Features.html\n",
    "# LightGBM Classifier: https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#\n",
    "\n",
    "from optimize_ppv_npv_scorer_ import optimize_ppv_npv_scorer\n",
    "\n",
    "import lightgbm\n",
    "param_dict = {\n",
    "    'learning_rate': [0.05],\n",
    "    'num_leaves': [90,200],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['multiclass'],\n",
    "    'max_depth' : [5,6,7,8],\n",
    "    'random_state' : [501], \n",
    "    'colsample_bytree' : [0.5,0.7],\n",
    "    'subsample' : [0.5,0.7],\n",
    "    'min_split_gain' : [0.01],\n",
    "    'min_data_in_leaf':[10],\n",
    "#     'metric':['auc']\n",
    "    }\n",
    "#modelling\n",
    "clf = lightgbm.LGBMClassifier()\n",
    "\n",
    "if run_models:\n",
    "    random_search_model = (RandomizedSearchCV(clf, \n",
    "                               param_dict, \n",
    "                               verbose=1, \n",
    "                               cv=10, \n",
    "                               n_jobs = -1, \n",
    "                               n_iter=10,\n",
    "                               scoring=optimize_ppv_npv_scorer))\n",
    "        # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    random_search_model.fit(X, Y_groups)\n",
    "    model_dict[\"lgbm_groups\"] = random_search_model.best_estimator_\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "    \n",
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "lgbm_groups = model_dict[\"lgbm_groups\"]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1 = Y_groups == 1\n",
    "group_2 = Y_groups == 2\n",
    "group_3 = Y_groups == 3\n",
    "\n",
    "print(np.mean(Y_groups[group_1] == lgbm_groups.predict(X[group_1])))\n",
    "print(np.mean(Y_groups[group_2] == lgbm_groups.predict(X[group_2])))\n",
    "print(np.mean(Y_groups[group_3] == lgbm_groups.predict(X[group_3])))\n",
    "\n",
    "train_predict = lgbm_groups.predict(X)\n",
    "pd.DataFrame(train_predict).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_group_1 = dev_Y_groups == 1\n",
    "dev_group_2 = dev_Y_groups == 2\n",
    "dev_group_3 = dev_Y_groups == 3\n",
    "\n",
    "print(np.mean(dev_Y_groups[dev_group_1] == lgbm_groups.predict(dev_X[dev_group_1])))\n",
    "print(np.mean(dev_Y_groups[dev_group_2] == lgbm_groups.predict(dev_X[dev_group_2])))\n",
    "print(np.mean(dev_Y_groups[dev_group_3] == lgbm_groups.predict(dev_X[dev_group_3])))\n",
    "\n",
    "dev_predict = lgbm_groups.predict(dev_X)\n",
    "pd.DataFrame(dev_predict).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(test_Y_groups).value_counts())\n",
    "\n",
    "test_group_1 = test_Y_groups == 1\n",
    "test_group_2 = test_Y_groups == 2\n",
    "test_group_3 = test_Y_groups == 3\n",
    "\n",
    "print(np.mean(test_Y_groups[test_group_1] == lgbm_groups.predict(test_X[test_group_1])))\n",
    "print(np.mean(test_Y_groups[test_group_2] == lgbm_groups.predict(test_X[test_group_2])))\n",
    "print(np.mean(test_Y_groups[test_group_3] == lgbm_groups.predict(test_X[test_group_3])))\n",
    "\n",
    "test_predict = lgbm_groups.predict(test_X)\n",
    "print(pd.DataFrame(test_predict).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following for \n",
    "# 1: 1,2,3,5\n",
    "# 2: 4,6,7\n",
    "# 3: 8 ,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1 = Y_groups == 1\n",
    "group_2 = Y_groups == 2\n",
    "group_3 = Y_groups == 3\n",
    "\n",
    "print(np.mean(Y_groups[group_1] == lgbm_groups.predict(X[group_1])))\n",
    "print(np.mean(Y_groups[group_2] == lgbm_groups.predict(X[group_2])))\n",
    "print(np.mean(Y_groups[group_3] == lgbm_groups.predict(X[group_3])))\n",
    "\n",
    "train_predict = lgbm_groups.predict(X)\n",
    "pd.DataFrame(train_predict).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_group_1 = dev_Y_groups == 1\n",
    "dev_group_2 = dev_Y_groups == 2\n",
    "dev_group_3 = dev_Y_groups == 3\n",
    "\n",
    "print(np.mean(dev_Y_groups[dev_group_1] == lgbm_groups.predict(dev_X[dev_group_1])))\n",
    "print(np.mean(dev_Y_groups[dev_group_2] == lgbm_groups.predict(dev_X[dev_group_2])))\n",
    "print(np.mean(dev_Y_groups[dev_group_3] == lgbm_groups.predict(dev_X[dev_group_3])))\n",
    "\n",
    "dev_predict = lgbm_groups.predict(dev_X)\n",
    "pd.DataFrame(dev_predict).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_group_1 = test_Y_groups == 1\n",
    "test_group_2 = test_Y_groups == 2\n",
    "test_group_3 = test_Y_groups == 3\n",
    "\n",
    "print(np.mean(test_Y_groups[test_group_1] == lgbm_groups.predict(test_X[test_group_1])))\n",
    "print(np.mean(test_Y_groups[test_group_2] == lgbm_groups.predict(test_X[test_group_2])))\n",
    "print(np.mean(test_Y_groups[test_group_3] == lgbm_groups.predict(test_X[test_group_3])))\n",
    "\n",
    "test_predict = lgbm_groups.predict(test_X)\n",
    "pd.DataFrame(test_predict).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM: Second level learner to minimize False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(lgbm, X, Y, model_name=\"lgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify all the true and false negatives on train data\n",
    "\n",
    "lgbm = model_dict[\"lgbm\"]  \n",
    "\n",
    "negs = model_dict[\"lgbm\"].predict(X) == 0\n",
    "X_negs = X[negs]\n",
    "Y_negs = Y[negs]\n",
    "np.mean(Y_negs) # 13% of the predicted negatives are true negatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    'learning_rate': [0.05],\n",
    "    'num_leaves': [90,200],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'max_depth' : [5,6,7,8],\n",
    "    'random_state' : [501], \n",
    "    'colsample_bytree' : [0.5,0.7],\n",
    "    'subsample' : [0.5,0.7],\n",
    "    'min_split_gain' : [0.01],\n",
    "    'min_data_in_leaf':[10],\n",
    "#     'metric':['auc']\n",
    "    }\n",
    "clf = lightgbm.LGBMClassifier()\n",
    "\n",
    "if run_models:\n",
    "    random_search_model = (RandomizedSearchCV(clf, \n",
    "                               param_dict, \n",
    "                               verbose=1, \n",
    "                               cv=10, \n",
    "                               n_jobs = -1, \n",
    "                               n_iter=10,\n",
    "                               scoring='precision'))\n",
    "        # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    random_search_model.fit(X_negs, Y_negs)\n",
    "    model_dict[\"lgbm_second_level\"] = random_search_model.best_estimator_\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "    \n",
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "lgbm_second_level = model_dict[\"lgbm_second_level\"]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_negs = model_dict[\"lgbm\"].predict(dev_X) == 0\n",
    "dev_X_negs = dev_X[dev_negs]\n",
    "dev_Y_negs = dev_Y[dev_negs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(lgbm_second_level, dev_X_negs, dev_Y_negs, model_name=\"lgbm_second_level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the size of our encoded representations\n",
    "encoding_dim = 100 # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    " \n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(X.shape[1],))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(413, activation='sigmoid')(encoded)\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "# configure our model to use a per-pixel binary crossentropy loss, and the Adadelta optimizer:\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = X\n",
    "x_test = dev_X\n",
    "# normalize all values between 0 and 1 and we will flatten the 28x28 images into vectors of size 784.\n",
    "x_train = x_train.astype('float32') / np.float(x_train.shape[1] - 1)\n",
    "x_test = x_test.astype('float32') / np.float(x_test.shape[1] - 1)\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_autoencoder:\n",
    "    autoencoder.fit(x_train, x_train,\n",
    "    epochs=50,\n",
    "    batch_size=x_train.shape[1],\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, x_test))\n",
    "    # encode and decode some digits\n",
    "    # note that we take them from the *test* set\n",
    "    encoded_imgs = encoder.predict(x_test)\n",
    "    decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/binilg/lightgbm-with-randomsearchcv-and-feature-imp\n",
    "# Implementation: https://www.kaggle.com/mlisovyi/lightgbm-hyperparameter-optimisation-lb-0-761\n",
    "# Documentation: https://lightgbm.readthedocs.io/en/latest/Features.html\n",
    "# LightGBM Classifier: https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#\n",
    "\n",
    "encoded_train_imgs = encoder.predict(x_train)\n",
    "from optimize_ppv_npv_scorer_ import optimize_ppv_npv_scorer\n",
    "\n",
    "import lightgbm\n",
    "param_dict = {\n",
    "    'learning_rate': [0.05],\n",
    "    'num_leaves': [90,200],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'max_depth' : [5,6,7,8],\n",
    "    'random_state' : [501], \n",
    "    'colsample_bytree' : [0.5,0.7],\n",
    "    'subsample' : [0.5,0.7],\n",
    "    'min_split_gain' : [0.01],\n",
    "    'min_data_in_leaf':[10],\n",
    "#     'metric':['auc']\n",
    "    }\n",
    "#modelling\n",
    "\n",
    "if run_autoencoder:\n",
    "    clf = lightgbm.LGBMClassifier()\n",
    "\n",
    "    if run_models:\n",
    "        random_search_model = (RandomizedSearchCV(clf, \n",
    "                                   param_dict, \n",
    "                                   verbose=1, \n",
    "                                   cv=10, \n",
    "                                   n_jobs = -1, \n",
    "                                   n_iter=10,\n",
    "                                   scoring=optimize_ppv_npv_scorer))\n",
    "            # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "        random_search_model.fit(encoded_train_imgs, Y)\n",
    "        model_dict[\"lgbm_autoencoder\"] = random_search_model\n",
    "        model_dict[\"file_params\"] = file_param_dict\n",
    "        pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "\n",
    "    model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "    lgbm_autoencoder = model_dict[\"lgbm_autoencoder\"]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_autoencoder:\n",
    "    model_results(lgbm_autoencoder, encoded_train_imgs, Y, model_name=\"lgbm_autoencoder\")\n",
    "    model_results(lgbm_autoencoder, encoded_imgs, dev_Y, model_name=\"lgbm_autoencoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Model\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/05.12-gaussian-mixtures.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(2, random_state=random_state)\n",
    "labels = kmeans.fit(X).predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(labels == Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def plot_kmeans(kmeans, X, n_clusters=4, rseed=0, ax=None):\n",
    "    labels = kmeans.fit_predict(X)\n",
    "\n",
    "    # plot the input data\n",
    "    ax = ax or plt.gca()\n",
    "    ax.axis('equal')\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)\n",
    "\n",
    "    # plot the representation of the KMeans model\n",
    "    centers = kmeans.cluster_centers_\n",
    "    radii = [cdist(X[labels == i], [center]).max()\n",
    "             for i, center in enumerate(centers)]\n",
    "    for c, r in zip(centers, radii):\n",
    "        ax.add_patch(plt.Circle(c, r, fc='#CCCCCC', lw=3, alpha=0.5, zorder=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=random_state)\n",
    "plot_kmeans(kmeans, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working because determinant of covariance matrix is 0 due to multicollinearity\n",
    "# from sklearn.mixture import GaussianMixture as GMM\n",
    "# gmm = GMM(n_components=4).fit(X)\n",
    "# labels = gmm.predict(X)\n",
    "# plt.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_knn:\n",
    "    knn = KNeighborsClassifier(n_neighbors=30)\n",
    "    X_ = X.copy()[:, :2]\n",
    "    knn.fit(X_, Y)\n",
    "    \n",
    "    model_dict[\"knn\"] = knn.best_estimator_\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "    \n",
    "    model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "    knn = model_dict[\"knn\"]  \n",
    "    model_results(knn, dev_X.copy()[:, :2], dev_Y, model_name=\"knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Second Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_knn:\n",
    "    knn = KNeighborsClassifier(n_neighbors=30)\n",
    "    X_ = X_negs.copy()[:, :2]\n",
    "    knn.fit(X_, Y_negs)\n",
    "    \n",
    "    model_dict[\"knn\"] = knn.best_estimator_\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "    \n",
    "    model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "    knn = model_dict[\"knn\"]  \n",
    "    model_results(knn, dev_X_negs.copy()[:, :2], dev_Y_negs, model_name=\"knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_svc:\n",
    "    param_dict = {'kernel': ['rbf'],\n",
    "                  'C': [1, 10, 100]}\n",
    "\n",
    "    # param_dict = {}\n",
    "\n",
    "    clf = SVC(gamma='scale', probability=True)\n",
    "    # clf.fit(X_negs, Y_negs)\n",
    "    if run_models:\n",
    "        random_search_model = (RandomizedSearchCV(clf, \n",
    "                                   param_dict, \n",
    "                                   verbose=1, \n",
    "                                   cv=10, \n",
    "                                   n_jobs = -1, \n",
    "                                   n_iter=10,\n",
    "                                   scoring='roc_auc'))\n",
    "            # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "        random_search_model.fit(X, Y)\n",
    "        model_dict[\"svc\"] = random_search_model.best_estimator_\n",
    "        model_dict[\"file_params\"] = file_param_dict\n",
    "        pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "\n",
    "    model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "    svc = model_dict[\"svc\"] \n",
    "    model_results(svc, dev_X, dev_Y, model_name=\"svc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classifier (on negative predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {'kernel': ['rbf'],\n",
    "              'C': [1, 10, 100]}\n",
    "\n",
    "# param_dict = {}\n",
    "\n",
    "if run_svc_second_level:\n",
    "    clf = SVC(gamma='scale')\n",
    "    # clf.fit(X_negs, Y_negs)\n",
    "    if run_models:\n",
    "        random_search_model = (RandomizedSearchCV(clf, \n",
    "                                   param_dict, \n",
    "                                   verbose=1, \n",
    "                                   cv=10, \n",
    "                                   n_jobs = -1, \n",
    "                                   n_iter=10,\n",
    "                                   scoring='roc_auc'))\n",
    "            # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "        random_search_model.fit(X_negs, Y_negs)\n",
    "        model_dict[\"svc_second_level\"] = random_search_model.best_estimator_\n",
    "        model_dict[\"file_params\"] = file_param_dict\n",
    "        pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "\n",
    "    model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "    svc_second_level = model_dict[\"svc_second_level\"]\n",
    "    confusion_matrix(dev_Y_negs, svc_second_level.predict(dev_X_negs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpKXfQfXzKLf"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzQrUXTW6J6b",
    "outputId": "506c9dc8-7ddd-46a3-f171-91e9993e52c9"
   },
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqOn82eq0Hsy"
   },
   "outputs": [],
   "source": [
    "\n",
    "# build a classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "param_dict = {\"C\":np.logspace(-3,3,7), \n",
    "              \"penalty\":[\"l1\", \"l2\", \"elasticnet\"],\n",
    "              \"l1_ratio\":np.linspace(0,1,10),\n",
    "              \"solver\":[\"saga\"]\n",
    "              }# l1 lasso l2 ridge\n",
    "\n",
    "# run randomized search\n",
    "if run_logistic:\n",
    "    random_search_model = RandomizedSearchCV(clf, \n",
    "                                       param_distributions=param_dict,\n",
    "                                       n_iter=20, \n",
    "                                       scoring=optimize_ppv_npv_scorer, \n",
    "                                       cv=10, \n",
    "                                       n_jobs=-1)\n",
    "\n",
    "\n",
    "    # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    random_search_model.fit(X, Y)\n",
    "    model_dict[\"lr\"] = random_search_model.best_estimator_\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYoge1Lo5Xy5",
    "outputId": "608485a4-911d-4c7f-b89b-b2ae06d5b4c8"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "    lr = model_dict[\"lr\"]\n",
    "    model_results(lr, dev_X, dev_Y, model_name=\"lr\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure if useful\n",
    "# precision, recall, thresholds = metrics.precision_recall_curve(test_Y, lr.predict_proba(test_X)[:, 1], pos_label=1)\n",
    "\n",
    "# metrics.plot_precision_recall_curve(lr, test_X, test_Y, response_method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLlnRF_s062y"
   },
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ug-A0ZPMDgZ7"
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8k3ZsgjHNjC"
   },
   "outputs": [],
   "source": [
    "# build a classifier\n",
    "clf = XGBRFClassifier()\n",
    "\n",
    "# A parameter grid for XGBoost\n",
    "# https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost\n",
    "param_dict = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n",
    "# run randomized search\n",
    "if run_models:\n",
    "    random_search_model = RandomizedSearchCV(clf, \n",
    "                                   param_distributions=param_dict,\n",
    "                                   n_iter=1, \n",
    "                                   scoring=optimize_ppv_npv_scorer, \n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1)\n",
    "\n",
    "\n",
    "    # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    random_search_model.fit(X, Y)\n",
    "    model_dict[\"xgb\"] = random_search_model.best_estimator_\n",
    "    model_dict[\"file_params\"] = file_param_dict    \n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "xgb = model_dict[\"xgb\"]\n",
    "y_predict = lr.predict(test_X) \n",
    "\n",
    "# threshold is taken as 0.5, as proven here\n",
    "# y_predict_ = 1 * (lr.predict_proba(test_X)[:, 1]>0.5) # \n",
    "# np.mean(y_predict == y_predict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(xgb, dev_X, dev_Y, model_name=\"xgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "DqyeGmeqZXnZ",
    "outputId": "36dc804f-a60b-4a0c-87dd-d4a9bc62411f"
   },
   "outputs": [],
   "source": [
    "# #Feature importance for top 50 predictors\n",
    "# predictors = [x for x in df_X_combined_dummies_ordered.columns]\n",
    "# feat_imp = pd.Series(xgb.best_estimator_.feature_importances_, predictors).sort_values(ascending=False)\n",
    "# feat_imp = feat_imp[0:50]\n",
    "# plt.rcParams['figure.figsize'] = 20, 5\n",
    "# feat_imp.plot(kind='bar', title='Feature Importance')\n",
    "# plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3RElmg55sOb"
   },
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers, meta_classifier, use_probas=False, cv=2, \n",
    "# use_features_in_secondary=False, stratify=True, shuffle=True, verbose=0, store_train_meta_features=False, use_clones=True)\n",
    "\n",
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "# xgb = model_dict[\"xgb\"]\n",
    "lgbm = model_dict[\"lgbm\"]\n",
    "# knn = model_dict[\"knn\"]\n",
    "\n",
    "try:\n",
    "    knn = model_dict[\"knn\"]\n",
    "except:\n",
    "    knn = None\n",
    "\n",
    "try:\n",
    "    svc = model_dict[\"svc\"]\n",
    "except:\n",
    "    svc = None\n",
    "\n",
    "if run_models:\n",
    "    stack_gen_model = (StackingCVClassifier(classifiers=[xgb,\n",
    "                                                         lgbm], \n",
    "                                            meta_classifier=xgb,\n",
    "                                            use_features_in_secondary=False,\n",
    "                                            use_probas=True,\n",
    "                                           random_state=random_state))\n",
    "\n",
    "    stack_gen_model.fit(X, Y)\n",
    "    model_dict[\"stacking\"] = stack_gen_model\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "    \n",
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "stacking = model_dict[\"stacking\"]\n",
    "y_predict = stacking.predict(test_X) \n",
    "y_score = stacking.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute ROC curve and ROC area for each class\n",
    "# n_classes = 2\n",
    "# fpr = dict()\n",
    "# tpr = dict()\n",
    "# roc_auc = dict()\n",
    "\n",
    "\n",
    "# fpr, tpr, _ = roc_curve(test_Y, y_score[:, 1])\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# roc_auc\n",
    "\n",
    "# # # Compute micro-average ROC curve and ROC area\n",
    "# # fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_Y.ravel(), y_score.ravel())\n",
    "# # roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# # plt.figure()\n",
    "# # lw = 2\n",
    "# # plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "# #          lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "# # plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "# # plt.xlim([0.0, 1.0])\n",
    "# # plt.ylim([0.0, 1.05])\n",
    "# # plt.xlabel('False Positive Rate')\n",
    "# # plt.ylabel('True Positive Rate')\n",
    "# # plt.title('Receiver operating characteristic example')\n",
    "# # plt.legend(loc=\"lower right\")\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(stacking, test_X, test_Y, model_name=\"stacking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Efv12Vc6ijNT"
   },
   "outputs": [],
   "source": [
    "if run_models:\n",
    "    vc_clf = (VotingClassifier(estimators=[(\"xbg\", model_dict[\"xgb\"]), \n",
    "                                           (\"lightgbm\", model_dict[\"lgbm\"]),\n",
    "                                          (\"stacking\", model_dict[\"stacking\"])],\n",
    "                                           voting=\"soft\",\n",
    "                                           flatten_transform=False))\n",
    "\n",
    "    vc_fit = vc_clf.fit(dev_X, dev_Y)\n",
    "    model_dict[\"voting_clf\"] = vc_fit\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "\n",
    "model_dict = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "voting_clf = model_dict[\"voting_clf\"]\n",
    "y_predict = voting_clf.predict(test_X) \n",
    "y_score = voting_clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(voting_clf, test_X, test_Y, model_name=\"voting_clf\")\n",
    "# find_roc_auc(vc_fit, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"ppv and npv on Test:\")\n",
    "for model in model_dict.keys():\n",
    "    if model not in [\"knn\", \"file_params\", \"lgbm_autoencoder\", \"svc_second_level\", \"lgbm_second_level\"]:\n",
    "        y_predict_proba = model_dict[model].predict_proba(test_X)[:, 1]\n",
    "        pv = ppv_npv_opt_th(test_Y, y_predict_proba)\n",
    "        print(\"{}: {}ppv = {}, npv = {} @ threshold = {}\".format(model, \" \"*(13 - len(model)), round(pv[0], 4), round(pv[1], 4), round(pv[2], 4)))\n",
    "    \n",
    "print(\"=========================================\")\n",
    "print(\"ROC_AUC on Test\")\n",
    "for model in model_dict.keys():\n",
    "    if model not in [\"knn\", \"file_params\", \"lgbm_autoencoder\", \"svc_second_level\", \"lgbm_second_level\"]:\n",
    "        y_predict = model_dict[model].predict(test_X)\n",
    "        print(\"{}:{}{}\".format(model, \" \"*(13 - len(model)), find_roc_auc(model_dict.get(model), test_X, test_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ppv and npv on Dev:\")\n",
    "for model in model_dict.keys():\n",
    "    if model not in [\"knn\", \"file_params\", \"lgbm_autoencoder\", \"svc_second_level\", \"lgbm_second_level\"]:\n",
    "        y_predict_proba = model_dict[model].predict_proba(dev_X)[:, 1]\n",
    "        pv = ppv_npv_opt_th(dev_Y, y_predict_proba)\n",
    "        print(\"{}: {}ppv = {}, npv = {} @ threshold = {}\".format(model, \" \"*(13 - len(model)), round(pv[0], 4), round(pv[1], 4), round(pv[2], 4)))\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"ROC_AUC on Dev\")\n",
    "for model in model_dict.keys():\n",
    "    if model not in [\"knn\", \"file_params\", \"lgbm_autoencoder\", \"svc_second_level\", \"lgbm_second_level\"]:\n",
    "        print(\"{}:{}{}\".format(model, \" \"*(13 - len(model)), find_roc_auc(model_dict.get(model), dev_X, dev_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ppv and npv on Train:\")\n",
    "for model in model_dict.keys():\n",
    "    if model not in [\"knn\", \"file_params\", \"lgbm_autoencoder\", \"svc_second_level\", \"lgbm_second_level\"]:\n",
    "        y_predict_proba = model_dict[model].predict_proba(X)[:, 1]\n",
    "        pv = ppv_npv_opt_th(Y, y_predict_proba)\n",
    "        print(\"{}: {}ppv = {}, npv = {} @ threshold = {}\".format(model, \" \"*(13 - len(model)), round(pv[0], 4), round(pv[1], 4), round(pv[2], 4)))\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"ROC_AUC on Training\")\n",
    "for model in model_dict.keys():\n",
    "    if model not in [\"knn\", \"file_params\", \"lgbm_autoencoder\", \"svc_second_level\", \"lgbm_second_level\"]:\n",
    "        print(\"{}:{}{}\".format(model, \" \"*(13 - len(model)), find_roc_auc(model_dict.get(model), X, Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Index\" in df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = np.array(df_test)\n",
    "model = \"lgbm\"\n",
    "y_predict = model_dict[model].predict(test_X)\n",
    "array2 = y_predict.reshape(y_predict.shape[0],1)\n",
    "array3 = np.hstack((array1, array2))\n",
    "df_pred = pd.DataFrame(array3, columns = list(df_test.columns) + [\"predictions\"])\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false negatives\n",
    "\n",
    "df_fn = df_pred[(df_pred.predictions == 0) & (df_pred.cwa_determination == 1)]\n",
    "df_fn.head()\n",
    "\n",
    "# true negatives\n",
    "\n",
    "df_tn = df_pred[(df_pred.predictions == 0) & (df_pred.cwa_determination == 0)]\n",
    "df_tn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cols = ['cwa1', 'cwa2', 'cwa3', 'cwa4', 'cwa5', 'cwa6' , 'cwa7', 'cwa8', 'cwa9', 'cwa_determination','longitude', 'latitude', 'Index','da_number',\n",
    "       'jurisdiction_type', 'potential_wetland', \"predictions\"]\n",
    "df_fn[imp_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fn.drop('geometry', axis=1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(df_fn.columns[50:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_tn.closest_wb_distance_m.mean())\n",
    "# print(df_fn.closest_wb_distance_m.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## which states have the most false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fn_tn = pd.concat([pd.DataFrame(df_fn.district).value_counts(), pd.DataFrame(df_tn.district).value_counts()], axis=1)\n",
    "df_fn_tn.columns = [\"FN\", \"TN\"]\n",
    "df_fn_tn[\"1-npv\"] = df_fn_tn.apply(lambda x: round(x.FN/(x.FN + x.TN), 2), axis=1)#.sort_values(ascending=False)\n",
    "df_fn_tn.sort_values(by=\"1-npv\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_tn.district).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_value(feature=\"closest_wb_elevation\"):\n",
    "    import scipy\n",
    "    try:\n",
    "        return (scipy.stats.ttest_ind(np.array(df_tn[feature], dtype=float), \n",
    "                           np.array(df_fn[feature], dtype=float), \n",
    "                           nan_policy='omit'))[1]\n",
    "    except Exception as e:\n",
    "#         print(e)\n",
    "        pass\n",
    "p_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df_fn.columns:\n",
    "    try:\n",
    "        if p_value(feature) < 0.0001:\n",
    "            if feature in imp_num_feature:\n",
    "                delta = (np.nanmean(np.array(df_tn[feature], dtype=float)) \n",
    "                         - np.nanmean(np.array(df_fn[feature], dtype=float)))\n",
    "                print (feature, \":\", delta)\n",
    "    except Exception as e:\n",
    "#         print(feature, \"XXXX\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df_fn.columns:\n",
    "    try:\n",
    "        if p_value(feature) < 0.001:\n",
    "            if feature in imp_num_feature:\n",
    "                delta = (np.nanmean(np.array(df_tn[feature], dtype=float)) \n",
    "                         - np.nanmean(np.array(df_fn[feature], dtype=float)))\n",
    "                print (feature, \":\", delta)\n",
    "    except Exception as e:\n",
    "#         print(feature, \"XXXX\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df_fn.columns:\n",
    "    try:\n",
    "        if p_value(feature) < 0.01:\n",
    "            if feature in imp_num_feature:\n",
    "                delta = (np.nanmean(np.array(df_tn[feature], dtype=float)) \n",
    "                         - np.nanmean(np.array(df_fn[feature], dtype=float)))\n",
    "                print (feature, \":\", delta)\n",
    "    except Exception as e:\n",
    "#         print(feature, \"XXXX\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df_fn.columns:\n",
    "    try:\n",
    "        if p_value(feature) < 0.1:\n",
    "            if feature in imp_num_feature:\n",
    "                delta = (np.nanmean(np.array(df_tn[feature], dtype=float)) \n",
    "                         - np.nanmean(np.array(df_fn[feature], dtype=float)))\n",
    "                print (feature, \":\", delta)\n",
    "    except Exception as e:\n",
    "#         print(feature, \"XXXX\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"lgbm\"\n",
    "model_results(model_dict[model], test_X, test_Y, model)\n",
    "confusion_matrix(test_Y, model_dict[model].predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_thresholding(threshold=0.5):\n",
    "    y_threshold = (model_dict[\"lgbm\"].predict_proba(test_X)[:, 1] > threshold) * 1\n",
    "    np.mean(y_threshold == test_Y)\n",
    "    print(classification_report(test_Y, y_threshold))\n",
    "    print(\"confusion matrix:\")\n",
    "    print(confusion_matrix(test_Y, y_threshold))\n",
    "do_thresholding()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_thresholding(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_thresholding(0.6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_thresholding(0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_thresholding(0.4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_thresholding(0.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_thresholding(0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_thresholding(0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_thresholding(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_pred[~df_pred.county.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df_pred.county.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred[\"count_1_pred_by_county\"] = df_pred.groupby([\"county\"])[\"predictions\"].transform(np.mean)#apply(lambda x: np.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.groupby_agg(\n",
    "#     by='item',\n",
    "#     agg='mean',\n",
    "#     agg_column_name='MRP',\n",
    "#     new_column_name='Avg_MRP'\n",
    "# )\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean(x):\n",
    "    return np.mean(x)\n",
    "\n",
    "df_pred[\"percent_1_actual\"] = df_pred.groupby(\"county\")[\"cwa_determination\"].transform(find_mean)\n",
    "df_pred[\"percent_1_predictions\"] = df_pred.groupby(\"county\")[\"predictions\"].transform(find_mean)\n",
    "df_pred[\"pred_over_actual\"] = df_pred.percent_1_predictions / (df_pred.percent_1_actual + 0.00000001)\n",
    "\n",
    "ratio_list = []\n",
    "for groupby in df_pred.groupby(\"county\"):\n",
    "    if 10000 > np.mean(np.array(groupby[1].pred_over_actual)):# > 1:\n",
    "        ratio_list.append(np.mean(np.array(groupby[1].pred_over_actual)))\n",
    "#         print(groupby[0], np.mean(np.array(groupby[1].pred_over_actual)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ratio_list, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in which counties are false positives more:\n",
    "\n",
    "for groupby in df_pred.groupby(\"county\"):\n",
    "    if 10000 > np.mean(np.array(groupby[1].pred_over_actual)) > 1:\n",
    "        print(groupby[0], np.mean(np.array(groupby[1].pred_over_actual)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in which counties are false negatives more:\n",
    "count = 0\n",
    "for groupby in df_pred.groupby(\"county\"):\n",
    "    if np.mean(np.array(groupby[1].pred_over_actual)) < 0.5:\n",
    "        count += 1\n",
    "#         print(groupby[0], np.mean(np.array(groupby[1].pred_over_actual)))\n",
    "print(count)    \n",
    "# are there 463 counties where there is no prediction of 1? out of 689 total counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_pred.groupby(\"county\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_pred.county.unique()) # 689\n",
    "len(df_pred.district.unique()) # 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look by district. These are the districts where there are no 1's being predicted\n",
    "\n",
    "def find_mean(x):\n",
    "    return np.mean(x)\n",
    "\n",
    "df_pred[\"percent_1_actual_by_district\"] = df_pred.groupby(\"district\")[\"cwa_determination\"].transform(find_mean)\n",
    "df_pred[\"percent_1_predictions_by_district\"] = df_pred.groupby(\"district\")[\"predictions\"].transform(find_mean)\n",
    "df_pred[\"pred_over_actual_by_district\"] = df_pred.percent_1_predictions / (df_pred.percent_1_actual + 0.00000001)\n",
    "\n",
    "ratio_list = []\n",
    "print(\"District           pred/act    tot_cnt    actual_1's,  pred_1's\")\n",
    "for groupby in df_pred.groupby(\"district\"):\n",
    "#     if not np.mean(np.array(groupby[1].pred_over_actual_district)):# > 1:\n",
    "    ratio_list.append(np.mean(np.array(groupby[1].pred_over_actual)))\n",
    "    (print(groupby[0], \" \" * (20 - len(groupby[0])), round(np.mean(np.array(groupby[1].pred_over_actual)), 2), \n",
    "           \" \" * (10 - len(str(round(np.mean(np.array(groupby[1].pred_over_actual)), 2)))), groupby[1].cwa_determination.shape[0], \n",
    "           \" \" * (10 - len(str(np.sum(groupby[1].cwa_determination)))), np.sum(groupby[1].cwa_determination),\n",
    "           \" \" * (10 - len(str(np.sum(groupby[1].predictions)))), np.sum(groupby[1].predictions))\n",
    "\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ratio_list, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.district == \"Albuquerque\"][[\"cwa_determination\", \"district\", \"predictions\", \"percent_1_actual\", \n",
    "                                           \"percent_1_predictions_by_district\", \"percent_1_actual_by_district\", \"percent_1_predictions_by_district\", \"pred_over_actual_by_district\"]].head(1)    #.iloc[:, 494:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.district == \"Fort Worth\"][[\"cwa_determination\", \"district\", \"predictions\", \"percent_1_actual\", \n",
    "                                           \"percent_1_predictions_by_district\", \"percent_1_actual_by_district\", \"percent_1_predictions_by_district\", \"pred_over_actual_by_district\"]].head(1)    #.iloc[:, 494:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.district == \"Huntington\"][[\"cwa_determination\", \"district\", \"predictions\", \"percent_1_actual\", \n",
    "                                           \"percent_1_predictions_by_district\", \"percent_1_actual_by_district\", \"percent_1_predictions_by_district\", \"pred_over_actual_by_district\"]].head(1)    #.iloc[:, 494:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.district == \"Louisville\"][[\"cwa_determination\", \"district\", \"predictions\", \"percent_1_actual\", \n",
    "                                           \"percent_1_predictions_by_district\", \"percent_1_actual_by_district\", \"percent_1_predictions_by_district\", \"pred_over_actual_by_district\"]].head(1)    #.iloc[:, 494:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.district == \"Nashville\"][[\"cwa_determination\", \"district\", \"predictions\", \"percent_1_actual\", \n",
    "                                           \"percent_1_predictions_by_district\", \"percent_1_actual_by_district\", \"percent_1_predictions_by_district\", \"pred_over_actual_by_district\"]].head(1)    #.iloc[:, 494:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.district == \"St. Louis\"][[\"cwa_determination\", \"district\", \"predictions\", \"percent_1_actual\", \n",
    "                                           \"percent_1_predictions_by_district\", \"percent_1_actual_by_district\", \"percent_1_predictions_by_district\", \"pred_over_actual_by_district\"]].head(1)    #.iloc[:, 494:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.district == \"Tulsa\"][[\"cwa_determination\", \"district\", \"predictions\", \"percent_1_actual\", \n",
    "                                           \"percent_1_predictions_by_district\", \"percent_1_actual_by_district\", \"percent_1_predictions_by_district\", \"pred_over_actual_by_district\"]].head(1)    #.iloc[:, 494:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.district == \"Vicksburg\"][[\"cwa_determination\", \"district\", \"predictions\", \"percent_1_actual\", \n",
    "                                           \"percent_1_predictions_by_district\", \"percent_1_actual_by_district\", \"percent_1_predictions_by_district\", \"pred_over_actual_by_district\"]].head(1)    #.iloc[:, 494:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.district == \"Walla Walla\"][[\"cwa_determination\", \"district\", \"predictions\", \"percent_1_actual\", \n",
    "                                           \"percent_1_predictions_by_district\", \"percent_1_actual_by_district\", \"percent_1_predictions_by_district\", \"pred_over_actual_by_district\"]].head(1)    #.iloc[:, 494:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred.groupby(\"county\")[\"predictions\"].apply(find_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean(df):\n",
    "    try:\n",
    "        result = df[~df.isna()].mean()\n",
    "        if not np.isnan(result):\n",
    "            return result\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "    \n",
    "def find_sum(df):\n",
    "    return np.sum(np.array(df))\n",
    "\n",
    "df_pred.groupby([\"county\"])[\"predictions\"].transform(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.county == \"Horry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotly maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fn_ = df_fn.copy()\n",
    "df_tn_ = df_tn.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false negatives\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df_fn_['longitude'], df_fn_['latitude'])]\n",
    "gdf = GeoDataFrame(df_fn_, geometry=geometry)   \n",
    "\n",
    "#this is a simple map that goes with geopandas\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "north_america = world[world.continent == \"North America\"]\n",
    "gdf.plot(ax=north_america.plot(figsize=(20, 12)), marker='o', color='red', markersize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true negatives\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df_tn_['longitude'], df_tn_['latitude'])]\n",
    "gdf = GeoDataFrame(df_tn_, geometry=geometry)   \n",
    "\n",
    "#this is a simple map that goes with geopandas\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "north_america = world[world.continent == \"North America\"]\n",
    "gdf.plot(ax=north_america.plot(figsize=(20, 12)), marker='o', color='red', markersize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not false negatives\n",
    "df_not_fn = df_pred[~((df_pred.predictions == 0) & (df_pred.cwa_determination == 1))]\n",
    "\n",
    "df_not_fn_ = df_not_fn.copy()\n",
    "geometry = [Point(xy) for xy in zip(df_not_fn_['longitude'], df_not_fn_['latitude'])]\n",
    "gdf = GeoDataFrame(df_not_fn_, geometry=geometry)   \n",
    "\n",
    "gdf.plot(ax=north_america.plot(figsize=(20, 12)), marker='o', color='red', markersize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false positives\n",
    "df_fp = df_pred[(df_pred.predictions == 1) & (df_pred.cwa_determination == 0)]\n",
    "df_fp_ = df_fp.copy()\n",
    "\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df_fp_['longitude'], df_fp_['latitude'])]\n",
    "gdf = GeoDataFrame(df_fp_, geometry=geometry)   \n",
    "\n",
    "gdf.plot(ax=north_america.plot(figsize=(20, 12)), marker='o', color='red', markersize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All good predictions\n",
    "df_good_preds = df_pred[((df_pred.predictions == 0) & (df_pred.cwa_determination == 0)) | ((df_pred.predictions == 1) & (df_pred.cwa_determination == 1))]\n",
    "\n",
    "df_good_preds_ = df_good_preds.copy()\n",
    "geometry = [Point(xy) for xy in zip(df_good_preds_['longitude'], df_good_preds_['latitude'])]\n",
    "gdf = GeoDataFrame(df_good_preds_, geometry=geometry)   \n",
    "\n",
    "gdf.plot(ax=north_america.plot(figsize=(20, 12)), marker='o', color='red', markersize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df_pred['longitude'], df_pred['latitude'])]\n",
    "gdf = GeoDataFrame(df_pred, geometry=geometry)   \n",
    "\n",
    "gdf.plot(ax=north_america.plot(figsize=(20, 12)), marker='o', color='red', markersize=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySEfwFTbEOsU"
   },
   "source": [
    "# Break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gximuif9tUZe"
   },
   "outputs": [],
   "source": [
    "df_fn[df_fn.state == '12'][\"hydclprs\"]#['da_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_fn.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJxn_V1lcnUd"
   },
   "outputs": [],
   "source": [
    "model_dict[\"file_params\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2021.03.19_WOTUS_restart_v6.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
