{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gh39s2KK_dGM"
   },
   "source": [
    "- v1: works till the categorical pipeline where it errors out for unknown variables\n",
    "- v2: fully functional\n",
    "- v3: baseline run (on the old dataset)\n",
    "- v4: baseline run (on the full 2021.03.17_full_dataset)\n",
    "- v5: baseline run (on 2021.03.19_full_dataset with all SSURGO variables)\n",
    "- v6: aoc_roc (on 2021.03.19_full_dataset with all SSURGO variables). Mute the Stacking as it is not possible with RandomizedSearchCV. Have to have a dev split.\n",
    "- v7: model v7 random state 123 on train/test, model v7.1 random_state 431 on train/dev/test\n",
    "- v8g: Golden model\n",
    "\n",
    "ROC_AUC with lat, lon\n",
    "====================\n",
    "lr:           0.64103\n",
    "xgb:          0.82366\n",
    "voting_clf:   0.83027\n",
    "lgbm:         0.86395\n",
    "stacking:     0.85923\n",
    "\n",
    "\n",
    "- v9: without lat, lon\n",
    "\n",
    "ROC_AUC without lat, lon\n",
    "=======================\n",
    "lr:           0.64211\n",
    "xgb:          0.8031\n",
    "voting_clf:   0.83105\n",
    "lgbm:         0.85952\n",
    "stacking:     0.85427\n",
    "\n",
    "- v9.1: without lat, lon, potential_wetland\n",
    "\n",
    "ROC_AUC without lat, lon, potential_wetland\n",
    "===============\n",
    "lr:           0.63992\n",
    "xgb:          0.79093\n",
    "voting_clf:   0.82987\n",
    "lgbm:         0.85143\n",
    "stacking:     0.84328\n",
    "\n",
    "- v9.2: without lat, lon, potential_wetland, district\n",
    "\n",
    "ROC_AUC without lat, lon, potential_wetland, district\n",
    "===============\n",
    "lr:           0.64208\n",
    "xgb:          0.77907\n",
    "voting_clf:   0.79829\n",
    "lgbm:         0.82675\n",
    "stacking:     0.82185\n",
    "\n",
    "- v9.3: with lat, lon, potential_wetland but flodfreqdc and drclassdcd as ordinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "file_param_dict = {}\n",
    "golden_models = [\"v8g\"]\n",
    "\n",
    "# file params\n",
    "stop_before_models = False\n",
    "random_state = 123 # for train, dev, test splits\n",
    "dev = True\n",
    "\n",
    "FILE_VERSION = \"v9.3\"\n",
    "run_models = True # BEWARE! This overwrites the models stored on disk\n",
    "run_logistic = True\n",
    "\n",
    "if FILE_VERSION in golden_models:\n",
    "    if run_models:\n",
    "        turn_off_run_models\n",
    "\n",
    "file_param_dict[\"random_state\"] = random_state\n",
    "file_param_dict[\"dev\"] = dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wj4LjNpHOzc9",
    "outputId": "6b01c399-d6fc-46c6-f622-ac200674afb8"
   },
   "outputs": [],
   "source": [
    "# !pip install lightgbm\n",
    "# !pip install xgboost\n",
    "# !pip install mlxtend\n",
    "# !pip install seaborn\n",
    "# import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "id": "y6CJ-2pyO-Pu"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# SK-learn libraries for machine learning\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import *\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import xgboost\n",
    "import lightgbm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "id": "1q95q-9wPEky"
   },
   "outputs": [],
   "source": [
    "df_full = pd.read_pickle(\"2021.03.20_full_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "flod_ordered = [\"None\", \"Very rare\", \"Rare\", \"Occasional\", \"Frequent\", \"Very frequent\"]\n",
    "flod_dict = dict(zip(flod_ordered, range(len(flod_ordered))))\n",
    "\n",
    "def flodfreqdc_ordinal(string):\n",
    "    try:\n",
    "        return flod_dict[string]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "df_full[\"flodfreqdc\"] = df_full.apply(lambda x: flodfreqdc_ordinal(x.flodfreqdc), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "drclassdcd_ordered = [\"Excessively drained\", \"Somewhat excessively drained\", \"Well drained\", \n",
    "\"Moderately well drained\", \"Somewhat poorly drained\", \"Poorly drained\", \"Very poorly drained\", \"Subaqueous\"]\n",
    "\n",
    "drclassdcd_dict = dict(zip(drclassdcd_ordered, range(len(drclassdcd_ordered))))\n",
    "\n",
    "def drclassdcd_ordinal(string):\n",
    "    try:\n",
    "        return drclassdcd_dict[string]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "df_full[\"drclassdcd\"] = df_full.apply(lambda x: drclassdcd_ordinal(x.drclassdcd), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "id": "vmXibdpmoSgz"
   },
   "outputs": [],
   "source": [
    "# df_full = df_full[df_full.district != \"Alaska\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0iIGqq0DlEz",
    "outputId": "4f42a088-639b-4bf6-84a5-c8a8deefa4a7"
   },
   "outputs": [],
   "source": [
    "# set(df_full.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V4OSS7EfFWLD",
    "outputId": "5cba5f6a-118e-4979-8194-000e45123b90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%good records = 98.0%\n"
     ]
    }
   ],
   "source": [
    "# any records where the cwa_determination is contrary to expectations?\n",
    "good_records = (df_full.apply(lambda x: \n",
    "               (np.sum(x.cwa1 + x.cwa2 + x.cwa3 + x.cwa4 + x.cwa5 + \n",
    "                       x.cwa6 + x.cwa7 + x.cwa8 + x.cwa9) > 0) * 1 \n",
    "               == x.cwa_determination, \n",
    "               axis=1))\n",
    "\n",
    "print(\"%good records = {}%\".format(round(np.mean(good_records) * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "MUI--cUNFmXp",
    "outputId": "08a07e58-d2a0-4ead-c85a-7e9edbf94883"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cwa4</th>\n",
       "      <th>cwa8</th>\n",
       "      <th>cwa7</th>\n",
       "      <th>cwa_determination</th>\n",
       "      <th>cwa5</th>\n",
       "      <th>longitude</th>\n",
       "      <th>cwa3</th>\n",
       "      <th>date_issued_or_denied</th>\n",
       "      <th>latitude</th>\n",
       "      <th>Index</th>\n",
       "      <th>...</th>\n",
       "      <th>nwi_SUBCLASS_NAME_non_persistent_2500m</th>\n",
       "      <th>nwi_SPLIT_SUBCLASS_NAME_lichen_2500m</th>\n",
       "      <th>nwi_WATER_REGIME_NAME_zzz_2500m</th>\n",
       "      <th>nwi_WATER_REGIME_NAME_permanently_flooded_2500m</th>\n",
       "      <th>nwi_SPLIT_CLASS_NAME_emergent_2500m</th>\n",
       "      <th>nwi_WATER_REGIME_SUBGROUP_zzz_2500m</th>\n",
       "      <th>nwi_WATER_REGIME_SUBGROUP_freshwater_tidal_2500m</th>\n",
       "      <th>nwi_CLASS_NAME_rocky_shore_2500m</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-77.58614</td>\n",
       "      <td>0</td>\n",
       "      <td>02/14/2017</td>\n",
       "      <td>43.10595</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Monroe</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-78.89428</td>\n",
       "      <td>0</td>\n",
       "      <td>03/14/2018</td>\n",
       "      <td>43.19710</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Niagara</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-78.98265</td>\n",
       "      <td>0</td>\n",
       "      <td>07/12/2017</td>\n",
       "      <td>43.13072</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Niagara</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 486 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cwa4  cwa8  cwa7  cwa_determination  cwa5  longitude  cwa3  \\\n",
       "36     0     0     0                  1     0  -77.58614     0   \n",
       "50     0     0     0                  1     0  -78.89428     0   \n",
       "56     0     0     0                  1     0  -78.98265     0   \n",
       "\n",
       "   date_issued_or_denied  latitude  Index  ...  \\\n",
       "36            02/14/2017  43.10595     37  ...   \n",
       "50            03/14/2018  43.19710     51  ...   \n",
       "56            07/12/2017  43.13072     57  ...   \n",
       "\n",
       "    nwi_SUBCLASS_NAME_non_persistent_2500m  \\\n",
       "36                                       0   \n",
       "50                                       0   \n",
       "56                                       0   \n",
       "\n",
       "   nwi_SPLIT_SUBCLASS_NAME_lichen_2500m nwi_WATER_REGIME_NAME_zzz_2500m  \\\n",
       "36                                    0                               0   \n",
       "50                                    0                              14   \n",
       "56                                    0                               0   \n",
       "\n",
       "    nwi_WATER_REGIME_NAME_permanently_flooded_2500m  \\\n",
       "36                                               19   \n",
       "50                                               10   \n",
       "56                                                5   \n",
       "\n",
       "    nwi_SPLIT_CLASS_NAME_emergent_2500m  nwi_WATER_REGIME_SUBGROUP_zzz_2500m  \\\n",
       "36                                    0                                    0   \n",
       "50                                    0                                    0   \n",
       "56                                    0                                    0   \n",
       "\n",
       "    nwi_WATER_REGIME_SUBGROUP_freshwater_tidal_2500m  \\\n",
       "36                                                 0   \n",
       "50                                                 0   \n",
       "56                                                 0   \n",
       "\n",
       "    nwi_CLASS_NAME_rocky_shore_2500m   county  state  \n",
       "36                                 0   Monroe     36  \n",
       "50                                 0  Niagara     36  \n",
       "56                                 0  Niagara     36  \n",
       "\n",
       "[3 rows x 486 columns]"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek at not good records\n",
    "df_full[~good_records].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wS52NjAa4kE_"
   },
   "source": [
    "# Train-Dev-Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "id": "Tc_mmRYBKxU6"
   },
   "outputs": [],
   "source": [
    "# filter out the bad records\n",
    "\n",
    "df_full = df_full[good_records]\n",
    "\n",
    "if dev:\n",
    "    df, df_test = train_test_split(df_full, test_size=0.2, random_state = random_state) # 20% test\n",
    "    df, df_dev = train_test_split(df, test_size=0.25, random_state = random_state) # 60% train, 20% dev\n",
    "else:\n",
    "    df, df_test = train_test_split(df_full, test_size=0.2, random_state = random_state) # 80% train, 20% test\n",
    "    df_dev = df_test.copy()\n",
    "    \n",
    "# df, df_test = train_test_split(df_full, test_size=0.95, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bODkeQCDPr24"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Zs23ZZxPtnN"
   },
   "source": [
    "### Remove cols with all NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "id": "vBwbLX6YPwT_"
   },
   "outputs": [],
   "source": [
    "nan_cols = []\n",
    "for col in df.columns:\n",
    "  nan_frac = np.mean(df[str(col)].isna())\n",
    "  if nan_frac == 1:\n",
    "    nan_cols.append(col)\n",
    "nan_cols\n",
    "df.drop(nan_cols, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxWXqayaFhXp",
    "outputId": "52c2ceb0-fc0c-49ce-8fb4-4050e7c7f778"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"county\" in df_full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlZ2nLgVPOn1"
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xlE_M1C2PIgp",
    "outputId": "af65405c-4220-4fe4-c5b9-c922d395bfde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cwa4\n",
      "1 cwa8\n",
      "2 cwa7\n",
      "3 cwa_determination\n",
      "4 cwa5\n",
      "5 longitude\n",
      "6 cwa3\n",
      "7 latitude\n",
      "8 Index\n",
      "9 cwa1\n",
      "10 rha_determination\n",
      "11 cwa9\n",
      "12 cwa2\n",
      "13 rha2\n",
      "14 potential_wetland\n",
      "15 cwa6\n",
      "16 rha1\n",
      "17 mukey\n",
      "18 wtdepaprju\n",
      "19 iccdcd\n",
      "20 aws0150wta\n",
      "21 brockdepmi\n",
      "22 iccdcdpct\n",
      "23 hydclprs\n",
      "24 aws050wta\n",
      "25 flodfreqdc\n",
      "26 pondfreqpr\n",
      "27 niccdcd\n",
      "28 awmmfpwwta\n",
      "29 aws0100wta\n",
      "30 slopegradw\n",
      "31 slopegradd\n",
      "32 drclassdcd\n",
      "33 aws025wta\n",
      "34 urbrecptwt\n",
      "35 niccdcdpct\n",
      "36 wtdepannmi\n",
      "37 slope_stdev_200m\n",
      "38 transition_8_200m\n",
      "39 seasonality_mean_200m\n",
      "40 transition_0_200m\n",
      "41 recurrence_min_200m\n",
      "42 elevation_min_200m\n",
      "43 seasonality_min_200m\n",
      "44 transition_2_200m\n",
      "45 slope_min_200m\n",
      "46 transition_3_200m\n",
      "47 seasonality_stdev_200m\n",
      "48 slope_mean_200m\n",
      "49 recurrence_mean_200m\n",
      "50 transition_5_200m\n",
      "51 transition_7_200m\n",
      "52 elevation_mean_200m\n",
      "53 slope_max_200m\n",
      "54 elevation_max_200m\n",
      "55 seasonality_max_200m\n",
      "56 transition_6_200m\n",
      "57 transition_4_200m\n",
      "58 elevation_stdev_200m\n",
      "59 transition_1_200m\n",
      "60 recurrence_max_200m\n",
      "61 recurrence_stdev_200m\n",
      "62 transition_9_200m\n",
      "63 fl_totdasqkm_sum_200m\n",
      "64 fl_gnis_name_ind_mean_200m\n",
      "65 fl_ftype_streamriver_200m\n",
      "66 fl_ftype_connector_200m\n",
      "67 fl_intephem_count_200m\n",
      "68 fl_startflag_mean_200m\n",
      "69 fl_divergence_sum_200m\n",
      "70 fl_ftype_coastline_200m\n",
      "71 fl_startflag_sum_200m\n",
      "72 fl_divergence_count_200m\n",
      "73 fl_streamorde_sum_200m\n",
      "74 fl_divergence_mean_200m\n",
      "75 fl_ftype_artificialpath_200m\n",
      "76 fl_length_sum_200m\n",
      "77 wb_ftype_coastline_200m\n",
      "78 fl_streamorde_mean_200m\n",
      "79 fl_length_mean_200m\n",
      "80 fl_intephem_mean_200m\n",
      "81 fl_flow_type_sum_200m\n",
      "82 fl_flow_type_count_200m\n",
      "83 wb_ftype_artificialpath_200m\n",
      "84 wb_gnis_name_ind_sum_200m\n",
      "85 wb_ftype_streamriver_200m\n",
      "86 wb_area_sum_200m\n",
      "87 fl_areasqkm_mean_200m\n",
      "88 fl_totdasqkm_mean_200m\n",
      "89 wb_ftype_canalditch_200m\n",
      "90 fl_flow_type_mean_200m\n",
      "91 fl_length_count_200m\n",
      "92 fl_areasqkm_sum_200m\n",
      "93 wb_gnis_name_ind_count_200m\n",
      "94 fl_intephem_sum_200m\n",
      "95 fl_areasqkm_count_200m\n",
      "96 wb_ftype_connector_200m\n",
      "97 fl_gnis_name_ind_sum_200m\n",
      "98 wb_area_count_200m\n",
      "99 fl_totdasqkm_count_200m\n",
      "100 wb_gnis_name_ind_mean_200m\n",
      "101 wb_ftype_pipeline_200m\n",
      "102 fl_startflag_count_200m\n",
      "103 wb_area_mean_200m\n",
      "104 fl_ftype_canalditch_200m\n",
      "105 fl_ftype_pipeline_200m\n",
      "106 fl_streamorde_count_200m\n",
      "107 fl_gnis_name_ind_count_200m\n",
      "108 nwi_SUBCLASS_NAME_cobble-gravel_200m\n",
      "109 nwi_CLASS_NAME_emergent_200m\n",
      "110 nwi_SUBCLASS_NAME_floating_vascular_200m\n",
      "111 nwi_SUBCLASS_NAME_sand_200m\n",
      "112 nwi_FIRST_MODIFIER_NAME_mesohaline_200m\n",
      "113 nwi_SPLIT_SUBCLASS_NAME_needle-leaved_evergreen_200m\n",
      "114 nwi_FIRST_MODIFIER_NAME_mixohaline/mixosaline_(brackish)_200m\n",
      "115 nwi_CLASS_NAME_moss-lichen_200m\n",
      "116 nwi_SUBCLASS_NAME_dead_200m\n",
      "117 nwi_FIRST_MODIFIER_NAME_diked/impounded_200m\n",
      "118 nwi_FIRST_MODIFIER_NAME_spoil_200m\n",
      "119 nwi_FIRST_MODIFIER_NAME_oligohaline_200m\n",
      "120 nwi_SUBCLASS_NAME_algal_200m\n",
      "121 nwi_SPLIT_CLASS_NAME_emergent_200m\n",
      "122 nwi_riverine_200m\n",
      "123 nwi_SUBSYSTEM_NAME_upper_perennial_200m\n",
      "124 nwi_SUBCLASS_NAME_broad-leaved_deciduous_200m\n",
      "125 nwi_CLASS_NAME_zzz_200m\n",
      "126 nwi_SPLIT_SUBCLASS_NAME_sand_200m\n",
      "127 nwi_SPLIT_CLASS_NAME_unconsolidated_bottom_200m\n",
      "128 nwi_WATER_REGIME_NAME_irregularly_flooded_200m\n",
      "129 nwi_SUBCLASS_NAME_needle-leaved_deciduous_200m\n",
      "130 nwi_SUBCLASS_NAME_rooted_vascular_200m\n",
      "131 nwi_FIRST_MODIFIER_NAME_farmed_200m\n",
      "132 nwi_estuarine_and_marine_wetland_200m\n",
      "133 nwi_WATER_REGIME_NAME_irregularly_exposed_200m\n",
      "134 nwi_SUBCLASS_NAME_persistent_200m\n",
      "135 nwi_FIRST_MODIFIER_NAME_partially_drained/ditched_200m\n",
      "136 nwi_CLASS_NAME_unconsolidated_shore_200m\n",
      "137 nwi_WATER_REGIME_NAME_continuously__saturated_200m\n",
      "138 nwi_SYSTEM_NAME_estuarine_200m\n",
      "139 nwi_FIRST_MODIFIER_NAME_zzz_200m\n",
      "140 nwi_FIRST_MODIFIER_NAME_managed_200m\n",
      "141 nwi_FIRST_MODIFIER_NAME_mineral_200m\n",
      "142 nwi_SPLIT_SUBCLASS_NAME_zzz_200m\n",
      "143 nwi_SUBSYSTEM_NAME_tidal_200m\n",
      "144 nwi_SUBCLASS_NAME_aquatic_moss_200m\n",
      "145 nwi_SPLIT_SUBCLASS_NAME_organic_200m\n",
      "146 nwi_WATER_REGIME_NAME_seasonally_flooded_200m\n",
      "147 nwi_other_200m\n",
      "148 nwi_SPLIT_SUBCLASS_NAME_rubble_200m\n",
      "149 nwi_WATER_REGIME_NAME_zzz_200m\n",
      "150 nwi_WATER_REGIME_SUBGROUP_zzz_200m\n",
      "151 nwi_SYSTEM_NAME_lacustrine_200m\n",
      "152 nwi_SPLIT_CLASS_NAME_rocky_shore_200m\n",
      "153 nwi_WATER_REGIME_NAME_artificially_flooded_200m\n",
      "154 nwi_SPLIT_SUBCLASS_NAME_evergreen_200m\n",
      "155 nwi_SUBCLASS_NAME_non_persistent_200m\n",
      "156 nwi_WATER_REGIME_NAME_intermittently_flooded_200m\n",
      "157 nwi_SPLIT_SUBCLASS_NAME_phragmites_australis_200m\n",
      "158 nwi_SPLIT_SUBCLASS_NAME_broad-leaved_deciduous_200m\n",
      "159 nwi_WATER_REGIME_NAME_seasonally_flooded-tidal_200m\n",
      "160 nwi_SPLIT_SUBCLASS_NAME_persistent_200m\n",
      "161 nwi_SUBSYSTEM_NAME_littoral_200m\n",
      "162 nwi_SPLIT_CLASS_NAME_unconsolidated_shore_200m\n",
      "163 nwi_CLASS_NAME_reef_200m\n",
      "164 nwi_SPLIT_SUBCLASS_NAME_aquatic_moss_200m\n",
      "165 nwi_SYSTEM_NAME_palustrine_200m\n",
      "166 nwi_lake_200m\n",
      "167 nwi_SPLIT_SUBCLASS_NAME_algal_200m\n",
      "168 nwi_WATER_REGIME_SUBGROUP_saltwater_tidal_200m\n",
      "169 nwi_SYSTEM_NAME_riverine_200m\n",
      "170 nwi_SPLIT_SUBCLASS_NAME_moss_200m\n",
      "171 nwi_SUBCLASS_NAME_phragmites_australis_200m\n",
      "172 nwi_SPLIT_SUBCLASS_NAME_rooted_vascular_200m\n",
      "173 nwi_WATER_REGIME_NAME_seasonally_saturated_200m\n",
      "174 nwi_estuarine_and_marine_deepwater_200m\n",
      "175 nwi_WATER_REGIME_SUBGROUP_freshwater_tidal_200m\n",
      "176 nwi_SPLIT_SUBCLASS_NAME_deciduous_200m\n",
      "177 nwi_WATER_REGIME_NAME_temporary_flooded_200m\n",
      "178 nwi_WATER_REGIME_NAME_subtidal_200m\n",
      "179 nwi_SPLIT_CLASS_NAME_forested_200m\n",
      "180 nwi_WATER_REGIME_NAME_semipermanently_flooded_200m\n",
      "181 nwi_SUBSYSTEM_NAME_lower_perennial_200m\n",
      "182 nwi_SUBCLASS_NAME_rubble_200m\n",
      "183 nwi_feature_count_200m\n",
      "184 nwi_FIRST_MODIFIER_NAME_beaver_200m\n",
      "185 nwi_SUBCLASS_NAME_evergreen_200m\n",
      "186 nwi_SUBSYSTEM_NAME_subtidal_200m\n",
      "187 nwi_SPLIT_SUBCLASS_NAME_broad-leaved_evergreen_200m\n",
      "188 nwi_SUBCLASS_NAME_bedrock_200m\n",
      "189 nwi_SPLIT_SUBCLASS_NAME_dead_200m\n",
      "190 nwi_WATER_REGIME_NAME_temporary_flooded-tidal_200m\n",
      "191 nwi_CLASS_NAME_unconsolidated_bottom_200m\n",
      "192 nwi_SUBCLASS_NAME_needle-leaved_evergreen_200m\n",
      "193 nwi_CLASS_NAME_streambed_200m\n",
      "194 nwi_WATER_REGIME_NAME_semipermanently_flooded-tidal_200m\n",
      "195 nwi_SPLIT_SUBCLASS_NAME_bedrock_200m\n",
      "196 nwi_SUBSYSTEM_NAME_limnetic_200m\n",
      "197 nwi_WATER_REGIME_NAME_permanently_flooded_200m\n",
      "198 nwi_FIRST_MODIFIER_NAME_alkaline_200m\n",
      "199 nwi_FIRST_MODIFIER_NAME_organic_200m\n",
      "200 nwi_SPLIT_SUBCLASS_NAME_lichen_200m\n",
      "201 nwi_SUBCLASS_NAME_coral_200m\n",
      "202 nwi_freshwater_forested_200m\n",
      "203 nwi_shrub_wetland_200m\n",
      "204 nwi_CLASS_NAME_rock_bottom_200m\n",
      "205 nwi_SUBSYSTEM_NAME_unknown_perennial_200m\n",
      "206 nwi_SUBCLASS_NAME_vegetated_200m\n",
      "207 nwi_SPLIT_CLASS_NAME_moss-lichen_200m\n",
      "208 nwi_CLASS_NAME_aquatic_bed_200m\n",
      "209 nwi_WATER_REGIME_NAME_permanently_flooded-tidal_200m\n",
      "210 nwi_CLASS_NAME_scrub-shrub_200m\n",
      "211 nwi_WATER_REGIME_NAME_regularly_flooded_200m\n",
      "212 nwi_SPLIT_CLASS_NAME_reef_200m\n",
      "213 nwi_SPLIT_CLASS_NAME_aquatic_bed_200m\n",
      "214 nwi_WATER_REGIME_SUBGROUP_nontidal_200m\n",
      "215 nwi_FIRST_MODIFIER_NAME_acid_200m\n",
      "216 nwi_SUBCLASS_NAME_broad-leaved_evergreen_200m\n",
      "217 nwi_SUBCLASS_NAME_zzz_200m\n",
      "218 nwi_SUBCLASS_NAME_mud_200m\n",
      "219 nwi_SPLIT_SUBCLASS_NAME_non_persistent_200m\n",
      "220 nwi_FIRST_MODIFIER_NAME_artificial_substrate_200m\n",
      "221 nwi_CLASS_NAME_rocky_shore_200m\n",
      "222 nwi_SPLIT_SUBCLASS_NAME_cobble-gravel_200m\n",
      "223 nwi_SPLIT_SUBCLASS_NAME_floating_vascular_200m\n",
      "224 nwi_SYSTEM_NAME_marine_200m\n",
      "225 nwi_SPLIT_CLASS_NAME_zzz_200m\n",
      "226 nwi_SUBCLASS_NAME_deciduous_200m\n",
      "227 nwi_SPLIT_SUBCLASS_NAME_coral_200m\n",
      "228 nwi_freshwater_emergent_wetland_200m\n",
      "229 nwi_CLASS_NAME_forested_200m\n",
      "230 nwi_SUBCLASS_NAME_moss_200m\n",
      "231 nwi_SPLIT_SUBCLASS_NAME_needle-leaved_deciduous_200m\n",
      "232 nwi_FIRST_MODIFIER_NAME_polyhaline_200m\n",
      "233 nwi_WATER_REGIME_NAME_intermittently_exposed_200m\n",
      "234 nwi_SUBCLASS_NAME_mollusk_200m\n",
      "235 nwi_FIRST_MODIFIER_NAME_excavated_200m\n",
      "236 nwi_SUBCLASS_NAME_lichen_200m\n",
      "237 nwi_SPLIT_SUBCLASS_NAME_mollusk_200m\n",
      "238 nwi_SPLIT_SUBCLASS_NAME_mud_200m\n",
      "239 nwi_FIRST_MODIFIER_NAME_euthaline/eusaline_200m\n",
      "240 nwi_FIRST_MODIFIER_NAME_hyperhaline/hypersaline_200m\n",
      "241 nwi_SUBSYSTEM_NAME_intertidal_200m\n",
      "242 nwi_freshwater_pond_200m\n",
      "243 nwi_SUBSYSTEM_NAME_intermittent_200m\n",
      "244 nwi_SPLIT_SUBCLASS_NAME_vegetated_200m\n",
      "245 nwi_WATER_REGIME_NAME_seasonally_flooded/saturated_200m\n",
      "246 nwi_SPLIT_CLASS_NAME_scrub-shrub_200m\n",
      "247 nwi_SUBCLASS_NAME_organic_200m\n",
      "248 transition_2_2500m\n",
      "249 recurrence_stdev_2500m\n",
      "250 seasonality_max_2500m\n",
      "251 recurrence_min_2500m\n",
      "252 transition_9_2500m\n",
      "253 elevation_mean_2500m\n",
      "254 transition_6_2500m\n",
      "255 slope_stdev_2500m\n",
      "256 slope_min_2500m\n",
      "257 slope_mean_2500m\n",
      "258 transition_1_2500m\n",
      "259 slope_max_2500m\n",
      "260 seasonality_stdev_2500m\n",
      "261 elevation_stdev_2500m\n",
      "262 transition_0_2500m\n",
      "263 seasonality_mean_2500m\n",
      "264 seasonality_min_2500m\n",
      "265 transition_4_2500m\n",
      "266 transition_7_2500m\n",
      "267 elevation_max_2500m\n",
      "268 elevation_min_2500m\n",
      "269 recurrence_mean_2500m\n",
      "270 transition_5_2500m\n",
      "271 transition_3_2500m\n",
      "272 recurrence_max_2500m\n",
      "273 transition_8_2500m\n",
      "274 fl_length_count_2500m\n",
      "275 fl_startflag_count_2500m\n",
      "276 wb_ftype_streamriver_2500m\n",
      "277 wb_area_count_2500m\n",
      "278 wb_area_mean_2500m\n",
      "279 fl_flow_type_mean_2500m\n",
      "280 fl_gnis_name_ind_count_2500m\n",
      "281 fl_totdasqkm_mean_2500m\n",
      "282 fl_divergence_sum_2500m\n",
      "283 fl_ftype_coastline_2500m\n",
      "284 fl_ftype_connector_2500m\n",
      "285 wb_area_sum_2500m\n",
      "286 fl_startflag_mean_2500m\n",
      "287 wb_gnis_name_ind_mean_2500m\n",
      "288 fl_flow_type_count_2500m\n",
      "289 wb_gnis_name_ind_sum_2500m\n",
      "290 wb_gnis_name_ind_count_2500m\n",
      "291 wb_ftype_canalditch_2500m\n",
      "292 wb_ftype_connector_2500m\n",
      "293 fl_ftype_pipeline_2500m\n",
      "294 fl_totdasqkm_count_2500m\n",
      "295 fl_ftype_streamriver_2500m\n",
      "296 fl_divergence_count_2500m\n",
      "297 fl_intephem_count_2500m\n",
      "298 wb_ftype_coastline_2500m\n",
      "299 fl_streamorde_count_2500m\n",
      "300 fl_streamorde_sum_2500m\n",
      "301 fl_totdasqkm_sum_2500m\n",
      "302 fl_areasqkm_sum_2500m\n",
      "303 fl_length_sum_2500m\n",
      "304 fl_areasqkm_mean_2500m\n",
      "305 wb_ftype_pipeline_2500m\n",
      "306 fl_flow_type_sum_2500m\n",
      "307 fl_gnis_name_ind_sum_2500m\n",
      "308 fl_intephem_mean_2500m\n",
      "309 fl_length_mean_2500m\n",
      "310 fl_ftype_artificialpath_2500m\n",
      "311 fl_intephem_sum_2500m\n",
      "312 fl_ftype_canalditch_2500m\n",
      "313 fl_areasqkm_count_2500m\n",
      "314 fl_startflag_sum_2500m\n",
      "315 fl_divergence_mean_2500m\n",
      "316 fl_streamorde_mean_2500m\n",
      "317 fl_gnis_name_ind_mean_2500m\n",
      "318 wb_ftype_artificialpath_2500m\n",
      "319 nwi_SYSTEM_NAME_lacustrine_2500m\n",
      "320 nwi_SUBCLASS_NAME_rooted_vascular_2500m\n",
      "321 nwi_SPLIT_CLASS_NAME_forested_2500m\n",
      "322 nwi_WATER_REGIME_NAME_temporary_flooded_2500m\n",
      "323 nwi_WATER_REGIME_NAME_semipermanently_flooded_2500m\n",
      "324 nwi_CLASS_NAME_streambed_2500m\n",
      "325 nwi_SPLIT_SUBCLASS_NAME_non_persistent_2500m\n",
      "326 nwi_SUBCLASS_NAME_aquatic_moss_2500m\n",
      "327 nwi_FIRST_MODIFIER_NAME_managed_2500m\n",
      "328 nwi_FIRST_MODIFIER_NAME_mesohaline_2500m\n",
      "329 nwi_WATER_REGIME_NAME_irregularly_flooded_2500m\n",
      "330 nwi_SPLIT_SUBCLASS_NAME_algal_2500m\n",
      "331 nwi_SPLIT_CLASS_NAME_rocky_shore_2500m\n",
      "332 nwi_SPLIT_SUBCLASS_NAME_broad-leaved_evergreen_2500m\n",
      "333 nwi_SPLIT_SUBCLASS_NAME_bedrock_2500m\n",
      "334 nwi_CLASS_NAME_zzz_2500m\n",
      "335 nwi_SUBCLASS_NAME_bedrock_2500m\n",
      "336 nwi_SPLIT_SUBCLASS_NAME_broad-leaved_deciduous_2500m\n",
      "337 nwi_FIRST_MODIFIER_NAME_beaver_2500m\n",
      "338 nwi_WATER_REGIME_NAME_permanently_flooded-tidal_2500m\n",
      "339 nwi_SUBCLASS_NAME_phragmites_australis_2500m\n",
      "340 nwi_freshwater_pond_2500m\n",
      "341 nwi_SPLIT_SUBCLASS_NAME_mud_2500m\n",
      "342 nwi_SUBSYSTEM_NAME_upper_perennial_2500m\n",
      "343 nwi_SPLIT_SUBCLASS_NAME_mollusk_2500m\n",
      "344 nwi_CLASS_NAME_moss-lichen_2500m\n",
      "345 nwi_SUBCLASS_NAME_rubble_2500m\n",
      "346 nwi_SUBCLASS_NAME_mud_2500m\n",
      "347 nwi_SUBCLASS_NAME_broad-leaved_deciduous_2500m\n",
      "348 nwi_SPLIT_SUBCLASS_NAME_needle-leaved_deciduous_2500m\n",
      "349 nwi_WATER_REGIME_NAME_seasonally_flooded-tidal_2500m\n",
      "350 nwi_SYSTEM_NAME_riverine_2500m\n",
      "351 nwi_SUBSYSTEM_NAME_limnetic_2500m\n",
      "352 nwi_SPLIT_SUBCLASS_NAME_evergreen_2500m\n",
      "353 nwi_FIRST_MODIFIER_NAME_mixohaline/mixosaline_(brackish)_2500m\n",
      "354 nwi_SPLIT_SUBCLASS_NAME_deciduous_2500m\n",
      "355 nwi_CLASS_NAME_aquatic_bed_2500m\n",
      "356 nwi_SUBCLASS_NAME_deciduous_2500m\n",
      "357 nwi_CLASS_NAME_reef_2500m\n",
      "358 nwi_SUBCLASS_NAME_sand_2500m\n",
      "359 nwi_other_2500m\n",
      "360 nwi_SUBSYSTEM_NAME_intermittent_2500m\n",
      "361 nwi_SPLIT_CLASS_NAME_unconsolidated_shore_2500m\n",
      "362 nwi_SUBSYSTEM_NAME_littoral_2500m\n",
      "363 nwi_riverine_2500m\n",
      "364 nwi_SUBCLASS_NAME_moss_2500m\n",
      "365 nwi_SUBCLASS_NAME_needle-leaved_deciduous_2500m\n",
      "366 nwi_WATER_REGIME_NAME_seasonally_flooded/saturated_2500m\n",
      "367 nwi_SPLIT_SUBCLASS_NAME_vegetated_2500m\n",
      "368 nwi_SPLIT_SUBCLASS_NAME_sand_2500m\n",
      "369 nwi_SUBSYSTEM_NAME_subtidal_2500m\n",
      "370 nwi_CLASS_NAME_rock_bottom_2500m\n",
      "371 nwi_FIRST_MODIFIER_NAME_euthaline/eusaline_2500m\n",
      "372 nwi_WATER_REGIME_NAME_semipermanently_flooded-tidal_2500m\n",
      "373 nwi_SPLIT_SUBCLASS_NAME_coral_2500m\n",
      "374 nwi_FIRST_MODIFIER_NAME_excavated_2500m\n",
      "375 nwi_SUBSYSTEM_NAME_intertidal_2500m\n",
      "376 nwi_freshwater_forested_2500m\n",
      "377 nwi_SUBCLASS_NAME_needle-leaved_evergreen_2500m\n",
      "378 nwi_FIRST_MODIFIER_NAME_organic_2500m\n",
      "379 nwi_SUBSYSTEM_NAME_tidal_2500m\n",
      "380 nwi_SPLIT_CLASS_NAME_moss-lichen_2500m\n",
      "381 nwi_SPLIT_CLASS_NAME_reef_2500m\n",
      "382 nwi_SPLIT_SUBCLASS_NAME_rooted_vascular_2500m\n",
      "383 nwi_SUBCLASS_NAME_vegetated_2500m\n",
      "384 nwi_WATER_REGIME_SUBGROUP_saltwater_tidal_2500m\n",
      "385 nwi_SUBCLASS_NAME_coral_2500m\n",
      "386 nwi_SUBCLASS_NAME_dead_2500m\n",
      "387 nwi_SPLIT_SUBCLASS_NAME_organic_2500m\n",
      "388 nwi_SUBCLASS_NAME_lichen_2500m\n",
      "389 nwi_SPLIT_SUBCLASS_NAME_phragmites_australis_2500m\n",
      "390 nwi_SYSTEM_NAME_marine_2500m\n",
      "391 nwi_FIRST_MODIFIER_NAME_artificial_substrate_2500m\n",
      "392 nwi_CLASS_NAME_unconsolidated_bottom_2500m\n",
      "393 nwi_WATER_REGIME_NAME_seasonally_saturated_2500m\n",
      "394 nwi_SUBCLASS_NAME_evergreen_2500m\n",
      "395 nwi_SUBSYSTEM_NAME_lower_perennial_2500m\n",
      "396 nwi_SPLIT_SUBCLASS_NAME_aquatic_moss_2500m\n",
      "397 nwi_FIRST_MODIFIER_NAME_hyperhaline/hypersaline_2500m\n",
      "398 nwi_FIRST_MODIFIER_NAME_spoil_2500m\n",
      "399 nwi_freshwater_emergent_wetland_2500m\n",
      "400 nwi_FIRST_MODIFIER_NAME_diked/impounded_2500m\n",
      "401 nwi_lake_2500m\n",
      "402 nwi_WATER_REGIME_NAME_intermittently_exposed_2500m\n",
      "403 nwi_WATER_REGIME_NAME_continuously__saturated_2500m\n",
      "404 nwi_shrub_wetland_2500m\n",
      "405 nwi_SYSTEM_NAME_estuarine_2500m\n",
      "406 nwi_CLASS_NAME_unconsolidated_shore_2500m\n",
      "407 nwi_SPLIT_SUBCLASS_NAME_dead_2500m\n",
      "408 nwi_SPLIT_SUBCLASS_NAME_moss_2500m\n",
      "409 nwi_SUBCLASS_NAME_algal_2500m\n",
      "410 nwi_estuarine_and_marine_wetland_2500m\n",
      "411 nwi_WATER_REGIME_SUBGROUP_nontidal_2500m\n",
      "412 nwi_FIRST_MODIFIER_NAME_zzz_2500m\n",
      "413 nwi_SUBCLASS_NAME_broad-leaved_evergreen_2500m\n",
      "414 nwi_SUBCLASS_NAME_zzz_2500m\n",
      "415 nwi_SPLIT_CLASS_NAME_scrub-shrub_2500m\n",
      "416 nwi_SPLIT_CLASS_NAME_zzz_2500m\n",
      "417 nwi_WATER_REGIME_NAME_irregularly_exposed_2500m\n",
      "418 nwi_WATER_REGIME_NAME_seasonally_flooded_2500m\n",
      "419 nwi_SPLIT_SUBCLASS_NAME_floating_vascular_2500m\n",
      "420 nwi_WATER_REGIME_NAME_subtidal_2500m\n",
      "421 nwi_SUBCLASS_NAME_persistent_2500m\n",
      "422 nwi_SYSTEM_NAME_palustrine_2500m\n",
      "423 nwi_SPLIT_SUBCLASS_NAME_persistent_2500m\n",
      "424 nwi_SPLIT_SUBCLASS_NAME_zzz_2500m\n",
      "425 nwi_WATER_REGIME_NAME_intermittently_flooded_2500m\n",
      "426 nwi_WATER_REGIME_NAME_regularly_flooded_2500m\n",
      "427 nwi_SPLIT_CLASS_NAME_aquatic_bed_2500m\n",
      "428 nwi_SUBCLASS_NAME_mollusk_2500m\n",
      "429 nwi_FIRST_MODIFIER_NAME_polyhaline_2500m\n",
      "430 nwi_estuarine_and_marine_deepwater_2500m\n",
      "431 nwi_FIRST_MODIFIER_NAME_farmed_2500m\n",
      "432 nwi_WATER_REGIME_NAME_temporary_flooded-tidal_2500m\n",
      "433 nwi_SPLIT_SUBCLASS_NAME_cobble-gravel_2500m\n",
      "434 nwi_FIRST_MODIFIER_NAME_acid_2500m\n",
      "435 nwi_SUBSYSTEM_NAME_unknown_perennial_2500m\n",
      "436 nwi_CLASS_NAME_emergent_2500m\n",
      "437 nwi_SUBCLASS_NAME_cobble-gravel_2500m\n",
      "438 nwi_FIRST_MODIFIER_NAME_alkaline_2500m\n",
      "439 nwi_FIRST_MODIFIER_NAME_oligohaline_2500m\n",
      "440 nwi_SUBCLASS_NAME_floating_vascular_2500m\n",
      "441 nwi_SUBCLASS_NAME_organic_2500m\n",
      "442 nwi_FIRST_MODIFIER_NAME_mineral_2500m\n",
      "443 nwi_WATER_REGIME_NAME_artificially_flooded_2500m\n",
      "444 nwi_CLASS_NAME_scrub-shrub_2500m\n",
      "445 nwi_SPLIT_SUBCLASS_NAME_needle-leaved_evergreen_2500m\n",
      "446 nwi_SPLIT_CLASS_NAME_unconsolidated_bottom_2500m\n",
      "447 nwi_CLASS_NAME_forested_2500m\n",
      "448 nwi_SPLIT_SUBCLASS_NAME_rubble_2500m\n",
      "449 nwi_FIRST_MODIFIER_NAME_partially_drained/ditched_2500m\n",
      "450 nwi_SUBCLASS_NAME_non_persistent_2500m\n",
      "451 nwi_SPLIT_SUBCLASS_NAME_lichen_2500m\n",
      "452 nwi_WATER_REGIME_NAME_zzz_2500m\n",
      "453 nwi_WATER_REGIME_NAME_permanently_flooded_2500m\n",
      "454 nwi_SPLIT_CLASS_NAME_emergent_2500m\n",
      "455 nwi_WATER_REGIME_SUBGROUP_zzz_2500m\n",
      "456 nwi_WATER_REGIME_SUBGROUP_freshwater_tidal_2500m\n",
      "457 nwi_CLASS_NAME_rocky_shore_2500m\n"
     ]
    }
   ],
   "source": [
    "df_num_features = pd.DataFrame(df.describe().columns)\n",
    "for count, col in enumerate(df.describe().columns):\n",
    "  print(count, col)\n",
    "\n",
    "# 5, 7, 14, 17, 19:445"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQVQGqHhGkE_"
   },
   "source": [
    "## Numerical Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "viN9PWn5PY7H",
    "outputId": "25a607e3-e822-47b5-908e-ff201a1ac251"
   },
   "outputs": [],
   "source": [
    "# numerical features of interest: \n",
    "# imp_num_feature_list = [5, 7,14, 17] + list(range(19, 445)) #[2, 3, 17] + list(range(21, 93))\n",
    "imp_num_feature_list = [17] + list(range(19, 445)) #[2, 3, 17] + list(range(21, 93)) # no lat, lon, potential_wetland\n",
    "\n",
    "\n",
    "imp_num_feature = df_num_features.loc[imp_num_feature_list]\n",
    "imp_num_feature = list(imp_num_feature.values.flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfKbTgYTGohQ"
   },
   "source": [
    "## Categorical Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "id": "n5JCwDs_Q8pW"
   },
   "outputs": [],
   "source": [
    "# call out the important categorical features\n",
    "\n",
    "set(df.columns) - set(df.describe().columns)\n",
    "# imp_cat_feature = ['district', 'flodfreqdc', 'drclassdcd', 'county', 'jurisdiction_type']\n",
    "imp_cat_feature = ['county', 'jurisdiction_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VweeykE-4Ter"
   },
   "source": [
    "# Order Train-Dev-Test splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqbXGvZIRHGi",
    "outputId": "6238c23e-8db0-4cc0-fe3c-71f547ef6e6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2866, 429)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-arrange so numerical columns go first, then the categorical\n",
    "df1 = df[imp_num_feature]\n",
    "df2 = df[imp_cat_feature]\n",
    "\n",
    "# train\n",
    "df_X_combined_ordered = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "# dev\n",
    "df_dev_X = pd.concat([df_dev[imp_num_feature], df_dev[imp_cat_feature]], axis=1)\n",
    "\n",
    "\n",
    "# test\n",
    "df_test_X = pd.concat([df_test[imp_num_feature], df_test[imp_cat_feature]], axis=1)\n",
    "\n",
    "\n",
    "df_X_combined_ordered.columns #44\n",
    "df_X_combined_ordered.shape # (10000, 44)\n",
    "df_test_X.shape # (4500, 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdBKul2wROi4",
    "outputId": "fb607dae-a36a-4e9b-e4be-eb54ae133426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mukey 0.04\n",
      "iccdcd 0.88\n",
      "aws0150wta 0.04\n",
      "brockdepmi 0.04\n",
      "iccdcdpct 0.04\n",
      "hydclprs 0.04\n",
      "aws050wta 0.04\n",
      "flodfreqdc 0.1\n",
      "pondfreqpr 0.04\n",
      "niccdcd 0.11\n",
      "awmmfpwwta 0.04\n",
      "aws0100wta 0.04\n",
      "slopegradw 0.04\n",
      "slopegradd 0.04\n",
      "drclassdcd 0.13\n",
      "aws025wta 0.04\n",
      "urbrecptwt 0.04\n",
      "niccdcdpct 0.04\n",
      "wtdepannmi 0.04\n",
      "slope_stdev_200m 0.02\n",
      "transition_8_200m 0.95\n",
      "seasonality_mean_200m 0.81\n",
      "transition_0_200m 0.99\n",
      "recurrence_min_200m 0.79\n",
      "elevation_min_200m 0.02\n",
      "seasonality_min_200m 0.82\n",
      "transition_2_200m 0.96\n",
      "slope_min_200m 0.02\n",
      "transition_3_200m 0.99\n",
      "seasonality_stdev_200m 0.82\n",
      "slope_mean_200m 0.02\n",
      "recurrence_mean_200m 0.78\n",
      "transition_5_200m 0.86\n",
      "transition_7_200m 0.96\n",
      "elevation_mean_200m 0.02\n",
      "slope_max_200m 0.02\n",
      "elevation_max_200m 0.02\n",
      "seasonality_max_200m 0.82\n",
      "transition_6_200m 0.94\n",
      "transition_4_200m 0.91\n",
      "elevation_stdev_200m 0.02\n",
      "transition_1_200m 0.9\n",
      "recurrence_max_200m 0.79\n",
      "recurrence_stdev_200m 0.79\n",
      "transition_9_200m 1.0\n",
      "fl_length_sum_200m 0.08\n",
      "fl_length_mean_200m 0.08\n",
      "transition_2_2500m 0.41\n",
      "recurrence_stdev_2500m 0.07\n",
      "seasonality_max_2500m 0.11\n",
      "recurrence_min_2500m 0.07\n",
      "transition_9_2500m 0.89\n",
      "elevation_mean_2500m 0.02\n",
      "transition_6_2500m 0.36\n",
      "slope_stdev_2500m 0.02\n",
      "slope_min_2500m 0.02\n",
      "slope_mean_2500m 0.02\n",
      "transition_1_2500m 0.49\n",
      "slope_max_2500m 0.02\n",
      "seasonality_stdev_2500m 0.11\n",
      "elevation_stdev_2500m 0.02\n",
      "transition_0_2500m 0.82\n",
      "seasonality_mean_2500m 0.11\n",
      "seasonality_min_2500m 0.11\n",
      "transition_4_2500m 0.32\n",
      "transition_7_2500m 0.55\n",
      "elevation_max_2500m 0.02\n",
      "elevation_min_2500m 0.02\n",
      "recurrence_mean_2500m 0.07\n",
      "transition_5_2500m 0.13\n",
      "transition_3_2500m 0.8\n",
      "recurrence_max_2500m 0.07\n",
      "transition_8_2500m 0.55\n",
      "fl_length_sum_2500m 0.52\n",
      "fl_length_mean_2500m 0.52\n"
     ]
    }
   ],
   "source": [
    "# fraction of nan's in each variable\n",
    "for var in df_X_combined_ordered.describe().columns:\n",
    "  if np.mean(df_X_combined_ordered[str(var)].isna()) != 0:\n",
    "    print(var, round(np.mean(df_X_combined_ordered[str(var)].isna()), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "id": "D4kq__Giqima"
   },
   "outputs": [],
   "source": [
    "# impute 0's into wb_area_mean, fl_length_sum, fl_length_mean because they were\n",
    "# assigned np.nan if they were absent\n",
    "# A non-existent water feature should be assigned 0 given definition of each\n",
    "\n",
    "def fill_na(df):\n",
    "  try:\n",
    "    df.fl_length_sum_200m = df.fl_length_sum_200m.fillna(0)\n",
    "    df.fl_length_mean_200m = df.fl_length_sum_200m.fillna(0)\n",
    "    df.fl_length_sum_2500m = df.fl_length_sum_200m.fillna(0)\n",
    "    df.fl_length_mean_2500m = df.fl_length_sum_200m.fillna(0)\n",
    "  except:\n",
    "    pass\n",
    "  return df\n",
    "\n",
    "df_X_combined_ordered = fill_na(df_X_combined_ordered)\n",
    "df_dev_X_combined_ordered = fill_na(df_dev_X)\n",
    "df_test_X_combined_ordered = fill_na(df_test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qy2KEjaNq487",
    "outputId": "077aa965-5d64-4ad9-abc7-001580eb74d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mukey 0.04\n",
      "iccdcd 0.88\n",
      "aws0150wta 0.04\n",
      "brockdepmi 0.04\n",
      "iccdcdpct 0.04\n",
      "hydclprs 0.04\n",
      "aws050wta 0.04\n",
      "flodfreqdc 0.1\n",
      "pondfreqpr 0.04\n",
      "niccdcd 0.11\n",
      "awmmfpwwta 0.04\n",
      "aws0100wta 0.04\n",
      "slopegradw 0.04\n",
      "slopegradd 0.04\n",
      "drclassdcd 0.13\n",
      "aws025wta 0.04\n",
      "urbrecptwt 0.04\n",
      "niccdcdpct 0.04\n",
      "wtdepannmi 0.04\n",
      "slope_stdev_200m 0.02\n",
      "transition_8_200m 0.95\n",
      "seasonality_mean_200m 0.81\n",
      "transition_0_200m 0.99\n",
      "recurrence_min_200m 0.79\n",
      "elevation_min_200m 0.02\n",
      "seasonality_min_200m 0.82\n",
      "transition_2_200m 0.96\n",
      "slope_min_200m 0.02\n",
      "transition_3_200m 0.99\n",
      "seasonality_stdev_200m 0.82\n",
      "slope_mean_200m 0.02\n",
      "recurrence_mean_200m 0.78\n",
      "transition_5_200m 0.86\n",
      "transition_7_200m 0.96\n",
      "elevation_mean_200m 0.02\n",
      "slope_max_200m 0.02\n",
      "elevation_max_200m 0.02\n",
      "seasonality_max_200m 0.82\n",
      "transition_6_200m 0.94\n",
      "transition_4_200m 0.91\n",
      "elevation_stdev_200m 0.02\n",
      "transition_1_200m 0.9\n",
      "recurrence_max_200m 0.79\n",
      "recurrence_stdev_200m 0.79\n",
      "transition_9_200m 1.0\n",
      "transition_2_2500m 0.41\n",
      "recurrence_stdev_2500m 0.07\n",
      "seasonality_max_2500m 0.11\n",
      "recurrence_min_2500m 0.07\n",
      "transition_9_2500m 0.89\n",
      "elevation_mean_2500m 0.02\n",
      "transition_6_2500m 0.36\n",
      "slope_stdev_2500m 0.02\n",
      "slope_min_2500m 0.02\n",
      "slope_mean_2500m 0.02\n",
      "transition_1_2500m 0.49\n",
      "slope_max_2500m 0.02\n",
      "seasonality_stdev_2500m 0.11\n",
      "elevation_stdev_2500m 0.02\n",
      "transition_0_2500m 0.82\n",
      "seasonality_mean_2500m 0.11\n",
      "seasonality_min_2500m 0.11\n",
      "transition_4_2500m 0.32\n",
      "transition_7_2500m 0.55\n",
      "elevation_max_2500m 0.02\n",
      "elevation_min_2500m 0.02\n",
      "recurrence_mean_2500m 0.07\n",
      "transition_5_2500m 0.13\n",
      "transition_3_2500m 0.8\n",
      "recurrence_max_2500m 0.07\n",
      "transition_8_2500m 0.55\n",
      "\n",
      "mukey 0.04\n",
      "iccdcd 0.89\n",
      "aws0150wta 0.04\n",
      "brockdepmi 0.04\n",
      "iccdcdpct 0.04\n",
      "hydclprs 0.04\n",
      "aws050wta 0.04\n",
      "flodfreqdc 0.09\n",
      "pondfreqpr 0.04\n",
      "niccdcd 0.1\n",
      "awmmfpwwta 0.04\n",
      "aws0100wta 0.04\n",
      "slopegradw 0.04\n",
      "slopegradd 0.04\n",
      "drclassdcd 0.12\n",
      "aws025wta 0.04\n",
      "urbrecptwt 0.04\n",
      "niccdcdpct 0.04\n",
      "wtdepannmi 0.04\n",
      "slope_stdev_200m 0.02\n",
      "transition_8_200m 0.94\n",
      "seasonality_mean_200m 0.8\n",
      "transition_0_200m 0.99\n",
      "recurrence_min_200m 0.79\n",
      "elevation_min_200m 0.02\n",
      "seasonality_min_200m 0.82\n",
      "transition_2_200m 0.96\n",
      "slope_min_200m 0.02\n",
      "transition_3_200m 0.98\n",
      "seasonality_stdev_200m 0.82\n",
      "slope_mean_200m 0.02\n",
      "recurrence_mean_200m 0.77\n",
      "transition_5_200m 0.85\n",
      "transition_7_200m 0.96\n",
      "elevation_mean_200m 0.02\n",
      "slope_max_200m 0.02\n",
      "elevation_max_200m 0.02\n",
      "seasonality_max_200m 0.82\n",
      "transition_6_200m 0.94\n",
      "transition_4_200m 0.9\n",
      "elevation_stdev_200m 0.02\n",
      "transition_1_200m 0.89\n",
      "recurrence_max_200m 0.79\n",
      "recurrence_stdev_200m 0.79\n",
      "transition_9_200m 1.0\n",
      "transition_2_2500m 0.4\n",
      "recurrence_stdev_2500m 0.07\n",
      "seasonality_max_2500m 0.1\n",
      "recurrence_min_2500m 0.07\n",
      "transition_9_2500m 0.89\n",
      "elevation_mean_2500m 0.02\n",
      "transition_6_2500m 0.35\n",
      "slope_stdev_2500m 0.02\n",
      "slope_min_2500m 0.02\n",
      "slope_mean_2500m 0.02\n",
      "transition_1_2500m 0.49\n",
      "slope_max_2500m 0.02\n",
      "seasonality_stdev_2500m 0.1\n",
      "elevation_stdev_2500m 0.02\n",
      "transition_0_2500m 0.82\n",
      "seasonality_mean_2500m 0.1\n",
      "seasonality_min_2500m 0.1\n",
      "transition_4_2500m 0.31\n",
      "transition_7_2500m 0.54\n",
      "elevation_max_2500m 0.02\n",
      "elevation_min_2500m 0.02\n",
      "recurrence_mean_2500m 0.06\n",
      "transition_5_2500m 0.11\n",
      "transition_3_2500m 0.8\n",
      "recurrence_max_2500m 0.07\n",
      "transition_8_2500m 0.54\n",
      "\n",
      "mukey 0.04\n",
      "iccdcd 0.89\n",
      "aws0150wta 0.04\n",
      "brockdepmi 0.04\n",
      "iccdcdpct 0.04\n",
      "hydclprs 0.04\n",
      "aws050wta 0.04\n",
      "flodfreqdc 0.09\n",
      "pondfreqpr 0.04\n",
      "niccdcd 0.1\n",
      "awmmfpwwta 0.04\n",
      "aws0100wta 0.04\n",
      "slopegradw 0.04\n",
      "slopegradd 0.04\n",
      "drclassdcd 0.13\n",
      "aws025wta 0.04\n",
      "urbrecptwt 0.04\n",
      "niccdcdpct 0.04\n",
      "wtdepannmi 0.04\n",
      "slope_stdev_200m 0.02\n",
      "transition_8_200m 0.94\n",
      "seasonality_mean_200m 0.8\n",
      "transition_0_200m 0.99\n",
      "recurrence_min_200m 0.78\n",
      "elevation_min_200m 0.02\n",
      "seasonality_min_200m 0.81\n",
      "transition_2_200m 0.96\n",
      "slope_min_200m 0.02\n",
      "transition_3_200m 0.98\n",
      "seasonality_stdev_200m 0.81\n",
      "slope_mean_200m 0.02\n",
      "recurrence_mean_200m 0.76\n",
      "transition_5_200m 0.85\n",
      "transition_7_200m 0.95\n",
      "elevation_mean_200m 0.02\n",
      "slope_max_200m 0.02\n",
      "elevation_max_200m 0.02\n",
      "seasonality_max_200m 0.81\n",
      "transition_6_200m 0.94\n",
      "transition_4_200m 0.9\n",
      "elevation_stdev_200m 0.02\n",
      "transition_1_200m 0.89\n",
      "recurrence_max_200m 0.78\n",
      "recurrence_stdev_200m 0.78\n",
      "transition_9_200m 0.99\n",
      "transition_2_2500m 0.43\n",
      "recurrence_stdev_2500m 0.08\n",
      "seasonality_max_2500m 0.11\n",
      "recurrence_min_2500m 0.08\n",
      "transition_9_2500m 0.89\n",
      "elevation_mean_2500m 0.02\n",
      "transition_6_2500m 0.36\n",
      "slope_stdev_2500m 0.02\n",
      "slope_min_2500m 0.02\n",
      "slope_mean_2500m 0.02\n",
      "transition_1_2500m 0.51\n",
      "slope_max_2500m 0.02\n",
      "seasonality_stdev_2500m 0.11\n",
      "elevation_stdev_2500m 0.02\n",
      "transition_0_2500m 0.83\n",
      "seasonality_mean_2500m 0.11\n",
      "seasonality_min_2500m 0.11\n",
      "transition_4_2500m 0.32\n",
      "transition_7_2500m 0.56\n",
      "elevation_max_2500m 0.02\n",
      "elevation_min_2500m 0.02\n",
      "recurrence_mean_2500m 0.08\n",
      "transition_5_2500m 0.13\n",
      "transition_3_2500m 0.8\n",
      "recurrence_max_2500m 0.08\n",
      "transition_8_2500m 0.56\n"
     ]
    }
   ],
   "source": [
    "# fraction of nan's in each variable\n",
    "def print_na(df_X_combined_ordered):\n",
    "  for var in df_X_combined_ordered.describe().columns:\n",
    "    if np.mean(df_X_combined_ordered[str(var)].isna()) != 0:\n",
    "      print(var, round(np.mean(df_X_combined_ordered[str(var)].isna()), 2))\n",
    "\n",
    "print_na(df_X_combined_ordered)      \n",
    "print()\n",
    "print_na(df_dev_X_combined_ordered)\n",
    "print()\n",
    "print_na(df_test_X_combined_ordered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiZZiHI7rroC"
   },
   "source": [
    "# Offline OHE to keep track of variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "id": "5wgvKVZ7rNb8"
   },
   "outputs": [],
   "source": [
    "# ohe-hot-encode the columns\n",
    "# get_dummies only encodes cat columns\n",
    "df_X_combined_dummies_ordered = pd.get_dummies(df_X_combined_ordered)\n",
    "# df_X_combined_dummies_ordered.columns # 90\n",
    "\n",
    "df_dev_X_combined_dummies_ordered = pd.get_dummies(df_dev_X_combined_ordered)\n",
    "df_test_X_combined_dummies_ordered = pd.get_dummies(df_test_X_combined_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2DzQYz-guOe",
    "outputId": "d15cc667-b613-4161-fdee-cb63bd03ce29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8596, 429)\n",
      "(2866, 429)\n",
      "(2866, 429)\n",
      "(8596, 1438)\n",
      "(2866, 1127)\n",
      "(2866, 1108)\n"
     ]
    }
   ],
   "source": [
    "print(df_X_combined_ordered.shape)\n",
    "print(df_dev_X_combined_ordered.shape)\n",
    "print(df_test_X_combined_ordered.shape)\n",
    "print(df_X_combined_dummies_ordered.shape)\n",
    "print(df_dev_X_combined_dummies_ordered.shape)\n",
    "print(df_test_X_combined_dummies_ordered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1Eq49x-r55M"
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "id": "YoBhg5wPrxlx"
   },
   "outputs": [],
   "source": [
    "# impute categorical data\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "  \"\"\"\n",
    "  By inheriting TransformerMixin, you get fit_transform method for free \n",
    "  if you implement fit and transform methods\n",
    "  \"\"\" \n",
    "\n",
    "  def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "\n",
    "        Columns of dtype object are imputed with the most frequent value \n",
    "        in column.\n",
    "        Columns of other types are imputed with median of column.\n",
    "        \"\"\"\n",
    "  def fit(self, X, y=None):\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].median() for c in X], \n",
    "            index=X.columns)\n",
    "        return self\n",
    "\n",
    "  def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "id": "2E_VtoXpr8W9"
   },
   "outputs": [],
   "source": [
    "# Pipeline for numerical columns\n",
    "# 1. fill NA's with median values\n",
    "# 2. scale them\n",
    "\n",
    "# num_pipeline_impute_ss = Pipeline([        # should be list of tuples\n",
    "#                           (\"num_imputer\", SimpleImputer(strategy=\"median\")),\n",
    "#                           (\"std_scaler\", StandardScaler())\n",
    "#                           ])                      \n",
    "\n",
    "# num_pipeline_impute_ss = Pipeline([        # should be list of tuples\n",
    "#                           (\"num_imputer\", SimpleImputer(strategy=\"median\")),\n",
    "#                           (\"robust_scaler\", RobustScaler())\n",
    "#                           ])                      \n",
    "\n",
    "num_pipeline_impute_ss = Pipeline([        # should be list of tuples\n",
    "                          (\"num_imputer\", SimpleImputer(strategy=\"median\"))\n",
    "                          ])                      \n",
    "\n",
    "\n",
    "# Pipleline for categorical columns\n",
    "# 1. fill NA's with most frequent values\n",
    "# 2. one hot code\n",
    "\n",
    "# cat_pipeline_impute_ohe = Pipeline([(\"cat_imputer\", DataFrameImputer()),\n",
    "#                          (\"one_hot_encoder\", OneHotEncoder(drop=\"first\", \\\n",
    "#                                                            sparse=False))\n",
    "#                          ])\n",
    "\n",
    "\n",
    "# you want to do the following where you handle_unknown categories in the \n",
    "# test data by ignoring them. However, in the imeplementation, I am using\n",
    "# df_X_combined_dummies_ordered to indicate the numerical and cat columns \n",
    "# hence need to fix the df_X_combined_dummies_ordered such that the first \n",
    "# ohe is not dropped (as is being done in immediately above)\n",
    "\n",
    "cat_pipeline_impute_ohe = Pipeline([(\"cat_imputer\", DataFrameImputer()),\n",
    "                         (\"one_hot_encoder\", OneHotEncoder(sparse=False,\n",
    "                                                           handle_unknown = \"ignore\"))\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "id": "T6zsqDgLsIhp"
   },
   "outputs": [],
   "source": [
    "numericals_list = list(df_X_combined_ordered.describe().columns)\n",
    "categories_list = list(set(df_X_combined_ordered.columns) - set(numericals_list))\n",
    "\n",
    "# here trying to do numerical and categorical transformation in isolation\n",
    "# this because ColumnTransformer removes column name information :-(\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# only the cat columns will be one-hot encoded\n",
    "partial_transformer_impute_ohe = ColumnTransformer([\n",
    "                                   (\"categorical_ohe\", cat_pipeline_impute_ohe,\\\n",
    "                                    categories_list)\n",
    "])\n",
    "\n",
    "# only the numerical columns withh get standard scaling\n",
    "partial_transformer_impute_ss = ColumnTransformer([\n",
    "                                   (\"numerical_ss_impute\", num_pipeline_impute_ss,\\\n",
    "                                    numericals_list)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation of Dev and Test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7DxNTfIFtT9y",
    "outputId": "5d8a5f9d-f079-43d8-b8db-65afc2d25027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8596, 427)\n",
      "(2866, 427)\n",
      "(2866, 427)\n"
     ]
    }
   ],
   "source": [
    "# Pass the numerical columns through Numerical Pipeline \n",
    "\n",
    "# train\n",
    "full_data_ohe_ss_imputed = (partial_transformer_impute_ss\n",
    "                            .fit(df_X_combined_ordered[numericals_list])\n",
    "                            .transform(df_X_combined_ordered[numericals_list])) \n",
    "print(full_data_ohe_ss_imputed.shape)\n",
    "\n",
    "# dev\n",
    "dev_ohe_ss_imputed = (partial_transformer_impute_ss\n",
    "                            .fit(df_X_combined_ordered[numericals_list])\n",
    "                            .transform(df_dev_X_combined_ordered[numericals_list])) \n",
    "print(dev_ohe_ss_imputed.shape)\n",
    "\n",
    "\n",
    "# test\n",
    "test_ohe_ss_imputed = (partial_transformer_impute_ss\n",
    "                            .fit(df_X_combined_ordered[numericals_list])\n",
    "                            .transform(df_test_X_combined_ordered[numericals_list])) \n",
    "print(test_ohe_ss_imputed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQD-xNjqtUA9",
    "outputId": "9bf01104-653e-4175-e099-3c7a0296e530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8596, 1011)\n",
      "(2866, 1011)\n",
      "(2866, 1011)\n"
     ]
    }
   ],
   "source": [
    "# Pass the cat columns through Categorical Pipeline\n",
    "\n",
    "# train\n",
    "cat_data_OHE = (partial_transformer_impute_ohe\n",
    "                .fit(df_X_combined_ordered)\n",
    "                .transform(df_X_combined_ordered))\n",
    "print(cat_data_OHE.shape)\n",
    "\n",
    "# test\n",
    "dev_cat_data_OHE = (partial_transformer_impute_ohe\n",
    "                .fit(df_X_combined_ordered)\n",
    "                .transform(df_dev_X_combined_ordered))\n",
    "print(dev_cat_data_OHE.shape)\n",
    "\n",
    "# test\n",
    "test_cat_data_OHE = (partial_transformer_impute_ohe\n",
    "                .fit(df_X_combined_ordered)\n",
    "                .transform(df_test_X_combined_ordered))\n",
    "print(test_cat_data_OHE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgK2Nv2HycZo",
    "outputId": "9af08aa1-945f-49a2-a36b-42064875d6d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8596, 1438) (8596,) (2866, 1438) (2866,) (2866, 1438) (2866,)\n"
     ]
    }
   ],
   "source": [
    "# join the arrays into one array that can be passed into models\n",
    "\n",
    "# train\n",
    "X = np.hstack((full_data_ohe_ss_imputed, cat_data_OHE))\n",
    "Y = np.array(df.cwa_determination)\n",
    "\n",
    "# dev\n",
    "dev_X = np.hstack((dev_ohe_ss_imputed, dev_cat_data_OHE))\n",
    "dev_Y = np.array(df_dev.cwa_determination)\n",
    "\n",
    "# test\n",
    "test_X = np.hstack((test_ohe_ss_imputed, test_cat_data_OHE))\n",
    "test_Y = np.array(df_test.cwa_determination)\n",
    "\n",
    "print(X.shape, Y.shape, dev_X.shape, dev_Y.shape, test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "id": "vNnvAK30tUDx"
   },
   "outputs": [],
   "source": [
    "# Convert numerical and cat transforms back to dataframe (for housekeeping)\n",
    "\n",
    "# convert numerical arrays into dataframe\n",
    "\n",
    "def make_dataframe(full_data_ohe_ss_imputed, cat_data_OHE):\n",
    "  df_num_data_ohe_ss = (pd.DataFrame(\n",
    "      full_data_ohe_ss_imputed,\n",
    "      columns=list(df_X_combined_dummies_ordered[numericals_list].columns)\n",
    "  ))\n",
    "\n",
    "  # # convert cat arrays into dataframe\n",
    "  ohe_categories_list = (list(set(df_X_combined_dummies_ordered.columns) - set(numericals_list)))\n",
    "  df_cat_data_OHE = (pd.DataFrame(\n",
    "      cat_data_OHE,\n",
    "      columns=list(df_X_combined_dummies_ordered[ohe_categories_list].columns))\n",
    "  )\n",
    "\n",
    "  # concatenate into one dataframe\n",
    "\n",
    "  return pd.concat([df_num_data_ohe_ss, df_cat_data_OHE], axis=1)\n",
    "\n",
    "\n",
    "df_train_X_dummies = make_dataframe(full_data_ohe_ss_imputed, cat_data_OHE)\n",
    "df_dev_X_dummies = make_dataframe(dev_ohe_ss_imputed, dev_cat_data_OHE)\n",
    "df_test_X_dummies = make_dataframe(test_ohe_ss_imputed, test_cat_data_OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "id": "iY1gOlOk5-ZM"
   },
   "outputs": [],
   "source": [
    "if stop_before_models:\n",
    "    stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZOqLgq5EsPm"
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmWtOA8lEThm",
    "outputId": "3a4a38ac-dfe3-4cc8-ddd0-80ae86b3eec8"
   },
   "outputs": [],
   "source": [
    "# print(sorted(metrics.SCORERS.keys()))\n",
    "# sorted(metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_search.__dir__()\n",
    "# random_search.return_train_score\n",
    "\n",
    "# random_search.scoring # roc_auc\n",
    "# random_search.best_score_ # \n",
    "# random_search.scorer_ # make_scorer(roc_auc_score, needs_threshold=True)\n",
    "\n",
    "# random_search.cv_results_\n",
    "# random_search.predict_proba(X)\n",
    "# random_search.predict_log_proba(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_taken(start, end):\n",
    "    delta = end - start\n",
    "    print(\"Time taken (min):\", round(delta.seconds/60, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(fitted_model, test_X, test_Y):\n",
    "#     print(\"accuracy:\", np.mean(test_Y == log_best_model.predict(test_X)))\n",
    "#     print(\"balanced_accuracy_score:\", balanced_accuracy_score(test_Y, log_best_model.predict(test_X)))\n",
    "\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html\n",
    "    # AP summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold\n",
    "    print(\"average_precision_score:\", round(metrics.average_precision_score(test_Y, fitted_model.predict_proba(test_X)[:, 1], average=\"weighted\"), 5))\n",
    "    \n",
    "    \n",
    "    y_prob = fitted_model.predict_proba(test_X)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_Y, y_prob[:, 1], pos_label=1)\n",
    "    print(\"roc_auc\",\":\", round(metrics.auc(fpr, tpr), 5))\n",
    "    \n",
    "    print(\"Classification Report:\") # threshold agnostic because you pass in the test labels instead of scores (probabilities)\n",
    "    print(classification_report(test_Y, fitted_model.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_roc_auc(fitted_model, test_X, test_Y):\n",
    "    y_prob = fitted_model.predict_proba(test_X)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_Y, y_prob[:, 1], pos_label=1)\n",
    "    return round(metrics.auc(fpr, tpr), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpKXfQfXzKLf"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzQrUXTW6J6b",
    "outputId": "506c9dc8-7ddd-46a3-f171-91e9993e52c9"
   },
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqOn82eq0Hsy"
   },
   "outputs": [],
   "source": [
    "\n",
    "# build a classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "param_dict = {\"C\":np.logspace(-3,3,7), \n",
    "              \"penalty\":[\"l1\", \"l2\", \"elasticnet\"],\n",
    "              \"l1_ratio\":np.linspace(0,1,10),\n",
    "              \"solver\":[\"lbfgs\", \"saga\"]\n",
    "              }# l1 lasso l2 ridge\n",
    "\n",
    "# run randomized search\n",
    "if run_logistic:\n",
    "    random_search_model = RandomizedSearchCV(clf, \n",
    "                                       param_distributions=param_dict,\n",
    "                                       n_iter=20, \n",
    "                                       scoring='roc_auc', \n",
    "                                       cv=10, \n",
    "                                       n_jobs=-1)\n",
    "\n",
    "\n",
    "    # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    random_search_model.fit(X, Y)\n",
    "    model_dict[\"lr\"] = random_search_model\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYoge1Lo5Xy5",
    "outputId": "608485a4-911d-4c7f-b89b-b2ae06d5b4c8"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    random_search_fitted_models = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "    lr = random_search_fitted_models[\"lr\"]\n",
    "    model_results(lr, dev_X, dev_Y)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure if useful\n",
    "# precision, recall, thresholds = metrics.precision_recall_curve(test_Y, lr.predict_proba(test_X)[:, 1], pos_label=1)\n",
    "\n",
    "# metrics.plot_precision_recall_curve(lr, test_X, test_Y, response_method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLlnRF_s062y"
   },
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ug-A0ZPMDgZ7"
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8k3ZsgjHNjC"
   },
   "outputs": [],
   "source": [
    "# build a classifier\n",
    "clf = XGBRFClassifier()\n",
    "\n",
    "# A parameter grid for XGBoost\n",
    "# https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost\n",
    "param_dict = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n",
    "# run randomized search\n",
    "if run_models:\n",
    "    random_search_model = RandomizedSearchCV(clf, \n",
    "                                   param_distributions=param_dict,\n",
    "                                   n_iter=1, \n",
    "                                   scoring='roc_auc', \n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1)\n",
    "\n",
    "\n",
    "    # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    random_search_model.fit(X, Y)\n",
    "    model_dict[\"xgb\"] = random_search_model\n",
    "    model_dict[\"file_params\"] = file_param_dict    \n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_fitted_models = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "xgb = random_search_fitted_models[\"xgb\"]\n",
    "y_predict = lr.predict(test_X) \n",
    "\n",
    "# threshold is taken as 0.5, as proven here\n",
    "# y_predict_ = 1 * (lr.predict_proba(test_X)[:, 1]>0.5) # \n",
    "# np.mean(y_predict == y_predict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(xgb, dev_X, dev_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "DqyeGmeqZXnZ",
    "outputId": "36dc804f-a60b-4a0c-87dd-d4a9bc62411f"
   },
   "outputs": [],
   "source": [
    "#Feature importance for top 50 predictors\n",
    "predictors = [x for x in df_X_combined_dummies_ordered.columns]\n",
    "feat_imp = pd.Series(xgb.best_estimator_.feature_importances_, predictors).sort_values(ascending=False)\n",
    "feat_imp = feat_imp[0:50]\n",
    "plt.rcParams['figure.figsize'] = 20, 5\n",
    "feat_imp.plot(kind='bar', title='Feature Importance')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ez1BBgTW_Bk"
   },
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-nU49jh6tULS",
    "outputId": "166d48d9-0f92-4c84-a479-c662c5172834"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/binilg/lightgbm-with-randomsearchcv-and-feature-imp\n",
    "# Implementation: https://www.kaggle.com/mlisovyi/lightgbm-hyperparameter-optimisation-lb-0-761\n",
    "# Documentation: https://lightgbm.readthedocs.io/en/latest/Features.html\n",
    "# LightGBM Classifier: https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#\n",
    "\n",
    "import lightgbm\n",
    "param_dict = {\n",
    "    'learning_rate': [0.05],\n",
    "    'num_leaves': [90,200],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'max_depth' : [5,6,7,8],\n",
    "    'random_state' : [501], \n",
    "    'colsample_bytree' : [0.5,0.7],\n",
    "    'subsample' : [0.5,0.7],\n",
    "    'min_split_gain' : [0.01],\n",
    "    'min_data_in_leaf':[10],\n",
    "    'metric':['auc']\n",
    "    }\n",
    "#modelling\n",
    "clf = lightgbm.LGBMClassifier()\n",
    "\n",
    "if run_models:\n",
    "    random_search_model = (RandomizedSearchCV(clf, \n",
    "                               param_dict, \n",
    "                               verbose=1, \n",
    "                               cv=10, \n",
    "                               n_jobs = -1, \n",
    "                               n_iter=10,\n",
    "                               scoring='roc_auc'))\n",
    "        # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    random_search_model.fit(X, Y)\n",
    "    model_dict[\"lgbm\"] = random_search_model\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_fitted_models = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "lgbm = random_search_fitted_models[\"lgbm\"]\n",
    "y_predict = lgbm.predict(test_X) \n",
    "\n",
    "# threshold is taken as 0.5, as proven here\n",
    "# y_predict_ = 1 * (lr.predict_proba(test_X)[:, 1]>0.5) # \n",
    "# np.mean(y_predict == y_predict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ISubtXNPXo_-",
    "outputId": "54b42de5-9909-4c66-b451-e106a5181e02"
   },
   "outputs": [],
   "source": [
    "model_results(lgbm, dev_X, dev_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "id": "SaFbWsFQX5Vs",
    "outputId": "f00a317c-8b5f-4dd4-e538-8056b8a803be"
   },
   "outputs": [],
   "source": [
    "#Feature importance for top 50 predictors\n",
    "predictors = [x for x in df_X_combined_dummies_ordered.columns]\n",
    "feat_imp = pd.Series(lgbm.best_estimator_.feature_importances_, predictors).sort_values(ascending=False)\n",
    "feat_imp = feat_imp[0:50]\n",
    "plt.rcParams['figure.figsize'] = 20, 5\n",
    "feat_imp.plot(kind='bar', title='Feature Importance')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3RElmg55sOb"
   },
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers, meta_classifier, use_probas=False, cv=2, \n",
    "# use_features_in_secondary=False, stratify=True, shuffle=True, verbose=0, store_train_meta_features=False, use_clones=True)\n",
    "\n",
    "random_search_fitted_models = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "xgb = random_search_fitted_models[\"xgb\"]\n",
    "lgbm = random_search_fitted_models[\"lgbm\"]\n",
    "\n",
    "if run_models:\n",
    "    stack_gen_model = (StackingCVClassifier(classifiers=[xgb.best_estimator_,\n",
    "                                                         lgbm.best_estimator_], \n",
    "                                            meta_classifier=xgb.best_estimator_,\n",
    "                                            use_features_in_secondary=True,\n",
    "                                            use_probas=True,\n",
    "                                           random_state=random_state))\n",
    "\n",
    "    stack_gen_model.fit(X, Y)\n",
    "    model_dict[\"stacking\"] = stack_gen_model\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "    \n",
    "random_search_fitted_models = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "stacking = random_search_fitted_models[\"stacking\"]\n",
    "y_predict = stacking.predict(test_X) \n",
    "y_score = stacking.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "n_classes = 2\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(test_Y, y_score[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_auc\n",
    "\n",
    "# # Compute micro-average ROC curve and ROC area\n",
    "# fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_Y.ravel(), y_score.ravel())\n",
    "# roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# plt.figure()\n",
    "# lw = 2\n",
    "# plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "#          lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver operating characteristic example')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(stack_gen_model, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Efv12Vc6ijNT"
   },
   "outputs": [],
   "source": [
    "if run_models:\n",
    "    vc_clf = (VotingClassifier(estimators=[(\"xbg\", random_search_fitted_models[\"xgb\"]), \n",
    "                                           (\"lightgbm\", random_search_fitted_models[\"lgbm\"]),\n",
    "                                          (\"stacking\", random_search_fitted_models[\"stacking\"])],\n",
    "                                           voting=\"soft\",\n",
    "                                           flatten_transform=False))\n",
    "\n",
    "    vc_fit = vc_clf.fit(dev_X, dev_Y)\n",
    "    model_dict[\"voting_clf\"] = vc_fit\n",
    "    model_dict[\"file_params\"] = file_param_dict\n",
    "    pickle.dump(model_dict, open(\"random_search_fitted_models_\" + FILE_VERSION, \"wb\"), protocol=3)\n",
    "\n",
    "random_search_fitted_models = pd.read_pickle(\"random_search_fitted_models_\" + FILE_VERSION)\n",
    "voting_clf = random_search_fitted_models[\"voting_clf\"]\n",
    "y_predict = voting_clf.predict(test_X) \n",
    "y_score = voting_clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(vc_fit, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "time_taken(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(fitted_model, test_X, test_Y):\n",
    "#     print(\"accuracy:\", np.mean(test_Y == log_best_model.predict(test_X)))\n",
    "#     print(\"balanced_accuracy_score:\", balanced_accuracy_score(test_Y, log_best_model.predict(test_X)))\n",
    "\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html\n",
    "    # AP summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold\n",
    "    print(\"average_precision_score:\", round(metrics.average_precision_score(test_Y, fitted_model.predict_proba(test_X)[:, 1], average=\"weighted\"), 5))\n",
    "    \n",
    "    y_prob = fitted_model.predict_proba(test_X)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_Y, y_prob[:, 1], pos_label=1)\n",
    "    print(\"roc_auc\",\":\", round(metrics.auc(fpr, tpr), 5))\n",
    "    \n",
    "    print(\"Classification Report:\") # threshold agnostic because you pass in the test labels instead of scores (probabilities)\n",
    "    print(classification_report(test_Y, fitted_model.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC_AUC on Test\")\n",
    "print(\"===============\")\n",
    "for model in model_dict.keys():\n",
    "    if model not in [\"file_params\"]:\n",
    "        print(\"{}:{}{}\".format(model, \" \"*(13 - len(model)), find_roc_auc(model_dict.get(model), test_X, test_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC_AUC on Dev\")\n",
    "print(\"==============\")\n",
    "for model in model_dict.keys():\n",
    "    if model not in [\"file_params\"]:\n",
    "        print(\"{}:{}{}\".format(model, \" \"*(13 - len(model)), find_roc_auc(model_dict.get(model), dev_X, dev_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC_AUC on Training\")\n",
    "print(\"===================\")\n",
    "for model in model_dict.keys():\n",
    "    if model not in [\"file_params\"]:\n",
    "        print(\"{}:{}{}\".format(model, \" \"*(13 - len(model)), find_roc_auc(model_dict.get(model), X, Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySEfwFTbEOsU"
   },
   "source": [
    "# Break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gximuif9tUZe"
   },
   "outputs": [],
   "source": [
    "print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5tIApogtUce"
   },
   "outputs": [],
   "source": [
    "random_search_fitted_models[\"xgb\"].__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_ugRFjytUet"
   },
   "outputs": [],
   "source": [
    "random_search_fitted_models[\"lgbm\"].cv_results_#[\"param_num_leaves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJxn_V1lcnUd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2021.03.19_WOTUS_restart_v6.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
