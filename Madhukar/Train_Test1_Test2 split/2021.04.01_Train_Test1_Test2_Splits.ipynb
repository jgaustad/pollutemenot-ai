{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "controlled-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "central-notebook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14619, 29)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_csv(\"combined_regular_clean_with_ssurgo_variables.csv\")\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-phase",
   "metadata": {},
   "source": [
    "# Filter out bad longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "digital-tradition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14613, 29)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove longitude > -50 (bad datapoints)\n",
    "\n",
    "df_full = df_full[df_full.longitude < -50]\n",
    "df_full.shape # 6 records removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-future",
   "metadata": {},
   "source": [
    "# Filter out bad records\n",
    "\n",
    "- any records where the cwa_determination is contrary to expectations? That is, where none of cwa1 etc are 1 but the cwa_determination value is 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "transparent-purchase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%good records = 98%\n",
      "There are 2% bad records\n",
      "(14613, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cwa_determination</th>\n",
       "      <th>rha1</th>\n",
       "      <th>rha2</th>\n",
       "      <th>cwa1</th>\n",
       "      <th>cwa2</th>\n",
       "      <th>cwa3</th>\n",
       "      <th>cwa4</th>\n",
       "      <th>cwa5</th>\n",
       "      <th>cwa6</th>\n",
       "      <th>cwa7</th>\n",
       "      <th>cwa8</th>\n",
       "      <th>cwa9</th>\n",
       "      <th>potential_wetland</th>\n",
       "      <th>index</th>\n",
       "      <th>Index</th>\n",
       "      <th>mukey</th>\n",
       "      <th>hydclprs</th>\n",
       "      <th>aws025wta</th>\n",
       "      <th>drclassdcd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>292681.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.48</td>\n",
       "      <td>Moderately well drained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>292995.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4.65</td>\n",
       "      <td>Very poorly drained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>292980.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.67</td>\n",
       "      <td>Somewhat poorly drained</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cwa_determination  rha1  rha2  cwa1  cwa2  cwa3  cwa4  cwa5  cwa6  cwa7  \\\n",
       "36                  1     0     0     0     0     0     0     0     0     0   \n",
       "50                  1     0     0     0     0     0     0     0     0     0   \n",
       "56                  1     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "    cwa8  cwa9  potential_wetland  index  Index     mukey  hydclprs  \\\n",
       "36     0     0                  1     37     37  292681.0       0.0   \n",
       "50     0     0                  1     51     51  292995.0      96.0   \n",
       "56     0     0                  1     57     57  292980.0       8.0   \n",
       "\n",
       "    aws025wta               drclassdcd  \n",
       "36       4.48  Moderately well drained  \n",
       "50       4.65      Very poorly drained  \n",
       "56       4.67  Somewhat poorly drained  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any records where the cwa_determination is contrary to expectations? That is, where none of cwa1 etc\n",
    "# are 1 but the cwa_determination value is 1\n",
    "good_records = (df_full.apply(lambda x: \n",
    "               (np.sum(x.cwa1 + x.cwa2 + x.cwa3 + x.cwa4 + x.cwa5 + \n",
    "                       x.cwa6 + x.cwa7 + x.cwa8 + x.cwa9) > 0) * 1 \n",
    "               == x.cwa_determination, \n",
    "               axis=1))\n",
    "\n",
    "print(\"%good records = {}%\".format(round(np.mean(good_records) * 100)))\n",
    "print(\"There are {}% bad records\".format(100-round(np.mean(good_records) * 100)))\n",
    "print(df_full.shape)\n",
    "# peek at not good records to verify code\n",
    "df_full[~good_records].head(3).iloc[:,10:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "intimate-strain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14322, 29)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retain only the good records\n",
    "df_full = df_full[good_records]\n",
    "df_full.shape # 291 records removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-contest",
   "metadata": {},
   "source": [
    "# Drop St. Louis entirely (it has only 6 records, and is not being split in 70/15/15, and causing other issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "instrumental-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full[df_full.district != \"St. Louis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "direct-canvas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'jurisdiction_type', 'da_number',\n",
       "       'district', 'project_name', 'longitude', 'latitude',\n",
       "       'date_issued_or_denied', 'rha_determination', 'cwa_determination',\n",
       "       'rha1', 'rha2', 'cwa1', 'cwa2', 'cwa3', 'cwa4', 'cwa5', 'cwa6', 'cwa7',\n",
       "       'cwa8', 'cwa9', 'potential_wetland', 'index', 'Index', 'mukey',\n",
       "       'hydclprs', 'aws025wta', 'drclassdcd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-martial",
   "metadata": {},
   "source": [
    "# Split data into Train, Test1 and Test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "adjustable-surrey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alaska\n",
      "Original 0's and 1's\n",
      "346 101\n",
      "\n",
      "train total records 379\n",
      "train 0's and 1's:\n",
      "293 86\n",
      "\n",
      "test total records 68\n",
      "test 0's and 1's:\n",
      "53 15\n",
      "======================\n",
      "Albuquerque\n",
      "Original 0's and 1's\n",
      "121 7\n",
      "\n",
      "train total records 108\n",
      "train 0's and 1's:\n",
      "102 6\n",
      "\n",
      "test total records 20\n",
      "test 0's and 1's:\n",
      "19 1\n",
      "======================\n",
      "Baltimore\n",
      "Original 0's and 1's\n",
      "50 87\n",
      "\n",
      "train total records 116\n",
      "train 0's and 1's:\n",
      "42 74\n",
      "\n",
      "test total records 21\n",
      "test 0's and 1's:\n",
      "8 13\n",
      "======================\n",
      "Buffalo\n",
      "Original 0's and 1's\n",
      "119 158\n",
      "\n",
      "train total records 235\n",
      "train 0's and 1's:\n",
      "101 134\n",
      "\n",
      "test total records 42\n",
      "test 0's and 1's:\n",
      "18 24\n",
      "======================\n",
      "Charleston\n",
      "Original 0's and 1's\n",
      "1307 750\n",
      "\n",
      "train total records 1748\n",
      "train 0's and 1's:\n",
      "1111 637\n",
      "\n",
      "test total records 309\n",
      "test 0's and 1's:\n",
      "196 113\n",
      "======================\n",
      "Chicago\n",
      "Original 0's and 1's\n",
      "236 332\n",
      "\n",
      "train total records 482\n",
      "train 0's and 1's:\n",
      "200 282\n",
      "\n",
      "test total records 86\n",
      "test 0's and 1's:\n",
      "36 50\n",
      "======================\n",
      "Detroit\n",
      "Original 0's and 1's\n",
      "93 81\n",
      "\n",
      "train total records 147\n",
      "train 0's and 1's:\n",
      "79 68\n",
      "\n",
      "test total records 27\n",
      "test 0's and 1's:\n",
      "14 13\n",
      "======================\n",
      "Fort Worth\n",
      "Original 0's and 1's\n",
      "6 12\n",
      "\n",
      "train total records 15\n",
      "train 0's and 1's:\n",
      "5 10\n",
      "\n",
      "test total records 3\n",
      "test 0's and 1's:\n",
      "1 2\n",
      "======================\n",
      "Galveston\n",
      "Original 0's and 1's\n",
      "380 649\n",
      "\n",
      "train total records 874\n",
      "train 0's and 1's:\n",
      "323 551\n",
      "\n",
      "test total records 155\n",
      "test 0's and 1's:\n",
      "57 98\n",
      "======================\n",
      "Honolulu\n",
      "Original 0's and 1's\n",
      "22 9\n",
      "\n",
      "train total records 26\n",
      "train 0's and 1's:\n",
      "18 8\n",
      "\n",
      "test total records 5\n",
      "test 0's and 1's:\n",
      "4 1\n",
      "======================\n",
      "Huntington\n",
      "Original 0's and 1's\n",
      "296 27\n",
      "\n",
      "train total records 274\n",
      "train 0's and 1's:\n",
      "251 23\n",
      "\n",
      "test total records 49\n",
      "test 0's and 1's:\n",
      "45 4\n",
      "======================\n",
      "Jacksonville\n",
      "Original 0's and 1's\n",
      "35 54\n",
      "\n",
      "train total records 75\n",
      "train 0's and 1's:\n",
      "29 46\n",
      "\n",
      "test total records 14\n",
      "test 0's and 1's:\n",
      "6 8\n",
      "======================\n",
      "Kansas City\n",
      "Original 0's and 1's\n",
      "237 36\n",
      "\n",
      "train total records 232\n",
      "train 0's and 1's:\n",
      "201 31\n",
      "\n",
      "test total records 41\n",
      "test 0's and 1's:\n",
      "36 5\n",
      "======================\n",
      "Little Rock\n",
      "Original 0's and 1's\n",
      "125 47\n",
      "\n",
      "train total records 146\n",
      "train 0's and 1's:\n",
      "106 40\n",
      "\n",
      "test total records 26\n",
      "test 0's and 1's:\n",
      "19 7\n",
      "======================\n",
      "Los Angeles\n",
      "Original 0's and 1's\n",
      "171 32\n",
      "\n",
      "train total records 172\n",
      "train 0's and 1's:\n",
      "145 27\n",
      "\n",
      "test total records 31\n",
      "test 0's and 1's:\n",
      "26 5\n",
      "======================\n",
      "Louisville\n",
      "Original 0's and 1's\n",
      "394 54\n",
      "\n",
      "train total records 380\n",
      "train 0's and 1's:\n",
      "334 46\n",
      "\n",
      "test total records 68\n",
      "test 0's and 1's:\n",
      "60 8\n",
      "======================\n",
      "Memphis\n",
      "Original 0's and 1's\n",
      "147 13\n",
      "\n",
      "train total records 136\n",
      "train 0's and 1's:\n",
      "125 11\n",
      "\n",
      "test total records 24\n",
      "test 0's and 1's:\n",
      "22 2\n",
      "======================\n",
      "Mobile\n",
      "Original 0's and 1's\n",
      "356 76\n",
      "\n",
      "train total records 367\n",
      "train 0's and 1's:\n",
      "302 65\n",
      "\n",
      "test total records 65\n",
      "test 0's and 1's:\n",
      "54 11\n",
      "======================\n",
      "Nashville\n",
      "Original 0's and 1's\n",
      "125 14\n",
      "\n",
      "train total records 118\n",
      "train 0's and 1's:\n",
      "106 12\n",
      "\n",
      "test total records 21\n",
      "test 0's and 1's:\n",
      "19 2\n",
      "======================\n",
      "New England\n",
      "Original 0's and 1's\n",
      "19 10\n",
      "\n",
      "train total records 24\n",
      "train 0's and 1's:\n",
      "16 8\n",
      "\n",
      "test total records 5\n",
      "test 0's and 1's:\n",
      "3 2\n",
      "======================\n",
      "New Orleans\n",
      "Original 0's and 1's\n",
      "519 505\n",
      "\n",
      "train total records 870\n",
      "train 0's and 1's:\n",
      "441 429\n",
      "\n",
      "test total records 154\n",
      "test 0's and 1's:\n",
      "78 76\n",
      "======================\n",
      "New York\n",
      "Original 0's and 1's\n",
      "32 95\n",
      "\n",
      "train total records 107\n",
      "train 0's and 1's:\n",
      "27 80\n",
      "\n",
      "test total records 20\n",
      "test 0's and 1's:\n",
      "5 15\n",
      "======================\n",
      "Norfolk\n",
      "Original 0's and 1's\n",
      "337 302\n",
      "\n",
      "train total records 543\n",
      "train 0's and 1's:\n",
      "286 257\n",
      "\n",
      "test total records 96\n",
      "test 0's and 1's:\n",
      "51 45\n",
      "======================\n",
      "Omaha\n",
      "Original 0's and 1's\n",
      "405 109\n",
      "\n",
      "train total records 436\n",
      "train 0's and 1's:\n",
      "344 92\n",
      "\n",
      "test total records 78\n",
      "test 0's and 1's:\n",
      "61 17\n",
      "======================\n",
      "Philadelphia\n",
      "Original 0's and 1's\n",
      "59 37\n",
      "\n",
      "train total records 81\n",
      "train 0's and 1's:\n",
      "50 31\n",
      "\n",
      "test total records 15\n",
      "test 0's and 1's:\n",
      "9 6\n",
      "======================\n",
      "Pittsburgh\n",
      "Original 0's and 1's\n",
      "17 18\n",
      "\n",
      "train total records 29\n",
      "train 0's and 1's:\n",
      "14 15\n",
      "\n",
      "test total records 6\n",
      "test 0's and 1's:\n",
      "3 3\n",
      "======================\n",
      "Portland\n",
      "Original 0's and 1's\n",
      "53 53\n",
      "\n",
      "train total records 90\n",
      "train 0's and 1's:\n",
      "45 45\n",
      "\n",
      "test total records 16\n",
      "test 0's and 1's:\n",
      "8 8\n",
      "======================\n",
      "Rock Island\n",
      "Original 0's and 1's\n",
      "26 53\n",
      "\n",
      "train total records 67\n",
      "train 0's and 1's:\n",
      "22 45\n",
      "\n",
      "test total records 12\n",
      "test 0's and 1's:\n",
      "4 8\n",
      "======================\n",
      "Sacramento\n",
      "Original 0's and 1's\n",
      "193 93\n",
      "\n",
      "train total records 243\n",
      "train 0's and 1's:\n",
      "164 79\n",
      "\n",
      "test total records 43\n",
      "test 0's and 1's:\n",
      "29 14\n",
      "======================\n",
      "San Francisco\n",
      "Original 0's and 1's\n",
      "18 69\n",
      "\n",
      "train total records 73\n",
      "train 0's and 1's:\n",
      "15 58\n",
      "\n",
      "test total records 14\n",
      "test 0's and 1's:\n",
      "3 11\n",
      "======================\n",
      "Savannah\n",
      "Original 0's and 1's\n",
      "106 25\n",
      "\n",
      "train total records 111\n",
      "train 0's and 1's:\n",
      "90 21\n",
      "\n",
      "test total records 20\n",
      "test 0's and 1's:\n",
      "16 4\n",
      "======================\n",
      "Seattle\n",
      "Original 0's and 1's\n",
      "33 69\n",
      "\n",
      "train total records 86\n",
      "train 0's and 1's:\n",
      "28 58\n",
      "\n",
      "test total records 16\n",
      "test 0's and 1's:\n",
      "5 11\n",
      "======================\n",
      "St. Paul\n",
      "Original 0's and 1's\n",
      "1367 105\n",
      "\n",
      "train total records 1251\n",
      "train 0's and 1's:\n",
      "1162 89\n",
      "\n",
      "test total records 221\n",
      "test 0's and 1's:\n",
      "205 16\n",
      "======================\n",
      "Tulsa\n",
      "Original 0's and 1's\n",
      "100 36\n",
      "\n",
      "train total records 115\n",
      "train 0's and 1's:\n",
      "85 30\n",
      "\n",
      "test total records 21\n",
      "test 0's and 1's:\n",
      "15 6\n",
      "======================\n",
      "Vicksburg\n",
      "Original 0's and 1's\n",
      "969 10\n",
      "\n",
      "train total records 832\n",
      "train 0's and 1's:\n",
      "824 8\n",
      "\n",
      "test total records 147\n",
      "test 0's and 1's:\n",
      "145 2\n",
      "======================\n",
      "Walla Walla\n",
      "Original 0's and 1's\n",
      "11 5\n",
      "\n",
      "train total records 13\n",
      "train 0's and 1's:\n",
      "9 4\n",
      "\n",
      "test total records 3\n",
      "test 0's and 1's:\n",
      "2 1\n",
      "======================\n",
      "Wilmington\n",
      "Original 0's and 1's\n",
      "379 974\n",
      "\n",
      "train total records 1150\n",
      "train 0's and 1's:\n",
      "322 828\n",
      "\n",
      "test total records 203\n",
      "test 0's and 1's:\n",
      "57 146\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "# verify if things are indeed working as expected\n",
    "\n",
    "mygroup = df_full.groupby(\"district\")\n",
    "\n",
    "for group in mygroup:\n",
    "    print(group[0])\n",
    "    print(\"Original 0's and 1's\")\n",
    "    data_count_1 = group[1][\"cwa_determination\"][group[1][\"cwa_determination\"]==1].shape[0]\n",
    "    data_count_0 = group[1][\"cwa_determination\"][group[1][\"cwa_determination\"]==0].shape[0]    \n",
    "    print(data_count_0, data_count_1)\n",
    "    print()\n",
    "    \n",
    "    train, test = (train_test_split(group[1],\n",
    "                                    test_size=0.15,\n",
    "                                    random_state = random_state, \n",
    "                                    stratify=group[1][\"cwa_determination\"]))\n",
    "    \n",
    "    print(\"train total records\", train.shape[0])\n",
    "    train_count_1 = train[\"cwa_determination\"][train[\"cwa_determination\"]==1].shape[0]\n",
    "    train_count_0 = train[\"cwa_determination\"][train[\"cwa_determination\"]==0].shape[0]    \n",
    "    print(\"train 0's and 1's:\")\n",
    "    print(train_count_0, train_count_1)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print(\"test total records\", test.shape[0])\n",
    "    print(\"test 0's and 1's:\")\n",
    "    test_count_1 = test[\"cwa_determination\"][test[\"cwa_determination\"]==1].shape[0]\n",
    "    test_count_0 = test[\"cwa_determination\"][test[\"cwa_determination\"]==0].shape[0]    \n",
    "    print(test_count_0, test_count_1)    \n",
    "    \n",
    "    print(\"======================\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "domestic-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the modified stratification\n",
    "\n",
    "df_train = pd.DataFrame()\n",
    "df_test1 = pd.DataFrame()\n",
    "df_test2 = pd.DataFrame()\n",
    "\n",
    "df_train_ = pd.DataFrame()\n",
    "df_test1_ = pd.DataFrame()\n",
    "df_test2_ = pd.DataFrame()\n",
    "\n",
    "for group in df_full.groupby(\"district\"):\n",
    "    try:\n",
    "        df_train_temp_, df_test2_ = (train_test_split(group[1], \n",
    "                                                 test_size=0.15, \n",
    "                                                 random_state = random_state, \n",
    "                                                 stratify=group[1][\"cwa_determination\"])) # 15% test\n",
    "\n",
    "        df_train_, df_test1_ = (train_test_split(df_train_temp_, \n",
    "                                                 test_size=0.17647, \n",
    "                                                 random_state = random_state, \n",
    "                                                 stratify=df_train_temp_[\"cwa_determination\"])) # 70% train, 15% dev\n",
    "    except Exception as e:\n",
    "        print(group[0], e)\n",
    "    df_train = pd.concat([df_train, df_train_])\n",
    "    df_test1 = pd.concat([df_test1, df_test1_])\n",
    "    df_test2 = pd.concat([df_test2, df_test2_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "present-witness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (9991, 29) (fraction = 0.7)\n",
      "Test1   : (2160, 29) (fraction = 0.15)\n",
      "Test2   : (2165, 29) (fraction = 0.15)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training: {} (fraction = {})\".format(df_train.shape, round(df_train.shape[0] / df_full.shape[0], 2)))\n",
    "print(\"Test1   : {} (fraction = {})\".format(df_test1.shape, round(df_test1.shape[0] / df_full.shape[0], 2)))\n",
    "print(\"Test2   : {} (fraction = {})\".format(df_test2.shape, round(df_test2.shape[0] / df_full.shape[0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "disabled-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(df_train, open(\"2021.04.01_train_dataset\",\"wb\"), protocol=3)\n",
    "# pickle.dump(df_test1, open(\"2021.04.01_test1_dataset\",\"wb\"), protocol=3)\n",
    "# pickle.dump(df_test2, open(\"2021.04.01_test2_dataset\",\"wb\"), protocol=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-cowboy",
   "metadata": {},
   "source": [
    "# appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "opening-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def find_duplicates(df):\n",
    "    l1 = df.da_number#[\"A\", \"A\", \"B\"]\n",
    "    l2 = df.da_number.unique()#[\"A\", \"B\"]\n",
    "    c1 = Counter(l1)\n",
    "    c2 = Counter(l2)\n",
    "\n",
    "    diff = c1-c2\n",
    "    duplicate_list = list(diff.elements())\n",
    "#     print (len(list(diff.elements())))\n",
    "#     print (list(diff.elements()))\n",
    "    return duplicate_list\n",
    "\n",
    "\n",
    "train_duplicate_list = find_duplicates(df_train)\n",
    "test1_duplicate_list = find_duplicates(df_test1)\n",
    "test2_duplicate_list = find_duplicates(df_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "anticipated-fellow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14316, 14316)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.shape[0], len(df_full.da_number.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "pacific-organizer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9991, 9991)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape[0], len(df_train.da_number.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "suitable-priority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2160, 2160)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test1.shape[0], len(df_test1.da_number.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "canadian-essex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2165, 2165)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2.shape[0], len(df_test2.da_number.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-hindu",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
