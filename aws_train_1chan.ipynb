{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "paperback-dayton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0 tf\n",
      "2.4.3 keras\n"
     ]
    }
   ],
   "source": [
    "### Init network Build\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "import keras\n",
    "import time\n",
    "import tensorflow as tf\n",
    "print(tf.__version__, 'tf')\n",
    "print(keras.__version__, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "large-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.read_csv('image_metrics_031021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fleet-inquiry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99707, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>img_res</th>\n",
       "      <th>img_type</th>\n",
       "      <th>img_index</th>\n",
       "      <th>da_num</th>\n",
       "      <th>img_path</th>\n",
       "      <th>da_number</th>\n",
       "      <th>cwa_determination</th>\n",
       "      <th>metrics</th>\n",
       "      <th>mean</th>\n",
       "      <th>stdev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>lores</td>\n",
       "      <td>mndwi</td>\n",
       "      <td>292</td>\n",
       "      <td>LRC-2003-22227</td>\n",
       "      <td>/data/image_final2/GEE_images_final2_lores_mnd...</td>\n",
       "      <td>LRC-2003-22227</td>\n",
       "      <td>1</td>\n",
       "      <td>(-0.3306894463763968, 0.09898692070930509)</td>\n",
       "      <td>-0.330689</td>\n",
       "      <td>0.098987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hires</td>\n",
       "      <td>mndwi</td>\n",
       "      <td>8157</td>\n",
       "      <td>SAC-2007-01367</td>\n",
       "      <td>/data/image_final2/GEE_images_final2_hires_mnd...</td>\n",
       "      <td>SAC-2007-01367</td>\n",
       "      <td>0</td>\n",
       "      <td>(-0.40988840562690426, 0.19788100896017022)</td>\n",
       "      <td>-0.409888</td>\n",
       "      <td>0.197881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>lores</td>\n",
       "      <td>srtm</td>\n",
       "      <td>5495</td>\n",
       "      <td>MVP-2020-00252-MHK</td>\n",
       "      <td>/data/image_final2/GEE_images_final2_lores_srt...</td>\n",
       "      <td>MVP-2020-00252-MHK</td>\n",
       "      <td>0</td>\n",
       "      <td>(211.5080108642578, 18.443937482788826)</td>\n",
       "      <td>211.508011</td>\n",
       "      <td>18.443937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>lores</td>\n",
       "      <td>gmndwi</td>\n",
       "      <td>10297</td>\n",
       "      <td>SAM-2016-00139-MJF</td>\n",
       "      <td>/data/image_final2/GEE_images_final2_lores_gmn...</td>\n",
       "      <td>SAM-2016-00139-MJF</td>\n",
       "      <td>1</td>\n",
       "      <td>(0.340306, 0.6714834)</td>\n",
       "      <td>0.340306</td>\n",
       "      <td>0.671483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>hires</td>\n",
       "      <td>seasonality</td>\n",
       "      <td>8500</td>\n",
       "      <td>SAC-2016-00087</td>\n",
       "      <td>/data/image_final2/GEE_images_final2_hires_sea...</td>\n",
       "      <td>SAC-2016-00087</td>\n",
       "      <td>1</td>\n",
       "      <td>(0.02587890625, 0.4714458509886673)</td>\n",
       "      <td>0.025879</td>\n",
       "      <td>0.471446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 img_res     img_type  img_index              da_num  \\\n",
       "0           0   lores        mndwi        292      LRC-2003-22227   \n",
       "1           1   hires        mndwi       8157      SAC-2007-01367   \n",
       "2           2   lores         srtm       5495  MVP-2020-00252-MHK   \n",
       "3           3   lores       gmndwi      10297  SAM-2016-00139-MJF   \n",
       "4           4   hires  seasonality       8500      SAC-2016-00087   \n",
       "\n",
       "                                            img_path           da_number  \\\n",
       "0  /data/image_final2/GEE_images_final2_lores_mnd...      LRC-2003-22227   \n",
       "1  /data/image_final2/GEE_images_final2_hires_mnd...      SAC-2007-01367   \n",
       "2  /data/image_final2/GEE_images_final2_lores_srt...  MVP-2020-00252-MHK   \n",
       "3  /data/image_final2/GEE_images_final2_lores_gmn...  SAM-2016-00139-MJF   \n",
       "4  /data/image_final2/GEE_images_final2_hires_sea...      SAC-2016-00087   \n",
       "\n",
       "   cwa_determination                                      metrics        mean  \\\n",
       "0                  1   (-0.3306894463763968, 0.09898692070930509)   -0.330689   \n",
       "1                  0  (-0.40988840562690426, 0.19788100896017022)   -0.409888   \n",
       "2                  0      (211.5080108642578, 18.443937482788826)  211.508011   \n",
       "3                  1                        (0.340306, 0.6714834)    0.340306   \n",
       "4                  1          (0.02587890625, 0.4714458509886673)    0.025879   \n",
       "\n",
       "       stdev  \n",
       "0   0.098987  \n",
       "1   0.197881  \n",
       "2  18.443937  \n",
       "3   0.671483  \n",
       "4   0.471446  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_merged.shape)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "attempted-proof",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MVP    14379\n",
       "MVN     9281\n",
       "SAC     7953\n",
       "SWG     7717\n",
       "NAO     6484\n",
       "MVK     6079\n",
       "LRC     5317\n",
       "NWO     4676\n",
       "POA     4452\n",
       "SAW     3385\n",
       "LRH     3148\n",
       "LRL     3062\n",
       "SAM     3029\n",
       "LRB     2889\n",
       "NWK     2732\n",
       "LRE     1752\n",
       "SWL     1700\n",
       "NAN     1674\n",
       "MVM     1567\n",
       "NAB     1400\n",
       "NWP     1023\n",
       "NWS     1020\n",
       "NAP      940\n",
       "SAS      874\n",
       "MVR      790\n",
       "SAJ      630\n",
       "SWT      428\n",
       "POH      340\n",
       "LRP      329\n",
       "NAE      290\n",
       "NWW      160\n",
       "LRN      157\n",
       "MVS       50\n",
       "Name: da_num, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f3 = df_merged.da_num.apply(lambda x: x[:3])\n",
    "f3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "continental-reservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412\n"
     ]
    }
   ],
   "source": [
    "dir2 = '/data/training_data4/'\n",
    "train_X = [f for f in Path(dir2).iterdir() if 'SAW' in f.name]\n",
    "print(len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "parliamentary-smart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SAW-2019-01405'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0].name[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aerial-laptop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(train_X[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nervous-jackson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_label(da_num_i, df_merged = df_merged):\n",
    "    return int(df_merged[df_merged.da_num == da_num_i].cwa_determination.iloc[0])\n",
    "get_label(train_X[0].name[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "white-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = [get_label(x.name[:-4]) for x in train_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "humanitarian-society",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412 412\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X), len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "independent-subject",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_3d(p):\n",
    "    x = np.load(p)\n",
    "    return np.concatenate([x,x,x]).reshape(256,256,3)\n",
    "load_3d(train_X[9]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "arabic-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_train_X = [load_3d(f).reshape(-1,256,256,3) for f in train_X]\n",
    "arr_train_X = [x + .756 for x in arr_train_X]\n",
    "arr_train_X = [x * 1/1.5 for x in arr_train_X]\n",
    "\n",
    "#arr_train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "thermal-internship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412\n",
      "412\n",
      "0.7111650485436893\n"
     ]
    }
   ],
   "source": [
    "print(len(arr_train_X))\n",
    "print(len(train_y))\n",
    "print(np.mean(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-marine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "seventh-coach",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0174909"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = [np.max(x) for x in arr_train_X]\n",
    "np.nanmean(means)\n",
    "#for x in arr_train_X:\n",
    "#    if np.isnan(np.mean(x)):\n",
    "#        print(x)\n",
    "#        for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "usual-worry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_train_X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "technical-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the images with vgg16\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "vgg16_model1 = VGG16(include_top=False, weights='imagenet', input_shape=(256,256, 3))\n",
    "transformed = [vgg16_model1.predict(x) for x in arr_train_X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "living-italic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8, 8, 512)\n",
      "0.0\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "type(transformed[0])\n",
    "print(transformed[0].shape)\n",
    "print(np.min(transformed[0]))\n",
    "print(transformed[0][0,2,6,12:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "european-engineer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'stdev')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#investigate transformed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "m = [np.mean(x) for x in transformed]\n",
    "s = [np.std(x) for x in transformed]\n",
    "fig, ax = plt.subplots(2, figsize = (7,7))\n",
    "ax[0].hist(m)\n",
    "ax[0].set_title('mean')\n",
    "ax[1].hist(s)\n",
    "ax[1].set_title('stdev')\n",
    "#mos = np.mean([np.std(x) for x in transformed])\n",
    "#sos = np.std([np.std(x) for x in transformed])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "catholic-month",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_111 (Dense)            (None, 8, 8, 512)         262656    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 8, 8, 256)         131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 8, 8, 128)         32896     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 438,657\n",
      "Trainable params: 436,865\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Concatenate, Input, Lambda, Flatten, Softmax, BatchNormalization, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "top_model_vgg16 = Sequential()\n",
    "\n",
    "top_model_vgg16.add(Dense(512,activation='relu', input_shape=(8,8,512,)))\n",
    "top_model_vgg16.add(LeakyReLU(alpha = 0.1))\n",
    "top_model_vgg16.add(BatchNormalization())\n",
    "#top_model_vgg16.add(Dropout(0.5))\n",
    "\n",
    "#top_model_vgg16.add(Dense(512, activation='relu'))\n",
    "#top_model_vgg16.add(LeakyReLU(alpha = 0.1))\n",
    "#top_model_vgg16.add(BatchNormalization())\n",
    "#top_model_vgg16.add(Dropout(0.2))\n",
    "\n",
    "#top_model_vgg16.add(Dense(256, activation='relu'))\n",
    "#top_model_vgg16.add(LeakyReLU(alpha = 0.1))\n",
    "#top_model_vgg16.add(BatchNormalization())\n",
    "#top_model_vgg16.add(Dropout(0.5))\n",
    "\n",
    "top_model_vgg16.add(Dense(256, activation='relu'))\n",
    "top_model_vgg16.add(LeakyReLU(alpha = 0.1))\n",
    "top_model_vgg16.add(BatchNormalization())\n",
    "#top_model_vgg16.add(Dropout(0.2))\n",
    "\n",
    "top_model_vgg16.add(Dense(128, activation='relu'))\n",
    "top_model_vgg16.add(LeakyReLU(alpha = 0.1))\n",
    "top_model_vgg16.add(BatchNormalization())\n",
    "#top_model_vgg16.add(Dropout(0.5))\n",
    "\n",
    "#top_model_vgg16.add(Dense(128, activation='relu'))\n",
    "#top_model_vgg16.add(LeakyReLU(alpha = 0.1))\n",
    "#top_model_vgg16.add(BatchNormalization())\n",
    "#top_model_vgg16.add(Dropout(0.2))\n",
    "\n",
    "#top_model_vgg16.add(Dense(64, activation='relu'))\n",
    "#top_model_vgg16.add(LeakyReLU(alpha = 0.1))\n",
    "#top_model_vgg16.add(BatchNormalization())\n",
    "#top_model_vgg16.add(Dropout(0.5))\n",
    "\n",
    "#top_model_vgg16.add(Dense(64, activation='relu'))\n",
    "#model.add(LeakyReLU(alpha = 0.1))\n",
    "#model.add(BatchNormalization())\n",
    "#top_model_vgg16.add(Dropout(0.2))\n",
    "\n",
    "#top_model_vgg16.add(Dense(32, activation='relu'))\n",
    "#model.add(LeakyReLU(alpha = 0.1))\n",
    "#model.add(BatchNormalization())\n",
    "#top_model_vgg16.add(Dropout(0.5))\n",
    "\n",
    "top_model_vgg16.add(Flatten())\n",
    "#top_model_vgg16.add(Dense(32,activation='relu'))\n",
    "#top_model_vgg16.add(Dropout(0.2))\n",
    "top_model_vgg16.add(Dense(1, activation = 'sigmoid')), \n",
    "\n",
    "#top_model_vgg16.add(Softmax())\n",
    "\n",
    "top_model_vgg16.summary()\n",
    "\n",
    "top_model_vgg16.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "animated-championship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412, 8, 8, 512) (412,)\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8423 - accuracy: 0.5218\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6231 - accuracy: 0.6723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5669 - accuracy: 0.6893\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5280 - accuracy: 0.7257\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5007 - accuracy: 0.7403\n",
      "Train time: 1.0242128372192383\n"
     ]
    }
   ],
   "source": [
    "train_X_transform, train_y = np.array(transformed).reshape(412,8,8,512), np.array(train_y)\n",
    "print(train_X_transform.shape, train_y.shape)\n",
    "# Train the top model with the vgg16 extracted features\n",
    "t0 = time.time()\n",
    "top_model_vgg16.fit(train_X_transform, train_y, epochs=5, batch_size=412)#, validation_split = 0.2)\n",
    "print(\"Train time:\", time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "superior-sister",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model_vgg16.predict(train_X_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-large",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "intense-columbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_20 (Flatten)         (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 512)               16777728  \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 16,778,241\n",
      "Trainable params: 16,778,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# baseline model\n",
    "# create model\n",
    "model22 = Sequential()\n",
    "model22.add(Flatten(input_shape=(8,8,512,)))\n",
    "model22.add(Dense(512,activation='relu'))\n",
    "model22.add(Flatten())\n",
    "model22.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model22.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model22.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "internal-treat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412, 8, 8, 512) (412,)\n"
     ]
    }
   ],
   "source": [
    "train_X_transform, train_y = np.array(transformed).reshape(412,8,8,512), np.array(train_y)\n",
    "print(train_X_transform.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "consecutive-paris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8142 - accuracy: 0.3010\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 11.9648 - accuracy: 0.7112\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.4250 - accuracy: 0.7112\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3999 - accuracy: 0.7112\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2425 - accuracy: 0.7112\n",
      "Train time: 0.6344654560089111\n"
     ]
    }
   ],
   "source": [
    "# Train the top model with the vgg16 extracted features\n",
    "t0 = time.time()\n",
    "model22.fit(train_X_transform, train_y, epochs=5, batch_size=412)#, validation_split = 0.2)\n",
    "print(\"Train time:\", time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-poker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "increasing-wheat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 11 01:47:18 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   46C    P0    71W / 149W |  10877MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "therapeutic-rescue",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "vgg16_model1 = VGG16(include_top=False, weights='imagenet', input_shape=(256,256, 3))\n",
    "#vgg16_model2 = VGG16(include_top=False, weights='imagenet', input_shape=(256,256, 3))\n",
    "#vgg16_model3 = VGG16(include_top=False, weights='imagenet', input_shape=(256,256, 3))\n",
    "\n",
    "vgg16_model1.trainable = False\n",
    "#vgg16_model2.trainable = False\n",
    "#vgg16_model3.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "earned-edwards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256, 256, 3)\n",
      "(None, 8, 8, 512)\n",
      "(None, 8, 8, 10)\n",
      "(None, 640)\n",
      "(None, 10)\n",
      "(None, 2)\n",
      "(None, 2)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Concatenate, Input, Lambda, Flatten, Softmax\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "num_channels = 3\n",
    "input = Input(shape=(256,256, num_channels))\n",
    "\n",
    "branch_outputs = []\n",
    "\n",
    "# loop for however many branches you want to use.  (each branch needs 3 channel depth)\n",
    "\n",
    "# create looping so that vgg16 model input is created ie 256,256,3\n",
    "print(input.shape)\n",
    "#out = Lambda(lambda x: x[:,:,:,i:i+3])(input)\n",
    "#print(out.shape)\n",
    "\n",
    "# Setting up your layers in each branch: (currently each branch is identical architecture.)\n",
    "out = Sequential(vgg16_model1)(input)   # use pretrained and loaded vgg16\n",
    "\n",
    "print(out.shape)\n",
    "out = Dense(10)(out)\n",
    "print(out.shape)\n",
    "out = Flatten()(out)\n",
    "print(out.shape)\n",
    "branch_outputs.append(out)\n",
    "\n",
    "# Concatenating the branches outputs:\n",
    "#out = Concatenate()(branch_outputs)\n",
    "#print(out.shape)\n",
    "\n",
    "# Add final dense layers and softmax\n",
    "out = Dense(20)(out)\n",
    "out = Dense(10)(out)\n",
    "print(out.shape)\n",
    "out = Dense(6)(out)\n",
    "out = Dense(2)(out)\n",
    "print(out.shape)\n",
    "out = Softmax()(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "angry-interim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 8, 8, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 8, 8, 10)          5130      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 20)                12820     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 14        \n",
      "_________________________________________________________________\n",
      "softmax_4 (Softmax)          (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 14,732,928\n",
      "Trainable params: 18,240\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=input, outputs=out)   \n",
    "model.summary()\n",
    "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "premium-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "moderate-gathering",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 3)\n",
      "[[0.1622066  0.83779347]]\n",
      "time taken: 6.368284225463867 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "test_input = np.random.rand(256,256,3)\n",
    "test_input = test_input.reshape(1, 256,256, 3)\n",
    "print(test_input.shape)\n",
    "t0 = time.time()\n",
    "print(model.predict(test_input))\n",
    "print(f\"time taken: {time.time()-t0} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "satellite-sacrifice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6/6 [==============================] - 4s 590ms/step - loss: 7.6871 - accuracy: 0.2888 - val_loss: 7.6871 - val_accuracy: 0.2892\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 3s 543ms/step - loss: 7.6871 - accuracy: 0.2888 - val_loss: 7.6871 - val_accuracy: 0.2892\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 7.6871 - accuracy: 0.2888 - val_loss: 7.6871 - val_accuracy: 0.2892\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 3s 542ms/step - loss: 7.6871 - accuracy: 0.2888 - val_loss: 7.6871 - val_accuracy: 0.2892\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 3s 542ms/step - loss: 7.6871 - accuracy: 0.2888 - val_loss: 7.6871 - val_accuracy: 0.2892\n",
      "Train time: 20.48793864250183\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "model.fit(arr_train_X, arr_train_y, epochs=5, batch_size=64, validation_split = 0.2)#, workers=4, use_multiprocessing=True)\n",
    "print(\"Train time:\", time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "martial-sculpture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 8, 8, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8, 8, 10)          5130      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 20)                12820     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 126       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 14        \n",
      "_________________________________________________________________\n",
      "softmax_2 (Softmax)          (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 14,732,778\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 18,090\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_layer = model.get_layer(name='sequential_2', index=None)\n",
    "#model.get_layer(name='dense_8', index=None).trainable = False\n",
    "model.get_layer(name='dense_9', index=None).trainable = False\n",
    "model.get_layer(name='dense_10', index=None).trainable = False\n",
    "model.get_layer(name='dense_11', index=None).trainable = False\n",
    "model.get_layer(name='dense_12', index=None).trainable = False\n",
    "\n",
    "vgg_layer.trainable = True\n",
    "model.summary()\n",
    "opt = keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "monthly-polyester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/9 [=====>........................] - ETA: 1s - loss: 7.6795 - accuracy: 0.6250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1532s vs `on_train_batch_end` time: 0.3289s). Check your callbacks.\n",
      "9/9 [==============================] - 15s 2s/step - loss: 7.6771 - accuracy: 0.5970 - val_loss: 7.6763 - val_accuracy: 0.5882\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 4s 480ms/step - loss: 7.6771 - accuracy: 0.5970 - val_loss: 7.6763 - val_accuracy: 0.5882\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 4s 481ms/step - loss: 7.6771 - accuracy: 0.5970 - val_loss: 7.6763 - val_accuracy: 0.5882\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 4s 481ms/step - loss: 7.6771 - accuracy: 0.5970 - val_loss: 7.6763 - val_accuracy: 0.5882\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 4s 479ms/step - loss: 7.6771 - accuracy: 0.5970 - val_loss: 7.6763 - val_accuracy: 0.5882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9c3eb82278>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(arr_train_X, arr_train_y, epochs=5, batch_size=16, validation_split = 0.2)#, workers=4, use_multiprocessing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-headline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-equivalent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sustained-structure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5952380952380952"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(arr_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "unlike-rapid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.1937740e-31]\n",
      " [1.0000000e+00 1.2457646e-30]\n",
      " [1.0000000e+00 3.6220060e-25]\n",
      " [1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "x = model.predict_on_batch(arr_train_X[:10])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-retention",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
