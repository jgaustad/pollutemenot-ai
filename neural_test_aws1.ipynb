{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worth-tulsa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1 tf\n",
      "2.4.3 keras\n"
     ]
    }
   ],
   "source": [
    "### Init network Build\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "import keras\n",
    "import time\n",
    "import tensorflow as tf\n",
    "print(tf.__version__, 'tf')\n",
    "print(keras.__version__, 'keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sticky-longitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9946623771434656096\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vertical-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.4.1 tf\n",
    "#2.4.3 keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "white-momentum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb 28 07:29:51 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   39C    P8    27W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "qualified-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "# create a service key json file and point to it here,   I will put a copy of the .json key I am using in slack.\n",
    "storage_client = storage.Client.from_service_account_json('access_key1.json')  # create a service key json file and point to it here\n",
    "\n",
    "bucket_name = 'pollutemenot-ai'\n",
    "bucket = storage_client.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "existing-beginning",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr+rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr+rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr+rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr+rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrfinished in  0.10796520709991456 minutes.\n"
     ]
    }
   ],
   "source": [
    "#download files\n",
    "t0 = time.time()\n",
    "prefix = 'GEE_images_final2/'\n",
    "dl_dir = 'image_final2/'\n",
    "blobs = bucket.list_blobs(prefix=prefix)  # Get list of files\n",
    "for blob in blobs:\n",
    "    filename = blob.name.replace('/', '_') \n",
    "    if Path(dl_dir + filename).is_file(): \n",
    "        print('r', end = '')\n",
    "        continue  # this file is already downloaded so skip download\n",
    "    else:\n",
    "        try:\n",
    "            blob.download_to_filename(dl_dir + filename)  # Download\n",
    "            print('+', end = '')\n",
    "        except:\n",
    "            print('error, waiting 5sec and trying again.')\n",
    "            time.sleep(5)\n",
    "            blob.download_to_filename(dl_dir + filename)  # Download\n",
    "            print('+', end = '')\n",
    "print('finished in ', (time.time()-t0)/60, 'minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "maritime-virtue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15321\n"
     ]
    }
   ],
   "source": [
    "tif_list = [f for f in Path(dl_dir).iterdir() if '.tif' in str(f)]\n",
    "print(len(tif_list))\n",
    "#tif_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "secure-arbor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jurisdiction_type</th>\n",
       "      <th>da_number</th>\n",
       "      <th>district</th>\n",
       "      <th>project_name</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>date_issued_or_denied</th>\n",
       "      <th>rha_determination</th>\n",
       "      <th>cwa_determination</th>\n",
       "      <th>rha1</th>\n",
       "      <th>...</th>\n",
       "      <th>cwa1</th>\n",
       "      <th>cwa2</th>\n",
       "      <th>cwa3</th>\n",
       "      <th>cwa4</th>\n",
       "      <th>cwa5</th>\n",
       "      <th>cwa6</th>\n",
       "      <th>cwa7</th>\n",
       "      <th>cwa8</th>\n",
       "      <th>cwa9</th>\n",
       "      <th>potential_wetland</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAPANOS</td>\n",
       "      <td>LRB-1983-10120</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>Trade-A-Yacht (Hibiscus Harbor - Union Springs...</td>\n",
       "      <td>-76.70773</td>\n",
       "      <td>42.85821</td>\n",
       "      <td>6/19/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RAPANOS</td>\n",
       "      <td>LRB-1985-69031</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>POOLEY, MARK A.</td>\n",
       "      <td>-75.85524</td>\n",
       "      <td>43.15230</td>\n",
       "      <td>7/7/2016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RAPANOS</td>\n",
       "      <td>LRB-1986-99614</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>Bellamy, Michael (previous: MACKO, JOHN)</td>\n",
       "      <td>-78.04046</td>\n",
       "      <td>42.68911</td>\n",
       "      <td>10/12/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RAPANOS</td>\n",
       "      <td>LRB-1990-97632</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>WESTWOOD COUNTRY CLUB</td>\n",
       "      <td>-78.77134</td>\n",
       "      <td>42.97994</td>\n",
       "      <td>6/28/2016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RAPANOS</td>\n",
       "      <td>LRB-1991-98611</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>MODERN LANDFILL INCORPORATED</td>\n",
       "      <td>-78.97142</td>\n",
       "      <td>43.21616</td>\n",
       "      <td>3/22/2016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  jurisdiction_type       da_number district  \\\n",
       "0           RAPANOS  LRB-1983-10120  Buffalo   \n",
       "1           RAPANOS  LRB-1985-69031  Buffalo   \n",
       "2           RAPANOS  LRB-1986-99614  Buffalo   \n",
       "3           RAPANOS  LRB-1990-97632  Buffalo   \n",
       "4           RAPANOS  LRB-1991-98611  Buffalo   \n",
       "\n",
       "                                        project_name  longitude  latitude  \\\n",
       "0  Trade-A-Yacht (Hibiscus Harbor - Union Springs...  -76.70773  42.85821   \n",
       "1                                    POOLEY, MARK A.  -75.85524  43.15230   \n",
       "2           Bellamy, Michael (previous: MACKO, JOHN)  -78.04046  42.68911   \n",
       "3                              WESTWOOD COUNTRY CLUB  -78.77134  42.97994   \n",
       "4                       MODERN LANDFILL INCORPORATED  -78.97142  43.21616   \n",
       "\n",
       "  date_issued_or_denied  rha_determination  cwa_determination  rha1  ...  \\\n",
       "0             6/19/2020                  0                  0     0  ...   \n",
       "1              7/7/2016                  0                  1     0  ...   \n",
       "2            10/12/2017                  0                  1     0  ...   \n",
       "3             6/28/2016                  0                  1     0  ...   \n",
       "4             3/22/2016                  0                  1     0  ...   \n",
       "\n",
       "   cwa1  cwa2  cwa3  cwa4  cwa5  cwa6  cwa7  cwa8  cwa9  potential_wetland  \n",
       "0     0     0     0     0     0     0     0     0     0                  1  \n",
       "1     0     0     1     0     0     0     0     0     0                  0  \n",
       "2     1     0     0     0     0     0     0     0     0                  0  \n",
       "3     1     0     1     0     0     0     0     0     0                  1  \n",
       "4     0     0     1     0     1     1     0     0     0                  1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "datapath = \"Madhukar/Data_combined_regular_clean.csv\"\n",
    "df = pd.read_csv(datapath, encoding = \"ISO-8859-1\")\n",
    "df.head()#.iloc[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "forward-plymouth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9212\n",
      "6109\n"
     ]
    }
   ],
   "source": [
    "# investigate files\n",
    "hires = [f for f in tif_list if 'hires' in str(f)]\n",
    "lores = [f for f in tif_list if 'lores' in str(f)]\n",
    "\n",
    "from collections import defaultdict\n",
    "d = defaultdict(list)\n",
    "\n",
    "for image in tif_list:\n",
    "    d[image.name.split('_')[6]].append(image)\n",
    "\n",
    "\n",
    "print(len(hires))\n",
    "print(len(lores))\n",
    "#for i in range(100,110):\n",
    "#   print(tif_list[i].name.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "global-stocks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVN-2020-00278-ST 10\n",
      "image_final2/GEE_images_final2_hires_mndwi_4089_MVN-2020-00278-ST_mndwi_hires.tif\n",
      "image_final2/GEE_images_final2_hires_seasonality_4089_MVN-2020-00278-ST_seasonality_hires.tif\n",
      "image_final2/GEE_images_final2_hires_gmndwi_4089_MVN-2020-00278-ST_gmndwi_hires.tif\n",
      "image_final2/GEE_images_final2_lores_srtm_4089_MVN-2020-00278-ST_srtm_lores.tif\n",
      "image_final2/GEE_images_final2_lores_gmndwi_4089_MVN-2020-00278-ST_gmndwi_lores.tif\n",
      "image_final2/GEE_images_final2_hires_mndvi_4089_MVN-2020-00278-ST_mndvi_hires.tif\n",
      "image_final2/GEE_images_final2_hires_srtm_4089_MVN-2020-00278-ST_srtm_hires.tif\n",
      "image_final2/GEE_images_final2_lores_mndwi_4089_MVN-2020-00278-ST_mndwi_lores.tif\n",
      "image_final2/GEE_images_final2_lores_mndvi_4089_MVN-2020-00278-ST_mndvi_lores.tif\n",
      "image_final2/GEE_images_final2_hires_transition_4089_MVN-2020-00278-ST_transition_hires.tif\n",
      "MVK-2015-00945-LCM 10\n",
      "image_final2/GEE_images_final2_lores_mndvi_2018_MVK-2015-00945-LCM_mndvi_lores.tif\n",
      "image_final2/GEE_images_final2_hires_seasonality_2018_MVK-2015-00945-LCM_seasonality_hires.tif\n",
      "image_final2/GEE_images_final2_hires_mndwi_2018_MVK-2015-00945-LCM_mndwi_hires.tif\n",
      "image_final2/GEE_images_final2_lores_srtm_2018_MVK-2015-00945-LCM_srtm_lores.tif\n",
      "image_final2/GEE_images_final2_lores_gmndwi_2018_MVK-2015-00945-LCM_gmndwi_lores.tif\n",
      "image_final2/GEE_images_final2_hires_transition_2018_MVK-2015-00945-LCM_transition_hires.tif\n",
      "image_final2/GEE_images_final2_lores_mndwi_2018_MVK-2015-00945-LCM_mndwi_lores.tif\n",
      "image_final2/GEE_images_final2_hires_mndvi_2018_MVK-2015-00945-LCM_mndvi_hires.tif\n",
      "image_final2/GEE_images_final2_hires_gmndwi_2018_MVK-2015-00945-LCM_gmndwi_hires.tif\n",
      "image_final2/GEE_images_final2_hires_srtm_2018_MVK-2015-00945-LCM_srtm_hires.tif\n",
      "LRH-2016-00913-LMR 10\n",
      "image_final2/GEE_images_final2_hires_gmndwi_1163_LRH-2016-00913-LMR_gmndwi_hires.tif\n",
      "image_final2/GEE_images_final2_hires_mndvi_1163_LRH-2016-00913-LMR_mndvi_hires.tif\n",
      "image_final2/GEE_images_final2_lores_mndwi_1163_LRH-2016-00913-LMR_mndwi_lores.tif\n",
      "image_final2/GEE_images_final2_hires_seasonality_1163_LRH-2016-00913-LMR_seasonality_hires.tif\n",
      "image_final2/GEE_images_final2_hires_transition_1163_LRH-2016-00913-LMR_transition_hires.tif\n",
      "image_final2/GEE_images_final2_lores_mndvi_1163_LRH-2016-00913-LMR_mndvi_lores.tif\n",
      "image_final2/GEE_images_final2_hires_srtm_1163_LRH-2016-00913-LMR_srtm_hires.tif\n",
      "image_final2/GEE_images_final2_lores_srtm_1163_LRH-2016-00913-LMR_srtm_lores.tif\n",
      "image_final2/GEE_images_final2_hires_mndwi_1163_LRH-2016-00913-LMR_mndwi_hires.tif\n",
      "image_final2/GEE_images_final2_lores_gmndwi_1163_LRH-2016-00913-LMR_gmndwi_lores.tif\n",
      "LRH-2015-00666-SCR 10\n",
      "image_final2/GEE_images_final2_hires_mndvi_1065_LRH-2015-00666-SCR_mndvi_hires.tif\n",
      "image_final2/GEE_images_final2_lores_gmndwi_1065_LRH-2015-00666-SCR_gmndwi_lores.tif\n",
      "image_final2/GEE_images_final2_hires_gmndwi_1065_LRH-2015-00666-SCR_gmndwi_hires.tif\n",
      "image_final2/GEE_images_final2_hires_srtm_1065_LRH-2015-00666-SCR_srtm_hires.tif\n",
      "image_final2/GEE_images_final2_lores_mndwi_1065_LRH-2015-00666-SCR_mndwi_lores.tif\n",
      "image_final2/GEE_images_final2_hires_seasonality_1065_LRH-2015-00666-SCR_seasonality_hires.tif\n",
      "image_final2/GEE_images_final2_hires_transition_1065_LRH-2015-00666-SCR_transition_hires.tif\n",
      "image_final2/GEE_images_final2_hires_mndwi_1065_LRH-2015-00666-SCR_mndwi_hires.tif\n",
      "image_final2/GEE_images_final2_lores_mndvi_1065_LRH-2015-00666-SCR_mndvi_lores.tif\n",
      "image_final2/GEE_images_final2_lores_srtm_1065_LRH-2015-00666-SCR_srtm_lores.tif\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for k, v in d.items():\n",
    "    print(k, len(v))\n",
    "    for f in v:\n",
    "        print(f)\n",
    "    counter += 1\n",
    "    if counter >3: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "together-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_Tiffs(list_of_tiffs):\n",
    "    layer_list = []\n",
    "    for t in list_of_tiffs:\n",
    "        # open the geotiff\n",
    "        p = gdal.Open(str(t))\n",
    "        channels = p.RasterCount\n",
    "        #print(p.GetDescription())\n",
    "        \n",
    "        # iterate through rasters and add each to the list of layer_list\n",
    "        layer_list += [np.array(p.GetRasterBand(i).ReadAsArray()) for i in range(1,channels+1)] \n",
    "        \n",
    "        \n",
    "    return np.array(layer_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "loving-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_array(tif_image):\n",
    "    p = gdal.Open(str(tif_image))\n",
    "    channels = p.RasterCount\n",
    "        \n",
    "    # iterate through rasters and add each to the list of layer_list\n",
    "    layer_list = [np.array(p.GetRasterBand(i).ReadAsArray()) for i in range(1,channels+1)] \n",
    "    return np.array(layer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adaptive-transmission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def packager1(tf_list):\n",
    "    if len(tf_list) != 4: print('ERROR tif list is not correct length')\n",
    "    hires_mndwi = [f for f in tf_list if 'hires' in f.name and 'mndwi' in f.name][0]\n",
    "    hires_srtm = [f for f in tf_list if 'hires' in f.name and 'srtm' in f.name][0]\n",
    "    lores_mndwi = [f for f in tf_list if 'lores' in f.name and 'mndwi' in f.name][0]\n",
    "    lores_srtm = [f for f in tf_list if 'lores' in f.name and 'srtm' in f.name][0]\n",
    "\n",
    "    hm = create_array(hires_mndwi)\n",
    "    #print(np.any(np.isnan(hm)))\n",
    "    #print(np.min(hm), np.max(hm))\n",
    "    hs = create_array(hires_srtm)\n",
    "    #print(np.any(np.isnan(hs)))\n",
    "    #print(np.min(hs), np.max(hs))\n",
    "    hs = (hs - hs.mean()) * (.3/hs.std()) +.5\n",
    "    #print(np.min(hs), np.max(hs))\n",
    "\n",
    "    lm = create_array(lores_mndwi)\n",
    "    #print(np.any(np.isnan(lm)))\n",
    "    #print(np.min(lm), np.max(lm))\n",
    "\n",
    "    ls = create_array(lores_srtm)\n",
    "    #print(np.any(np.isnan(ls)))\n",
    "    #print(np.min(ls), np.max(ls))\n",
    "    ls = (ls - ls.mean()) * (.3/ls.std()) +.5\n",
    "\n",
    "    return np.concatenate((hm, hs, hm+hs, lm, ls, lm+ls)).reshape(1,256,256,6)\n",
    "    \n",
    "    #print(hires_mndwi, hires_srtm, lores_mndwi, lores_srtm)\n",
    "    \n",
    "x = packager1(d.get('SAW-2019-01154'))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "placed-rachel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAC-2017-01685\n",
      "ERROR tif list is not correct length\n",
      "SAC-2017-01337\n",
      "SAC-2017-01457\n",
      "LRB-2014-01078\n",
      "SAC-2017-01637\n",
      "ERROR tif list is not correct length\n",
      "LRB-2005-00781\n",
      "ERROR tif list is not correct length\n",
      "ERROR tif list is not correct length\n",
      "ERROR tif list is not correct length\n",
      "MVN-2019-00863-XX\n",
      "LRB-2016-00071\n",
      "ERROR tif list is not correct length\n",
      "ERROR tif list is not correct length\n",
      "ERROR tif list is not correct length\n",
      "SAW-2019-00996\n",
      "SAC-2017-01523\n",
      "SAW-2019-01992\n",
      "ERROR tif list is not correct length\n",
      "ERROR tif list is not correct length\n",
      "MVP-2015-04355-MMJ\n"
     ]
    }
   ],
   "source": [
    "ids = list(d.keys())[450:550]\n",
    "X = []\n",
    "y = []\n",
    "for i in ids:\n",
    "    try:\n",
    "        arr = packager1(d.get(i))\n",
    "        if np.any(np.isnan(arr)): \n",
    "            print(i)\n",
    "            continue\n",
    "    except: continue\n",
    "    X.append(packager1(d.get(i)))\n",
    "    y.append(df[df.da_number == i]['cwa_determination'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bizarre-friendly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'>\n",
      "(85, 256, 256, 6)\n",
      "85 85\n",
      "[0.43529411764705883]\n"
     ]
    }
   ],
   "source": [
    "print(type(X),type(y))\n",
    "X = np.concatenate(X)\n",
    "y = np.array(y)\n",
    "print(X.shape)\n",
    "print(len(X), len(y))\n",
    "print([np.mean(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "average-canberra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.009447674418604"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_num = []\n",
    "image_sizes = []\n",
    "for key, val in d.items():\n",
    "    image_num.append(len(val))\n",
    "    \n",
    "np.mean(image_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "vietnamese-termination",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n",
      "<class 'tensorflow.python.keras.engine.functional.Functional'>\n"
     ]
    }
   ],
   "source": [
    "## develop input splitter\n",
    "from keras.applications.vgg16 import VGG16\n",
    "vgg16_model1 = VGG16(include_top=False, weights='imagenet', input_shape=(256,256, 3))\n",
    "vgg16_model2 = VGG16(include_top=False, weights='imagenet', input_shape=(256,256, 3))\n",
    "print(type(vgg16_model1))\n",
    "#vgg16_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-carpet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "infrared-nebraska",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.93007374, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.0363909 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.282697  , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.1146593 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.89918816, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.0051401 , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.0150213 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.1293299 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.2980423 , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.2231125 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.949102  , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.8570514 , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.0328059 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.9027562 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.9558207 , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.1456845 , 0.        ],\n",
       "         [0.08546084, 0.        , 0.        , ..., 0.        ,\n",
       "          0.84481096, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.7858678 , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.17155918, 0.        , 0.        , ..., 0.        ,\n",
       "          0.88217723, 0.        ],\n",
       "         [0.23371866, 0.        , 0.        , ..., 0.        ,\n",
       "          0.88849235, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.1354094 , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.0082655 , 0.        ],\n",
       "         [0.24395604, 0.        , 0.        , ..., 0.        ,\n",
       "          0.78490376, 0.        ],\n",
       "         [0.18355098, 0.        , 0.        , ..., 0.        ,\n",
       "          0.70911324, 0.        ]],\n",
       "\n",
       "        [[0.14214763, 0.        , 0.        , ..., 0.        ,\n",
       "          0.83460045, 0.        ],\n",
       "         [0.21928757, 0.        , 0.        , ..., 0.        ,\n",
       "          0.9724219 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.1877252 , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.0575519 , 0.        ],\n",
       "         [0.06739408, 0.        , 0.        , ..., 0.        ,\n",
       "          0.96306205, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.8021569 , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.15173763, ..., 0.        ,\n",
       "          0.7372483 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.8159797 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.93405515, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.9115811 , 0.        ],\n",
       "         [0.        , 0.        , 0.10128075, ..., 0.        ,\n",
       "          0.8116619 , 0.        ],\n",
       "         [0.        , 0.        , 0.08332625, ..., 0.        ,\n",
       "          0.53730446, 0.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = np.random.rand(256,256,3)\n",
    "test_input = test_input.reshape(1, 256,256, 3)\n",
    "print(test_input.shape)\n",
    "vgg16_model1.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "revolutionary-bunch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    s = np.random.rand(256,256,6)[:,:, i*3:3*(i+1)].shape\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "centered-virginia",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-019789f4266e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16_model1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "Sequential(vgg16_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "artificial-aberdeen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256, 256, 6)\n",
      "(None, 256, 256, 3)\n",
      "(None, 8, 8, 512)\n",
      "(None, 8, 8, 10)\n",
      "(None, 640)\n",
      "(None, 256, 256, 6)\n",
      "(None, 256, 256, 3)\n",
      "(None, 8, 8, 512)\n",
      "(None, 8, 8, 10)\n",
      "(None, 640)\n",
      "(None, 1280)\n",
      "(None, 10)\n",
      "(None, 2)\n",
      "(None, 2)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Concatenate, Input, Lambda, Flatten, Softmax\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "num_channels = 6\n",
    "input = Input(shape=(256,256, num_channels))\n",
    "\n",
    "branch_outputs = []\n",
    "\n",
    "# loop for however many branches you want to use.  (each branch needs 3 channel depth)\n",
    "for i in [0,3]:\n",
    "    # create looping so that vgg16 model input is created ie 256,256,3\n",
    "    print(input.shape)\n",
    "    out = Lambda(lambda x: x[:,:,:,i:i+3])(input)\n",
    "    print(out.shape)\n",
    "    \n",
    "    # Setting up your layers in each branch: (currently each branch is identical architecture.)\n",
    "    if i == 0: out = Sequential(vgg16_model1)(out)   # use pretrained and loaded vgg16\n",
    "    else: out = Sequential(vgg16_model1)(out)   # use pretrained and loaded vgg16\n",
    "    print(out.shape)\n",
    "    out = Dense(10)(out)\n",
    "    print(out.shape)\n",
    "    out = Flatten()(out)\n",
    "    print(out.shape)\n",
    "    branch_outputs.append(out)\n",
    "\n",
    "# Concatenating the branches outputs:\n",
    "out = Concatenate()(branch_outputs)\n",
    "print(out.shape)\n",
    "\n",
    "# Add final dense layers and softmax\n",
    "out = Dense(10)(out)\n",
    "print(out.shape)\n",
    "out = Dense(2)(out)\n",
    "print(out.shape)\n",
    "out = Softmax()(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "figured-publisher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb 28 07:30:50 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   39C    P8    27W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "filled-bahrain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 256, 256, 6) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 256, 256, 3)  0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 256, 256, 3)  0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 8, 8, 512)    14714688    lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 8, 8, 512)    14714688    lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 8, 8, 10)     5130        sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 8, 8, 10)     5130        sequential_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 640)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 640)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1280)         0           flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           12810       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2)            22          dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax_1 (Softmax)             (None, 2)            0           dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,737,780\n",
      "Trainable params: 14,737,780\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=input, outputs=out)   \n",
    "model.summary()\n",
    "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sitting-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "included-vacation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52614987, 0.47385013],\n",
       "       [0.50729644, 0.49270362],\n",
       "       [0.4020764 , 0.59792364],\n",
       "       [0.5092877 , 0.49071234],\n",
       "       [0.558615  , 0.44138497],\n",
       "       [0.5424467 , 0.4575533 ],\n",
       "       [0.6158485 , 0.38415152],\n",
       "       [0.9279001 , 0.07209992],\n",
       "       [0.91072845, 0.08927153],\n",
       "       [0.7216913 , 0.27830866],\n",
       "       [0.69085824, 0.30914176],\n",
       "       [0.6877592 , 0.31224078],\n",
       "       [0.49993137, 0.50006866],\n",
       "       [0.6228172 , 0.37718278],\n",
       "       [0.79717696, 0.20282304],\n",
       "       [0.57873434, 0.4212657 ],\n",
       "       [0.6701145 , 0.32988548],\n",
       "       [0.4465543 , 0.5534457 ],\n",
       "       [0.47780797, 0.522192  ],\n",
       "       [0.6321457 , 0.3678543 ],\n",
       "       [0.4218403 , 0.5781597 ],\n",
       "       [0.7781874 , 0.22181265],\n",
       "       [0.50960356, 0.49039644],\n",
       "       [0.51452   , 0.48548   ],\n",
       "       [0.47596624, 0.5240337 ],\n",
       "       [0.60892016, 0.39107987],\n",
       "       [0.6190333 , 0.38096675],\n",
       "       [0.76610214, 0.23389782],\n",
       "       [0.64370394, 0.35629612],\n",
       "       [0.46383935, 0.5361606 ],\n",
       "       [0.52807903, 0.47192097],\n",
       "       [0.27429357, 0.7257064 ],\n",
       "       [0.95849615, 0.04150378],\n",
       "       [0.69966733, 0.30033267],\n",
       "       [0.88112235, 0.11887763],\n",
       "       [0.5668664 , 0.43313363],\n",
       "       [0.63916534, 0.36083463],\n",
       "       [0.7446403 , 0.25535968],\n",
       "       [0.81540674, 0.18459326],\n",
       "       [0.6653549 , 0.3346451 ],\n",
       "       [0.7062909 , 0.2937091 ],\n",
       "       [0.6333564 , 0.36664355],\n",
       "       [0.6671803 , 0.33281967],\n",
       "       [0.7341342 , 0.2658658 ],\n",
       "       [0.532403  , 0.467597  ],\n",
       "       [0.8227616 , 0.17723843],\n",
       "       [0.52625626, 0.47374377],\n",
       "       [0.58377707, 0.41622293],\n",
       "       [0.7369982 , 0.2630018 ],\n",
       "       [0.5635051 , 0.43649486],\n",
       "       [0.7221692 , 0.2778308 ],\n",
       "       [0.85456944, 0.14543058],\n",
       "       [0.64182884, 0.35817116],\n",
       "       [0.7559968 , 0.24400316],\n",
       "       [0.58079153, 0.41920847],\n",
       "       [0.7095586 , 0.29044142],\n",
       "       [0.93441707, 0.06558289],\n",
       "       [0.84700125, 0.15299873],\n",
       "       [0.6371511 , 0.36284885],\n",
       "       [0.5167399 , 0.48326012],\n",
       "       [0.86061746, 0.13938257],\n",
       "       [0.73152274, 0.2684773 ],\n",
       "       [0.65755284, 0.3424472 ],\n",
       "       [0.7974545 , 0.20254548],\n",
       "       [0.61018413, 0.38981587],\n",
       "       [0.5081564 , 0.49184355],\n",
       "       [0.5508581 , 0.44914195],\n",
       "       [0.61495674, 0.3850433 ],\n",
       "       [0.68383825, 0.31616178],\n",
       "       [0.49554658, 0.5044535 ],\n",
       "       [0.795489  , 0.20451099],\n",
       "       [0.68484896, 0.31515104],\n",
       "       [0.7160837 , 0.28391626],\n",
       "       [0.40979668, 0.5902033 ],\n",
       "       [0.54519707, 0.454803  ],\n",
       "       [0.40753064, 0.5924694 ],\n",
       "       [0.67713135, 0.3228686 ],\n",
       "       [0.7715943 , 0.22840576],\n",
       "       [0.7686121 , 0.23138787],\n",
       "       [0.9497432 , 0.05025681],\n",
       "       [0.9194543 , 0.08054575],\n",
       "       [0.53891885, 0.4610812 ],\n",
       "       [0.4908255 , 0.50917447],\n",
       "       [0.34262076, 0.6573792 ],\n",
       "       [0.81336063, 0.18663937]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aerial-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "raised-vocabulary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 2/17 [==>...........................] - ETA: 51s - loss: 0.3759 - mae: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0730s vs `on_train_batch_end` time: 6.8187s). Check your callbacks.\n",
      "17/17 [==============================] - 141s 8s/step - loss: 0.4854 - mae: 0.5000 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/2\n",
      "17/17 [==============================] - 147s 9s/step - loss: 0.5000 - mae: 0.5000 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train time: 344.0562000274658\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "model.fit(X, y, epochs=2, batch_size=4, validation_split = 0.2)\n",
    "print(\"Train time:\", time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "massive-protein",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 6)\n",
      "[[0.4622121 0.537788 ]]\n",
      "time taken: 0.9495842456817627 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "test_input = np.random.rand(256,256,6)\n",
    "test_input = test_input.reshape(1, 256,256, 6)\n",
    "print(test_input.shape)\n",
    "t0 = time.time()\n",
    "print(model.predict(test_input))\n",
    "print(f\"time taken: {time.time()-t0} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "figured-medicine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.019184943337422e-08"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input.flatten().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "advisory-namibia",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Keras Visualizer: Layer not supported for visualizing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8d78ee4d9738>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_visualizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvisualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_visualizer/__init__.py\u001b[0m in \u001b[0;36mvisualizer\u001b[0;34m(model, filename, format, view)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Image\\n{pxls[1]} x{pxls[2]} pixels\\n{clrmap}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'square'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'filled'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthe_color\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Keras Visualizer: Layer not supported for visualizing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# Hidden Layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Keras Visualizer: Layer not supported for visualizing"
     ]
    }
   ],
   "source": [
    "from keras_visualizer import visualizer \n",
    "visualizer(model, format='png', view=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "radio-premium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'commit_hash': '2486838d9',\n",
      " 'commit_source': 'installation',\n",
      " 'default_encoding': 'ANSI_X3.4-1968',\n",
      " 'ipython_path': '/usr/local/lib/python3.6/dist-packages/IPython',\n",
      " 'ipython_version': '7.16.1',\n",
      " 'os_name': 'posix',\n",
      " 'platform': 'Linux-4.9.140-tegra-aarch64-with-Ubuntu-18.04-bionic',\n",
      " 'sys_executable': '/usr/bin/python3',\n",
      " 'sys_platform': 'linux',\n",
      " 'sys_version': '3.6.9 (default, Oct  8 2020, 12:12:24) \\n[GCC 8.4.0]'}\n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "print(IPython.sys_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "announced-vocabulary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'commit_hash': '2486838d9',\n",
      " 'commit_source': 'installation',\n",
      " 'default_encoding': 'UTF-8',\n",
      " 'ipython_path': '/usr/local/lib/python3.6/dist-packages/IPython',\n",
      " 'ipython_version': '7.16.1',\n",
      " 'os_name': 'posix',\n",
      " 'platform': 'Linux-5.4.0-1037-aws-x86_64-with-Ubuntu-18.04-bionic',\n",
      " 'sys_executable': '/usr/bin/python3',\n",
      " 'sys_platform': 'linux',\n",
      " 'sys_version': '3.6.9 (default, Jan 26 2021, 15:33:00) \\n[GCC 8.4.0]'}\n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "print(IPython.sys_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-street",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
